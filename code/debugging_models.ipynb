{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from sklearn import feature_selection, model_selection, preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import mytrain_lib as ml\n",
    "\n",
    "import importlib\n",
    "\n",
    "torch.manual_seed(0)\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train      = 'F://TFG//datasets//data_train//'\n",
    "path_graphs     = 'F://TFG//graphs//plot_results//'\n",
    "path_results    = 'F://TFG//results//'\n",
    "path_logs     = path_results+'logs//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF = pd.read_csv(path_train+'training_features_DF.csv',sep=';',index_col='wyId')\n",
    "dataDF.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Links:\n",
    "\n",
    "- <a href='https://blog.paperspace.com/pytorch-101-understanding-graphs-and-automatic-differentiation/'>Computation graphs and Automatic Differentiation</a>\n",
    "- <a href='https://blog.paperspace.com/pytorch-hooks-gradient-clipping-debugging/'>Hooks</a>\n",
    "- <a href='https://cs231n.github.io/neural-networks-3/#loss'>Debugging Loss</a>\n",
    "- <a href='http://karpathy.github.io/2019/04/25/recipe/'>A Recipe for training NN (Andrej Karpathy)</a>\n",
    "\n",
    "https://wandb.ai/ayush-thakur/debug-neural-nets/reports/Visualizing-and-Debugging-Neural-Networks-with-PyTorch-and-W-B--Vmlldzo2OTUzNA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objetivos:\n",
    "\n",
    "Analizar de los mejores modelos los siguientes aspectos:\n",
    "\n",
    "- Plot training y validation accuracy\n",
    "- Analizar el error segun el learning rate\n",
    "- Loss plot\n",
    "- Activation function plot\n",
    "- Plot activation/gradient histograms for all layers of the network\n",
    "- Plot weights 1st layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_feature, ouput_classes, hidden_neurons=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.h1 = nn.Linear(in_features=input_feature,out_features=hidden_neurons)\n",
    "        self.bn = nn.BatchNorm1d(hidden_neurons)\n",
    "        self.out = nn.Linear(hidden_neurons,ouput_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # x = F.relu(self.h1(x))\n",
    "        x = self.h1(x)\n",
    "        x = F.relu(self.bn(x))\n",
    "        # return self.out(x)    \n",
    "        # return self.out(x)    \n",
    "        return F.softmax(self.out(x),-1)   \n",
    "\n",
    "    def reset_weights(self):\n",
    "        self.h1.reset_parameters()\n",
    "        self.bn.reset_parameters()\n",
    "        self.out.reset_parameters()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData():\n",
    "    # Dimension reduction\n",
    "    train_data      = ml.FootballMatchesDataset(file = 'train')\n",
    "    train_data.data = train_data.data[:,:-2] # no consideramos ataque_defensa de toda la temporada\n",
    "    features = dataDF.columns[:-2]\n",
    "\n",
    "    # X_mean = torch.mean(train_data.data,dim=0).numpy()\n",
    "    # X_norm = train_data.data / X_mean\n",
    "\n",
    "    # # ANOVA: select best 7 features\n",
    "    # anova7 = feature_selection.SelectKBest(score_func=feature_selection.f_classif,k=7)\n",
    "    # anova7.fit(X_norm, train_data.labels.argmax(dim=1))\n",
    "    # train_data.data = train_data.data[:,anova7.get_support()]\n",
    "    # features = dataDF.columns[:-2][anova7.get_support()]\n",
    "    train_data.data.shape\n",
    "    return train_data, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ml)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train with Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, features = prepareData()\n",
    "\n",
    "model = NeuralNetwork(train_data.data.shape[1],3)\n",
    "\n",
    "lr=0.0001\n",
    "bs=64\n",
    "ep=100\n",
    "\n",
    "old_data = train_data.data.clone()\n",
    "scaler = preprocessing.Normalizer()\n",
    "train_data.data = scaler.fit_transform(old_data).astype(np.float32)\n",
    "\n",
    "title = f'mlp1x5_relu_sgd_anova07_norm_lr{lr}_epochs{ep}_b{bs}'\n",
    "path_exec = path_logs+title+'//'\n",
    "\n",
    "config = {\n",
    "                    'net': NeuralNetwork, 'input': train_data.data.shape[1], 'output': 3, \n",
    "                    'hidden_neurons': 5, 'opt_name':'SGD', 'opt': torch.optim.SGD, 'lr': lr, \n",
    "                    'momentum': False, 'nesterov': False, 'criterion': nn.BCELoss, \n",
    "                    'bat_size': bs, 'epochs': ep\n",
    "        }\n",
    "\n",
    "er,ac_tr,ac_te,cm = ml.train_wCrossValidation(config, train_data, \n",
    "                        model_selection.KFold(n_splits=5,shuffle=True,random_state=0),\n",
    "                        path=path_exec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fld = 3\n",
    "\n",
    "with open(path_exec+f'f{fld}.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "    trainlogs   = pd.DataFrame(data['train'])\n",
    "    testlogs    = pd.DataFrame(data['test'])\n",
    "\n",
    "    importlib.reload(ml)\n",
    "    ml.plot_error(trainlogs,path_exec,fld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlogs[trainlogs.it==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ml)\n",
    "\n",
    "ml.plot_model_stats(path_exec,features,fld=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data      = ml.FootballMatchesDataset(file = 'train')\n",
    "train_data.data = train_data.data[:,:-2] # no consideramos ataque_defensa de toda la temporada\n",
    "features = dataDF.columns[:-2]\n",
    "\n",
    "# normalization data\n",
    "old_data = train_data.data.clone()\n",
    "scaler = preprocessing.Normalizer()\n",
    "train_data.data = scaler.fit_transform(old_data).astype(np.float32)\n",
    "\n",
    "# split data\n",
    "\n",
    "datatrain, datatest = (torch.utils.data.random_split(train_data, \n",
    "                            [1100-300,300], generator=torch.Generator().manual_seed(0)))\n",
    "\n",
    "trainloader = DataLoader(datatrain,batch_size=64)\n",
    "testloader  = DataLoader(datatest,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(trainloader))[0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(train_data.data,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ml)\n",
    "\n",
    "model = NeuralNetwork(train_data.data.shape[1],3)\n",
    "\n",
    "title = 'prueba'\n",
    "\n",
    "er,ac_tr,ac_te,cm = ml.train_model(model,nn.BCELoss(),\n",
    "                    torch.optim.SGD(lr=0.05,params=model.parameters()),\n",
    "                    trainloader, testloader,    \n",
    "                    epochs=150)\n",
    "\n",
    "ml.save_log_model(title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_logs+title+'.json') as json_file:\n",
    "    data = json.load(json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlogs   = pd.DataFrame(data['train'])\n",
    "testlogs    = pd.DataFrame(data['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlogs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.plot_error(trainlogs,path_logs+title,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ERROR AND ACCURACY PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "for it in range(5):\n",
    "    data = trainlogs[trainlogs.it==it]\n",
    "    plt.plot(data.loss,label=it+1)\n",
    "\n",
    "plt.title(f'Error model')\n",
    "plt.xticks(range(0,len(trainlogs),250),rotation=45)\n",
    "plt.legend(title='Batch')\n",
    "# plt.grid()\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('error')\n",
    "plt.ylim([0.5,0.75])\n",
    "# plt.savefig(path_exec + f'error_f{fld}.jpg', format='jpg', dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(nrows=1,ncols=2,figsize=(13,4))\n",
    "testdata = testlogs[testlogs.it==0]\n",
    "traindata = trainlogs[trainlogs.it==0]\n",
    "\n",
    "fig.suptitle('Learning plot',fontsize=18)\n",
    "\n",
    "ax1.plot(testlogs[testlogs.it==2].acc,color='#149AF8')\n",
    "\n",
    "ax2.plot(trainlogs[trainlogs.it==3].acc,color='#FF774E')\n",
    "\n",
    "ax1.set_title('Test accuracy'); ax2.set_title('Train accuracy')\n",
    "# ax1.legend(title='Batch'); ax2.legend(title='Batch')\n",
    "ax1.set_ylim([np.min(testdata.acc)-0.2,np.max(testdata.acc)+np.min(testdata.acc)])\n",
    "ax2.set_ylim([np.min(testdata.acc)-0.2,np.max(testdata.acc)+np.min(testdata.acc)])\n",
    "\n",
    "# plt.savefig(path_exec + f'accuracy_f{fld}.jpg', format='jpg', dpi=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(nrows=2,ncols=1,figsize=(10,12))\n",
    "testdata = testlogs[testlogs.it==0]\n",
    "traindata = trainlogs[trainlogs.it==0]\n",
    "\n",
    "fig.suptitle('Learning plot',fontsize=20)\n",
    "\n",
    "for it in range(max(testlogs.it)):\n",
    "    data = testlogs[testlogs.it==it+1]\n",
    "    ax1.plot(data.acc,label=it)\n",
    "\n",
    "for it in range(5):\n",
    "    data = trainlogs[trainlogs.it==it+1]\n",
    "    ax2.plot(data.acc,label=it)\n",
    "\n",
    "ax1.set_title('Test accuracy'); ax2.set_title('Train accuracy')\n",
    "ax1.legend(title='Batch'); ax2.legend(title='Batch')\n",
    "ax1.set_ylim([np.min(testdata.acc)-0.3,np.max(testdata.acc)+np.min(testdata.acc)])\n",
    "ax2.set_ylim([np.min(testdata.acc)-0.3,np.max(testdata.acc)+np.min(testdata.acc)])\n",
    "\n",
    "# plt.savefig(path_exec + f'accuracy_batches_f{fld}.jpg', format='jpg', dpi=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlogs.weights[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1      = np.array([w.weights['h1.weight'] for w in trainlogs.itertuples()]).T\n",
    "h1bias  = np.array([w.weights['h1.bias'] for w in trainlogs.itertuples()]).T\n",
    "# h1 = h1.reshape(h1.shape[0],-1)\n",
    "h1bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(0,figsize=(25,12))\n",
    "fig.suptitle('Hidden layer weights', fontsize=30)\n",
    "\n",
    "for i in range(h1.shape[1]):\n",
    "    ax = plt.subplot(2,3,i+1)\n",
    "    ax.set_title(f'Weights unit {i}')\n",
    "    for w,f in enumerate(features):\n",
    "        if i==4: ax.plot(h1[w,i,:],label=f)\n",
    "        else: ax.plot(h1[w,i,:])\n",
    "    if i==4: ax.legend(title='Weights:',loc='lower center',bbox_to_anchor=(0.5, 1.05),\n",
    "        ncol=3, fancybox=True, shadow=True)\n",
    "    ax.grid()\n",
    "    if i==0: ax.set_xlabel('iterations'); ax.set_ylabel('value')\n",
    "\n",
    "ax = plt.subplot(230+h1.shape[1]+1)\n",
    "ax.set_title('Biases of all units')\n",
    "for i,bias in enumerate(h1bias):\n",
    "    ax.plot(bias,label=i)\n",
    "ax.legend(title='Unit:')\n",
    "ax.grid()\n",
    "\n",
    "# plt.savefig(path_exec + f'weights_f{fld}.jpg', format='jpg', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRADIENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradients = np.array(trainlogs.grad.to_list()).T\n",
    "gradients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 0\n",
    "n = 4\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(gradients[w,n,:],label=f'peso {w} unit {n}')\n",
    "# plt.savefig(path_exec + f'gradient_f{fld}_w{w}_n{n}.jpg', format='jpg', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(0,figsize=(25,12))\n",
    "fig.suptitle('Hidden layer gradients', fontsize=30)\n",
    "\n",
    "for i in range(gradients.shape[1]):\n",
    "    ax = plt.subplot(2,3,i+1)\n",
    "    ax.set_title(f'Gradients unit {i}')\n",
    "    for w,f in enumerate(features):\n",
    "        if i==4: ax.plot(gradients[w,i,:],label=f,alpha=0.3)\n",
    "        else: ax.plot(gradients[w,i,:],alpha=0.5)\n",
    "    ax.grid()\n",
    "    if i==0: ax.set_xlabel('iterations'); ax.set_ylabel('value')\n",
    "    if i==4: ax.legend(title='Gradients:',loc='lower center',bbox_to_anchor=(0.5, 1.05),\n",
    "        ncol=3, fancybox=True, shadow=True)\n",
    "\n",
    "# plt.savefig(path_exec + f'gradients_f{fld}.jpg', format='jpg', dpi=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('tfg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "288ff6fe8157f43ba3e1fb4cfa0011490e9beb907b54ad0d71ae70a61946bdb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
