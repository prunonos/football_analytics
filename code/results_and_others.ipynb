{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import mytrain_lib as ml\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(error,accuracy_train,accuracy_test,confusion_matrix, hyperparams):\n",
    "    confusion_matrix = np.array(confusion_matrix)\n",
    "    accuracy_test    = np.array(accuracy_test)\n",
    "    accuracy_train   = np.array(accuracy_train)\n",
    "    error            = np.array(error)\n",
    "\n",
    "    acc_test_lastepoch = accuracy_test[:,:,-1]  # only interested in last epoch\n",
    "\n",
    "    # best models of each configuration\n",
    "    best_cv          = acc_test_lastepoch.argmax(axis=1)\n",
    "    best_config_cv   = np.unique(acc_test_lastepoch.argmax(axis=0))\n",
    "\n",
    "    # best configurations are:\n",
    "    print('config','\\t', 'accuracy_test\\t', '\\taccuracy_train\\t', '\\terror')\n",
    "\n",
    "    for c in best_config_cv:\n",
    "        print(c,'\\t', accuracy_test[c,best_cv[c],-1]\n",
    "                    , accuracy_train[c,best_cv[c],-1]\n",
    "                    , error[c,best_cv[c],-1])\n",
    "\n",
    "    temp = datetime.now().strftime(\"_%m%d_%H%M%S\")\n",
    "\n",
    "    for i,c in enumerate(best_config_cv):\n",
    "        print(f'Config of {c} - Fold {best_cv[c]}: {hyperparams[c]}')\n",
    "        ml.dispConfusionMatrix(confusion_matrix[c,best_cv[c]],\n",
    "                        f'Confusion Matrix: MLP 1x5 SGD {hyperparams[c]}',\n",
    "                        f'confmat_mlp5_SGD_t{temp}_id{i}', save=True)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train      = 'F://TFG//datasets//data_train//'\n",
    "path_graphs     = 'F://TFG//graphs//plot_results//'\n",
    "path_results    = 'F://TFG//results//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data        = pd.read_csv(path_train+'training_features_DF.csv',sep=';',index_col='wyId')\n",
    "raw_Data    = pd.read_json('F://TFG//datasets/raw_datasets//RAW_partidos.json').set_index('wyId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep, pca, opt = [10,20], [3,5,10], ['sgd','adam']\n",
    "params = (np.array(np.meshgrid(ep,pca,opt)).T.reshape((-1,3)))\n",
    "\n",
    "acc_res, acc_err = {}, {}\n",
    "r_acc = re.compile(r'(acctest__)(\\w)*(.npy)')\n",
    "r_err = re.compile(r'(error__)(\\w)*(.npy)')\n",
    "\n",
    "for p in params:\n",
    "    path_nopca  = f'mlp15_{p[2]}_ep{p[0]}'\n",
    "    path_pca    = f'mlp15_{p[2]}_ep{p[0]}_pca{p[1]}'\n",
    "\n",
    "    files_nopca = os.listdir(path_results+path_nopca)\n",
    "    files_pca   = os.listdir(path_results+path_pca)\n",
    "\n",
    "    if p[1]=='3': \n",
    "        file_name = list(filter(r_acc.match, files_nopca))[0]\n",
    "        acc_res[path_nopca] = np.load(path_results+path_nopca+'//'+file_name)\n",
    "        file_name = list(filter(r_err.match, files_nopca))[0]\n",
    "        acc_err[path_nopca] = np.load(path_results+path_nopca+'//'+file_name)\n",
    "        \n",
    "    file_name = list(filter(r_acc.match, files_pca))[0]\n",
    "    acc_res[path_pca] = np.load(path_results+path_pca+'//'+file_name)\n",
    "    file_name = list(filter(r_err.match, files_pca))[0]\n",
    "    acc_err[path_pca] = np.load(path_results+path_pca+'//'+file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks = []\n",
    "\n",
    "for p in params:\n",
    "    if p[1]=='3':\n",
    "        xticks.append(f'ep={p[0]}')\n",
    "    xticks.append('ep={}\\npca={}'.format(p[0],p[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy on Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values = [np.max(acc_res[k][:,:,-1]) for k in acc_res.keys()]\n",
    "mean_values = [np.mean(acc_res[k][:,:,-1]) for k in acc_res.keys()]\n",
    "\n",
    "color = ['#1183C4','#17CA45','#0E5F8E','#108C30']\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(2,1,figsize=(12,10))\n",
    "\n",
    "fig.suptitle('Accuracy on experiments',fontsize=18)\n",
    "\n",
    "ax1.set_title('Max Accuracy')\n",
    "ax1.bar(x=list(acc_res.keys()),height=max_values,color=[color[i>7] for i in range(16)])\n",
    "ax1.set_xlabel('experiments'); ax1.set_ylabel('accuracy')\n",
    "ax1.set_ylim([0,1])\n",
    "ax1.set_xticklabels('')\n",
    "\n",
    "ax2.set_title('Mean Accuracy')\n",
    "ax2.bar(x=list(acc_res.keys()),height=mean_values,color=[color[(i>7)+2] for i in range(16)])\n",
    "ax2.set_xlabel('experiments'); ax2.set_ylabel('accuracy')\n",
    "ax2.set_xticklabels(ax2.get_xticks(), rotation = 0)\n",
    "ax2.set_ylim([0,1])\n",
    "ax2.set_xticklabels(xticks[:len(mean_values)],fontsize=8)\n",
    "\n",
    "plt.savefig(path_graphs + 'accuracy_expPCA.jpg', format='jpg', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error on experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values = [np.min(acc_err[k][:,:,-1]) for k in acc_res.keys()]\n",
    "mean_values = [np.mean(acc_err[k][:,:,-1]) for k in acc_res.keys()]\n",
    "\n",
    "color = ['#D14444','#B5189D','#6F2424','#630E56']\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(2,1,figsize=(12,10))\n",
    "\n",
    "fig.suptitle('Error on experiments',fontsize=18)\n",
    "\n",
    "ax1.set_title('Min error')\n",
    "ax1.bar(x=list(acc_err.keys()),height=max_values,color=[color[i>7] for i in range(16)])\n",
    "ax1.set_xlabel('experiments'); ax1.set_ylabel('error')\n",
    "ax1.set_ylim([0,1.2])\n",
    "ax1.set_xticklabels('')\n",
    "\n",
    "ax2.set_title('Mean error')\n",
    "ax2.bar(x=list(acc_err.keys()),height=mean_values,color=[color[(i>7)+2] for i in range(16)])\n",
    "ax2.set_xlabel('experiments'); ax2.set_ylabel('error')\n",
    "ax2.set_xticklabels(ax2.get_xticks(), rotation = 0)\n",
    "ax2.set_ylim([0,1.2])\n",
    "ax2.set_xticklabels(xticks,fontsize=8)\n",
    "\n",
    "plt.savefig(path_graphs + 'error_expPCA.jpg', format='jpg', dpi=200)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('tfg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "288ff6fe8157f43ba3e1fb4cfa0011490e9beb907b54ad0d71ae70a61946bdb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
