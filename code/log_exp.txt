INFO: start
['side_avg_15D_home' 'Scored_15D_home' 'Received_15D_home'
 'points_15D_home' 'side_avg_15D_away' 'Scored_15D_away'
 'Received_15D_away' 'points_15D_away' 'side_avg_30D_home'
 'Scored_30D_home' 'Received_30D_home' 'points_30D_home'
 'side_avg_30D_away' 'Scored_30D_away' 'Received_30D_away'
 'points_30D_away' 'side_avg_60D_home' 'Scored_60D_home'
 'Received_60D_home' 'points_60D_home' 'side_avg_60D_away'
 'Scored_60D_away' 'Received_60D_away' 'points_60D_away'
 'side_avg_180D_home' 'Scored_180D_home' 'Received_180D_home'
 'points_180D_home' 'side_avg_180D_away' 'Scored_180D_away'
 'Received_180D_away' 'points_180D_away' 'side_avg_365D_home'
 'Scored_365D_home' 'Received_365D_home' 'points_365D_home'
 'side_avg_365D_away' 'Scored_365D_away' 'Received_365D_away'
 'points_365D_away' 'side_avg_730D_home' 'Scored_730D_home'
 'Received_730D_home' 'points_730D_home' 'side_avg_730D_away'
 'Scored_730D_away' 'Received_730D_away' 'points_730D_away'
 'side_avg_1825D_home' 'Scored_1825D_home' 'Received_1825D_home'
 'points_1825D_home' 'side_avg_1825D_away' 'Scored_1825D_away'
 'Received_1825D_away' 'points_1825D_away' 'derby_Scored_1_home'
 'derby_Side_1_home' 'derby_points_1_home' 'derby_Scored_1_away'
 'derby_Side_1_away' 'derby_points_1_away' 'derby_Scored_3_home'
 'derby_Side_3_home' 'derby_points_3_home' 'derby_Scored_3_away'
 'derby_Side_3_away' 'derby_points_3_away' 'derby_Scored_5_home'
 'derby_Side_5_home' 'derby_points_5_home' 'derby_Scored_5_away'
 'derby_Side_5_away' 'derby_points_5_away' 'derby_Scored_10_home'
 'derby_Side_10_home' 'derby_points_10_home' 'derby_Scored_10_away'
 'derby_Side_10_away' 'derby_points_10_away']
Index(['side_avg_15D_home', 'Scored_15D_home', 'Received_15D_home',
       'points_15D_home', 'side_avg_15D_away', 'Scored_15D_away',
       'Received_15D_away', 'points_15D_away', 'side_avg_30D_home',
       'Scored_30D_home', 'Received_30D_home', 'points_30D_home',
       'side_avg_30D_away', 'Scored_30D_away', 'Received_30D_away',
       'points_30D_away', 'side_avg_60D_home', 'Scored_60D_home',
       'Received_60D_home', 'points_60D_home', 'side_avg_60D_away',
       'Scored_60D_away', 'Received_60D_away', 'points_60D_away',
       'side_avg_180D_home', 'Scored_180D_home', 'Received_180D_home',
       'points_180D_home', 'side_avg_180D_away', 'Scored_180D_away',
       'Received_180D_away', 'points_180D_away', 'side_avg_365D_home',
       'Scored_365D_home', 'Received_365D_home', 'points_365D_home',
       'side_avg_365D_away', 'Scored_365D_away', 'Received_365D_away',
       'points_365D_away', 'side_avg_730D_home', 'Scored_730D_home',
       'Received_730D_home', 'points_730D_home', 'side_avg_730D_away',
       'Scored_730D_away', 'Received_730D_away', 'points_730D_away',
       'side_avg_1825D_home', 'Scored_1825D_home', 'Received_1825D_home',
       'points_1825D_home', 'side_avg_1825D_away', 'Scored_1825D_away',
       'Received_1825D_away', 'points_1825D_away', 'derby_Scored_1_home',
       'derby_Side_1_home', 'derby_points_1_home', 'derby_Scored_1_away',
       'derby_Side_1_away', 'derby_points_1_away', 'derby_Scored_3_home',
       'derby_Side_3_home', 'derby_points_3_home', 'derby_Scored_3_away',
       'derby_Side_3_away', 'derby_points_3_away', 'derby_Scored_5_home',
       'derby_Side_5_home', 'derby_points_5_home', 'derby_Scored_5_away',
       'derby_Side_5_away', 'derby_points_5_away', 'derby_Scored_10_home',
       'derby_Side_10_home', 'derby_points_10_home', 'derby_Scored_10_away',
       'derby_Side_10_away', 'derby_points_10_away'],
      dtype='object')
(9519, 80)
Index(['side_avg_15D_home', 'Scored_15D_home', 'Received_15D_home',
       'points_15D_home', 'side_avg_15D_away', 'Scored_15D_away',
       'Received_15D_away', 'points_15D_away', 'side_avg_30D_home',
       'Scored_30D_home', 'Received_30D_home', 'points_30D_home',
       'side_avg_30D_away', 'Scored_30D_away', 'Received_30D_away',
       'points_30D_away', 'side_avg_60D_home', 'Scored_60D_home',
       'Received_60D_home', 'points_60D_home', 'side_avg_60D_away',
       'Scored_60D_away', 'Received_60D_away', 'points_60D_away',
       'side_avg_180D_home', 'Scored_180D_home', 'Received_180D_home',
       'points_180D_home', 'side_avg_180D_away', 'Scored_180D_away',
       'Received_180D_away', 'points_180D_away', 'side_avg_365D_home',
       'Scored_365D_home', 'Received_365D_home', 'points_365D_home',
       'side_avg_365D_away', 'Scored_365D_away', 'Received_365D_away',
       'points_365D_away', 'side_avg_730D_home', 'Scored_730D_home',
       'Received_730D_home', 'points_730D_home', 'side_avg_730D_away',
       'Scored_730D_away', 'Received_730D_away', 'points_730D_away',
       'side_avg_1825D_home', 'Scored_1825D_home', 'Received_1825D_home',
       'points_1825D_home', 'side_avg_1825D_away', 'Scored_1825D_away',
       'Received_1825D_away', 'points_1825D_away', 'derby_Scored_1_home',
       'derby_Side_1_home', 'derby_points_1_home', 'derby_Scored_1_away',
       'derby_Side_1_away', 'derby_points_1_away', 'derby_Scored_3_home',
       'derby_Side_3_home', 'derby_points_3_home', 'derby_Scored_3_away',
       'derby_Side_3_away', 'derby_points_3_away', 'derby_Scored_5_home',
       'derby_Side_5_home', 'derby_points_5_home', 'derby_Scored_5_away',
       'derby_Side_5_away', 'derby_points_5_away', 'derby_Scored_10_home',
       'derby_Side_10_home', 'derby_points_10_home', 'derby_Scored_10_away',
       'derby_Side_10_away', 'derby_points_10_away'],
      dtype='object')
(2376, 80)
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=7900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7900
[LightGBM] [Warning] min_gain_to_split is set=12.054078258227182, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.054078258227182
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=7900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7900
[LightGBM] [Warning] min_gain_to_split is set=12.054078258227182, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.054078258227182
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=7900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7900
[LightGBM] [Warning] min_gain_to_split is set=12.054078258227182, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.054078258227182
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=7900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7900
[LightGBM] [Warning] min_gain_to_split is set=12.054078258227182, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.054078258227182
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100
[LightGBM] [Warning] min_gain_to_split is set=6.780783004087341, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.780783004087341
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.1875	validation's multi_logloss: 1.1874
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.17132	validation's multi_logloss: 1.17156
[3]	training's multi_logloss: 1.15693	validation's multi_logloss: 1.15686
[4]	training's multi_logloss: 1.14417	validation's multi_logloss: 1.14418
[5]	training's multi_logloss: 1.13322	validation's multi_logloss: 1.13368
[6]	training's multi_logloss: 1.12333	validation's multi_logloss: 1.12383
[7]	training's multi_logloss: 1.11435	validation's multi_logloss: 1.115
[8]	training's multi_logloss: 1.10608	validation's multi_logloss: 1.10689
[9]	training's multi_logloss: 1.10241	validation's multi_logloss: 1.1032
[10]	training's multi_logloss: 1.10241	validation's multi_logloss: 1.1032
[11]	training's multi_logloss: 1.10241	validation's multi_logloss: 1.1032
[12]	training's multi_logloss: 1.09945	validation's multi_logloss: 1.10068
[13]	training's multi_logloss: 1.09737	validation's multi_logloss: 1.09863
[14]	training's multi_logloss: 1.09558	validation's multi_logloss: 1.09688
[15]	training's multi_logloss: 1.09399	validation's multi_logloss: 1.09529
[16]	training's multi_logloss: 1.09273	validation's multi_logloss: 1.09416
[17]	training's multi_logloss: 1.09161	validation's multi_logloss: 1.09301
[18]	training's multi_logloss: 1.09077	validation's multi_logloss: 1.09217
[19]	training's multi_logloss: 1.09	validation's multi_logloss: 1.09141
[20]	training's multi_logloss: 1.08935	validation's multi_logloss: 1.09066
[21]	training's multi_logloss: 1.08876	validation's multi_logloss: 1.09015
[22]	training's multi_logloss: 1.08876	validation's multi_logloss: 1.09015
[23]	training's multi_logloss: 1.08876	validation's multi_logloss: 1.09015
[24]	training's multi_logloss: 1.08876	validation's multi_logloss: 1.09015
[25]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[26]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[27]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[28]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[29]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[30]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[31]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[32]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[33]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[34]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[35]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[36]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[37]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[38]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[39]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[40]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[41]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[42]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[43]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[44]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[45]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
Early stopping, best iteration is:
[25]	training's multi_logloss: 1.08827	validation's multi_logloss: 1.08985
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100
[LightGBM] [Warning] min_gain_to_split is set=6.780783004087341, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.780783004087341
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18808	validation's multi_logloss: 1.18781
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.1716	validation's multi_logloss: 1.17201
[3]	training's multi_logloss: 1.15684	validation's multi_logloss: 1.15682
[4]	training's multi_logloss: 1.1446	validation's multi_logloss: 1.1443
[5]	training's multi_logloss: 1.13367	validation's multi_logloss: 1.13297
[6]	training's multi_logloss: 1.12368	validation's multi_logloss: 1.12327
[7]	training's multi_logloss: 1.11472	validation's multi_logloss: 1.11401
[8]	training's multi_logloss: 1.10634	validation's multi_logloss: 1.10559
[9]	training's multi_logloss: 1.10238	validation's multi_logloss: 1.10177
[10]	training's multi_logloss: 1.09937	validation's multi_logloss: 1.09857
[11]	training's multi_logloss: 1.097	validation's multi_logloss: 1.09637
[12]	training's multi_logloss: 1.0951	validation's multi_logloss: 1.09421
[13]	training's multi_logloss: 1.09364	validation's multi_logloss: 1.09276
[14]	training's multi_logloss: 1.09224	validation's multi_logloss: 1.09173
[15]	training's multi_logloss: 1.09112	validation's multi_logloss: 1.09084
[16]	training's multi_logloss: 1.09021	validation's multi_logloss: 1.08981
[17]	training's multi_logloss: 1.08937	validation's multi_logloss: 1.08876
[18]	training's multi_logloss: 1.08868	validation's multi_logloss: 1.08832
[19]	training's multi_logloss: 1.08815	validation's multi_logloss: 1.0878
[20]	training's multi_logloss: 1.08815	validation's multi_logloss: 1.0878
[21]	training's multi_logloss: 1.08765	validation's multi_logloss: 1.08714
[22]	training's multi_logloss: 1.08765	validation's multi_logloss: 1.08714
[23]	training's multi_logloss: 1.08765	validation's multi_logloss: 1.08714
[24]	training's multi_logloss: 1.08723	validation's multi_logloss: 1.08659
[25]	training's multi_logloss: 1.08723	validation's multi_logloss: 1.08659
[26]	training's multi_logloss: 1.08723	validation's multi_logloss: 1.08659
[27]	training's multi_logloss: 1.08723	validation's multi_logloss: 1.08659
[28]	training's multi_logloss: 1.08723	validation's multi_logloss: 1.08659
[29]	training's multi_logloss: 1.08723	validation's multi_logloss: 1.08659
[30]	training's multi_logloss: 1.08723	validation's multi_logloss: 1.08659
[31]	training's multi_logloss: 1.08723	validation's multi_logloss: 1.08659
[32]	training's multi_logloss: 1.08723	validation's multi_logloss: 1.08659
[33]	training's multi_logloss: 1.08723	validation's multi_logloss: 1.08659
[34]	training's multi_logloss: 1.08723	validation's multi_logloss: 1.08659
[35]	training's multi_logloss: 1.08684	validation's multi_logloss: 1.08631
[36]	training's multi_logloss: 1.08684	validation's multi_logloss: 1.08631
[37]	training's multi_logloss: 1.08684	validation's multi_logloss: 1.08631
[38]	training's multi_logloss: 1.08684	validation's multi_logloss: 1.08631
[39]	training's multi_logloss: 1.08684	validation's multi_logloss: 1.08631
[40]	training's multi_logloss: 1.08684	validation's multi_logloss: 1.08631
[41]	training's multi_logloss: 1.08684	validation's multi_logloss: 1.08631
[42]	training's multi_logloss: 1.08684	validation's multi_logloss: 1.08631
[43]	training's multi_logloss: 1.08684	validation's multi_logloss: 1.08631
[44]	training's multi_logloss: 1.08684	validation's multi_logloss: 1.08631
[45]	training's multi_logloss: 1.08684	validation's multi_logloss: 1.08631
[46]	training's multi_logloss: 1.08684	validation's multi_logloss: 1.08631
[47]	training's multi_logloss: 1.08684	validation's multi_logloss: 1.08631
[48]	training's multi_logloss: 1.08684	validation's multi_logloss: 1.08631
[49]	training's multi_logloss: 1.08684	validation's multi_logloss: 1.08631
[50]	training's multi_logloss: 1.08684	validation's multi_logloss: 1.08631
[51]	training's multi_logloss: 1.08684	validation's multi_logloss: 1.08631
[52]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[53]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[54]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[55]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[56]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[57]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[58]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[59]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[60]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[61]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[62]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[63]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[64]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[65]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[66]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[67]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[68]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[69]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[70]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[71]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[72]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
Early stopping, best iteration is:
[52]	training's multi_logloss: 1.08646	validation's multi_logloss: 1.08585
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100
[LightGBM] [Warning] min_gain_to_split is set=6.780783004087341, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.780783004087341
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05153	validation's multi_logloss: 1.05213
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.0452	validation's multi_logloss: 1.04641
[3]	training's multi_logloss: 1.04012	validation's multi_logloss: 1.04152
[4]	training's multi_logloss: 1.03599	validation's multi_logloss: 1.03829
[5]	training's multi_logloss: 1.03223	validation's multi_logloss: 1.0347
[6]	training's multi_logloss: 1.02929	validation's multi_logloss: 1.03251
[7]	training's multi_logloss: 1.02623	validation's multi_logloss: 1.02982
[8]	training's multi_logloss: 1.02405	validation's multi_logloss: 1.02742
[9]	training's multi_logloss: 1.022	validation's multi_logloss: 1.02584
[10]	training's multi_logloss: 1.02009	validation's multi_logloss: 1.02452
[11]	training's multi_logloss: 1.01844	validation's multi_logloss: 1.02323
[12]	training's multi_logloss: 1.01708	validation's multi_logloss: 1.02212
[13]	training's multi_logloss: 1.01583	validation's multi_logloss: 1.02141
[14]	training's multi_logloss: 1.01467	validation's multi_logloss: 1.02078
[15]	training's multi_logloss: 1.01411	validation's multi_logloss: 1.02038
[16]	training's multi_logloss: 1.01361	validation's multi_logloss: 1.02009
[17]	training's multi_logloss: 1.0127	validation's multi_logloss: 1.01955
[18]	training's multi_logloss: 1.01222	validation's multi_logloss: 1.01927
[19]	training's multi_logloss: 1.01181	validation's multi_logloss: 1.01919
[20]	training's multi_logloss: 1.01139	validation's multi_logloss: 1.01906
[21]	training's multi_logloss: 1.01101	validation's multi_logloss: 1.01884
[22]	training's multi_logloss: 1.01101	validation's multi_logloss: 1.01884
[23]	training's multi_logloss: 1.01101	validation's multi_logloss: 1.01884
[24]	training's multi_logloss: 1.01101	validation's multi_logloss: 1.01884
[25]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[26]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[27]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[28]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[29]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[30]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[31]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[32]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[33]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[34]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[35]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[36]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[37]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[38]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[39]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[40]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[41]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[42]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[43]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[44]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[45]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
Early stopping, best iteration is:
[25]	training's multi_logloss: 1.01061	validation's multi_logloss: 1.0186
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100
[LightGBM] [Warning] min_gain_to_split is set=6.780783004087341, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.780783004087341
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18691	validation's multi_logloss: 1.18874
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.17005	validation's multi_logloss: 1.17277
[3]	training's multi_logloss: 1.15563	validation's multi_logloss: 1.15841
[4]	training's multi_logloss: 1.14311	validation's multi_logloss: 1.14702
[5]	training's multi_logloss: 1.13238	validation's multi_logloss: 1.13751
[6]	training's multi_logloss: 1.12239	validation's multi_logloss: 1.12761
[7]	training's multi_logloss: 1.11332	validation's multi_logloss: 1.11839
[8]	training's multi_logloss: 1.105	validation's multi_logloss: 1.1111
[9]	training's multi_logloss: 1.09716	validation's multi_logloss: 1.10303
[10]	training's multi_logloss: 1.09716	validation's multi_logloss: 1.10303
[11]	training's multi_logloss: 1.09362	validation's multi_logloss: 1.09947
[12]	training's multi_logloss: 1.09077	validation's multi_logloss: 1.09671
[13]	training's multi_logloss: 1.08856	validation's multi_logloss: 1.09527
[14]	training's multi_logloss: 1.08679	validation's multi_logloss: 1.09355
[15]	training's multi_logloss: 1.08542	validation's multi_logloss: 1.09218
[16]	training's multi_logloss: 1.08422	validation's multi_logloss: 1.09109
[17]	training's multi_logloss: 1.08316	validation's multi_logloss: 1.09065
[18]	training's multi_logloss: 1.08224	validation's multi_logloss: 1.08977
[19]	training's multi_logloss: 1.08224	validation's multi_logloss: 1.08977
[20]	training's multi_logloss: 1.08224	validation's multi_logloss: 1.08977
[21]	training's multi_logloss: 1.08152	validation's multi_logloss: 1.08912
[22]	training's multi_logloss: 1.08152	validation's multi_logloss: 1.08912
[23]	training's multi_logloss: 1.08152	validation's multi_logloss: 1.08912
[24]	training's multi_logloss: 1.08152	validation's multi_logloss: 1.08912
[25]	training's multi_logloss: 1.08152	validation's multi_logloss: 1.08912
[26]	training's multi_logloss: 1.08086	validation's multi_logloss: 1.08847
[27]	training's multi_logloss: 1.08086	validation's multi_logloss: 1.08847
[28]	training's multi_logloss: 1.08086	validation's multi_logloss: 1.08847
[29]	training's multi_logloss: 1.08086	validation's multi_logloss: 1.08847
[30]	training's multi_logloss: 1.08086	validation's multi_logloss: 1.08847
[31]	training's multi_logloss: 1.08086	validation's multi_logloss: 1.08847
[32]	training's multi_logloss: 1.08034	validation's multi_logloss: 1.0884
[33]	training's multi_logloss: 1.08034	validation's multi_logloss: 1.0884
[34]	training's multi_logloss: 1.08034	validation's multi_logloss: 1.0884
[35]	training's multi_logloss: 1.08034	validation's multi_logloss: 1.0884
[36]	training's multi_logloss: 1.08034	validation's multi_logloss: 1.0884
[37]	training's multi_logloss: 1.08034	validation's multi_logloss: 1.0884
[38]	training's multi_logloss: 1.08034	validation's multi_logloss: 1.0884
[39]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[40]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[41]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[42]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[43]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[44]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[45]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[46]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[47]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[48]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[49]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[50]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[51]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[52]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[53]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[54]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[55]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[56]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[57]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[58]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[59]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
Early stopping, best iteration is:
[39]	training's multi_logloss: 1.07986	validation's multi_logloss: 1.08794
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100
[LightGBM] [Warning] min_gain_to_split is set=9.109877567702423, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.109877567702423
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100
[LightGBM] [Warning] min_gain_to_split is set=9.109877567702423, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.109877567702423
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100
[LightGBM] [Warning] min_gain_to_split is set=9.109877567702423, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.109877567702423
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100
[LightGBM] [Warning] min_gain_to_split is set=9.109877567702423, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.109877567702423
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500
[LightGBM] [Warning] min_gain_to_split is set=3.271773055359483, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.271773055359483
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500
[LightGBM] [Warning] min_gain_to_split is set=3.271773055359483, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.271773055359483
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500
[LightGBM] [Warning] min_gain_to_split is set=3.271773055359483, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.271773055359483
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500
[LightGBM] [Warning] min_gain_to_split is set=3.271773055359483, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.271773055359483
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=6200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6200
[LightGBM] [Warning] min_gain_to_split is set=0.40456586642946435, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.40456586642946435
[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=6200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6200
[LightGBM] [Warning] min_gain_to_split is set=0.40456586642946435, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.40456586642946435
[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=6200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6200
[LightGBM] [Warning] min_gain_to_split is set=0.40456586642946435, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.40456586642946435
[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=6200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6200
[LightGBM] [Warning] min_gain_to_split is set=0.40456586642946435, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.40456586642946435
[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600
[LightGBM] [Warning] min_gain_to_split is set=10.174356265225585, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.174356265225585
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600
[LightGBM] [Warning] min_gain_to_split is set=10.174356265225585, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.174356265225585
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600
[LightGBM] [Warning] min_gain_to_split is set=10.174356265225585, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.174356265225585
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600
[LightGBM] [Warning] min_gain_to_split is set=10.174356265225585, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.174356265225585
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100
[LightGBM] [Warning] min_gain_to_split is set=9.405420067477857, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.405420067477857
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100
[LightGBM] [Warning] min_gain_to_split is set=9.405420067477857, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.405420067477857
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100
[LightGBM] [Warning] min_gain_to_split is set=9.405420067477857, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.405420067477857
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100
[LightGBM] [Warning] min_gain_to_split is set=9.405420067477857, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.405420067477857
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=5500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5500
[LightGBM] [Warning] min_gain_to_split is set=6.623974143025204, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.623974143025204
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=5500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5500
[LightGBM] [Warning] min_gain_to_split is set=6.623974143025204, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.623974143025204
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=5500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5500
[LightGBM] [Warning] min_gain_to_split is set=6.623974143025204, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.623974143025204
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=5500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5500
[LightGBM] [Warning] min_gain_to_split is set=6.623974143025204, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.623974143025204
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=1000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1000
[LightGBM] [Warning] min_gain_to_split is set=8.040674577999257, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.040674577999257
[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200
[LightGBM] [Warning] min_gain_to_split is set=3.122189554784398, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.122189554784398
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200
[LightGBM] [Warning] min_gain_to_split is set=3.122189554784398, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.122189554784398
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200
[LightGBM] [Warning] min_gain_to_split is set=3.122189554784398, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.122189554784398
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=3900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3900
[LightGBM] [Warning] min_gain_to_split is set=14.416742654558028, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.416742654558028
[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=3900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3900
[LightGBM] [Warning] min_gain_to_split is set=14.416742654558028, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.416742654558028
[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=3900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3900
[LightGBM] [Warning] min_gain_to_split is set=14.416742654558028, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.416742654558028
[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=3900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3900
[LightGBM] [Warning] min_gain_to_split is set=14.416742654558028, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.416742654558028
[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100
[LightGBM] [Warning] min_gain_to_split is set=12.490609307465824, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.490609307465824
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100
[LightGBM] [Warning] min_gain_to_split is set=12.490609307465824, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.490609307465824
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100
[LightGBM] [Warning] min_gain_to_split is set=12.490609307465824, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.490609307465824
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100
[LightGBM] [Warning] min_gain_to_split is set=12.490609307465824, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.490609307465824
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=3200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3200
[LightGBM] [Warning] min_gain_to_split is set=11.598604767385083, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.598604767385083
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=6900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6900
[LightGBM] [Warning] min_gain_to_split is set=6.099710916138754, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.099710916138754
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=6900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6900
[LightGBM] [Warning] min_gain_to_split is set=6.099710916138754, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.099710916138754
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=6900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6900
[LightGBM] [Warning] min_gain_to_split is set=6.099710916138754, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.099710916138754
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=4400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4400
[LightGBM] [Warning] min_gain_to_split is set=13.941738014078107, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.941738014078107
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=4400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4400
[LightGBM] [Warning] min_gain_to_split is set=13.941738014078107, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.941738014078107
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=4400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4400
[LightGBM] [Warning] min_gain_to_split is set=13.941738014078107, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.941738014078107
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=4400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4400
[LightGBM] [Warning] min_gain_to_split is set=13.941738014078107, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.941738014078107
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=9900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9900
[LightGBM] [Warning] min_gain_to_split is set=11.028251910586704, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.028251910586704
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=9900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9900
[LightGBM] [Warning] min_gain_to_split is set=11.028251910586704, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.028251910586704
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=9900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9900
[LightGBM] [Warning] min_gain_to_split is set=11.028251910586704, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.028251910586704
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=9900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9900
[LightGBM] [Warning] min_gain_to_split is set=11.028251910586704, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.028251910586704
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700
[LightGBM] [Warning] min_gain_to_split is set=12.85535644252531, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.85535644252531
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700
[LightGBM] [Warning] min_gain_to_split is set=12.85535644252531, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.85535644252531
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700
[LightGBM] [Warning] min_gain_to_split is set=12.85535644252531, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.85535644252531
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700
[LightGBM] [Warning] min_gain_to_split is set=12.85535644252531, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.85535644252531
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=7400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7400
[LightGBM] [Warning] min_gain_to_split is set=14.878591969896497, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.878591969896497
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=7400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7400
[LightGBM] [Warning] min_gain_to_split is set=14.878591969896497, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.878591969896497
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=7400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7400
[LightGBM] [Warning] min_gain_to_split is set=14.878591969896497, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.878591969896497
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=7400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7400
[LightGBM] [Warning] min_gain_to_split is set=14.878591969896497, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.878591969896497
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=5100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5100
[LightGBM] [Warning] min_gain_to_split is set=8.018767292394443, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.018767292394443
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=5100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5100
[LightGBM] [Warning] min_gain_to_split is set=8.018767292394443, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.018767292394443
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=5100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5100
[LightGBM] [Warning] min_gain_to_split is set=8.018767292394443, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.018767292394443
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=5100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5100
[LightGBM] [Warning] min_gain_to_split is set=8.018767292394443, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.018767292394443
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2300
[LightGBM] [Warning] min_gain_to_split is set=10.8436037354731, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.8436037354731
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800
[LightGBM] [Warning] min_gain_to_split is set=12.713632594947645, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.713632594947645
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800
[LightGBM] [Warning] min_gain_to_split is set=12.713632594947645, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.713632594947645
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800
[LightGBM] [Warning] min_gain_to_split is set=12.713632594947645, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.713632594947645
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=3800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3800
[LightGBM] [Warning] min_gain_to_split is set=9.396571257342012, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.396571257342012
[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=3800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3800
[LightGBM] [Warning] min_gain_to_split is set=9.396571257342012, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.396571257342012
[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=3800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3800
[LightGBM] [Warning] min_gain_to_split is set=9.396571257342012, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.396571257342012
[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=3800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3800
[LightGBM] [Warning] min_gain_to_split is set=9.396571257342012, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.396571257342012
[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=9.685003326236782, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.685003326236782
[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=5100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5100
[LightGBM] [Warning] min_gain_to_split is set=6.670680719373495, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.670680719373495
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=5100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5100
[LightGBM] [Warning] min_gain_to_split is set=6.670680719373495, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.670680719373495
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=5100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5100
[LightGBM] [Warning] min_gain_to_split is set=6.670680719373495, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.670680719373495
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100
[LightGBM] [Warning] min_gain_to_split is set=11.64598401156813, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.64598401156813
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100
[LightGBM] [Warning] min_gain_to_split is set=11.64598401156813, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.64598401156813
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100
[LightGBM] [Warning] min_gain_to_split is set=11.64598401156813, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.64598401156813
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100
[LightGBM] [Warning] min_gain_to_split is set=11.64598401156813, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.64598401156813
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=4000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4000
[LightGBM] [Warning] min_gain_to_split is set=8.758220056359491, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.758220056359491
[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=4000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4000
[LightGBM] [Warning] min_gain_to_split is set=8.758220056359491, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.758220056359491
[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=4000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4000
[LightGBM] [Warning] min_gain_to_split is set=8.758220056359491, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.758220056359491
[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=4000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4000
[LightGBM] [Warning] min_gain_to_split is set=8.758220056359491, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.758220056359491
[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=6600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6600
[LightGBM] [Warning] min_gain_to_split is set=10.347247022600621, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.347247022600621
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=6600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6600
[LightGBM] [Warning] min_gain_to_split is set=10.347247022600621, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.347247022600621
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=6600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6600
[LightGBM] [Warning] min_gain_to_split is set=10.347247022600621, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.347247022600621
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=6600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6600
[LightGBM] [Warning] min_gain_to_split is set=10.347247022600621, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.347247022600621
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=5700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5700
[LightGBM] [Warning] min_gain_to_split is set=7.780431180778114, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.780431180778114
[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=5700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5700
[LightGBM] [Warning] min_gain_to_split is set=7.780431180778114, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.780431180778114
[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=5700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5700
[LightGBM] [Warning] min_gain_to_split is set=7.780431180778114, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.780431180778114
[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=5700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5700
[LightGBM] [Warning] min_gain_to_split is set=7.780431180778114, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.780431180778114
[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600
[LightGBM] [Warning] min_gain_to_split is set=5.843997492314925, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.843997492314925
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05208	validation's multi_logloss: 1.05167
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.04501	validation's multi_logloss: 1.04424
[3]	training's multi_logloss: 1.0387	validation's multi_logloss: 1.03777
[4]	training's multi_logloss: 1.03448	validation's multi_logloss: 1.03387
[5]	training's multi_logloss: 1.03069	validation's multi_logloss: 1.0296
[6]	training's multi_logloss: 1.02756	validation's multi_logloss: 1.02667
[7]	training's multi_logloss: 1.02456	validation's multi_logloss: 1.02326
[8]	training's multi_logloss: 1.02245	validation's multi_logloss: 1.02111
[9]	training's multi_logloss: 1.02052	validation's multi_logloss: 1.01907
[10]	training's multi_logloss: 1.01927	validation's multi_logloss: 1.01774
[11]	training's multi_logloss: 1.0178	validation's multi_logloss: 1.01593
[12]	training's multi_logloss: 1.0162	validation's multi_logloss: 1.01449
[13]	training's multi_logloss: 1.01477	validation's multi_logloss: 1.01311
[14]	training's multi_logloss: 1.01385	validation's multi_logloss: 1.01234
[15]	training's multi_logloss: 1.01287	validation's multi_logloss: 1.01136
[16]	training's multi_logloss: 1.01205	validation's multi_logloss: 1.01055
[17]	training's multi_logloss: 1.01103	validation's multi_logloss: 1.00933
[18]	training's multi_logloss: 1.01033	validation's multi_logloss: 1.00862
[19]	training's multi_logloss: 1.00974	validation's multi_logloss: 1.00808
[20]	training's multi_logloss: 1.00887	validation's multi_logloss: 1.00716
[21]	training's multi_logloss: 1.00856	validation's multi_logloss: 1.00691
[22]	training's multi_logloss: 1.00828	validation's multi_logloss: 1.00653
[23]	training's multi_logloss: 1.00828	validation's multi_logloss: 1.00653
[24]	training's multi_logloss: 1.00799	validation's multi_logloss: 1.00627
[25]	training's multi_logloss: 1.00773	validation's multi_logloss: 1.00593
[26]	training's multi_logloss: 1.00707	validation's multi_logloss: 1.00516
[27]	training's multi_logloss: 1.00707	validation's multi_logloss: 1.00516
[28]	training's multi_logloss: 1.00707	validation's multi_logloss: 1.00516
[29]	training's multi_logloss: 1.00683	validation's multi_logloss: 1.00481
[30]	training's multi_logloss: 1.00683	validation's multi_logloss: 1.00481
[31]	training's multi_logloss: 1.00683	validation's multi_logloss: 1.00481
[32]	training's multi_logloss: 1.00653	validation's multi_logloss: 1.00469
[33]	training's multi_logloss: 1.00653	validation's multi_logloss: 1.00469
[34]	training's multi_logloss: 1.00622	validation's multi_logloss: 1.00456
[35]	training's multi_logloss: 1.00622	validation's multi_logloss: 1.00456
[36]	training's multi_logloss: 1.00596	validation's multi_logloss: 1.00426
[37]	training's multi_logloss: 1.00596	validation's multi_logloss: 1.00426
[38]	training's multi_logloss: 1.00596	validation's multi_logloss: 1.00426
[39]	training's multi_logloss: 1.00596	validation's multi_logloss: 1.00426
[40]	training's multi_logloss: 1.00596	validation's multi_logloss: 1.00426
[41]	training's multi_logloss: 1.00596	validation's multi_logloss: 1.00426
[42]	training's multi_logloss: 1.00596	validation's multi_logloss: 1.00426
[43]	training's multi_logloss: 1.00596	validation's multi_logloss: 1.00426
[44]	training's multi_logloss: 1.00596	validation's multi_logloss: 1.00426
[45]	training's multi_logloss: 1.00596	validation's multi_logloss: 1.00426
[46]	training's multi_logloss: 1.00596	validation's multi_logloss: 1.00426
[47]	training's multi_logloss: 1.00575	validation's multi_logloss: 1.00404
[48]	training's multi_logloss: 1.00575	validation's multi_logloss: 1.00404
[49]	training's multi_logloss: 1.00575	validation's multi_logloss: 1.00404
[50]	training's multi_logloss: 1.00575	validation's multi_logloss: 1.00404
[51]	training's multi_logloss: 1.00575	validation's multi_logloss: 1.00404
[52]	training's multi_logloss: 1.00547	validation's multi_logloss: 1.00372
[53]	training's multi_logloss: 1.00547	validation's multi_logloss: 1.00372
[54]	training's multi_logloss: 1.00547	validation's multi_logloss: 1.00372
[55]	training's multi_logloss: 1.00547	validation's multi_logloss: 1.00372
[56]	training's multi_logloss: 1.00523	validation's multi_logloss: 1.00345
[57]	training's multi_logloss: 1.00523	validation's multi_logloss: 1.00345
[58]	training's multi_logloss: 1.00523	validation's multi_logloss: 1.00345
[59]	training's multi_logloss: 1.00523	validation's multi_logloss: 1.00345
[60]	training's multi_logloss: 1.00523	validation's multi_logloss: 1.00345
[61]	training's multi_logloss: 1.00523	validation's multi_logloss: 1.00345
[62]	training's multi_logloss: 1.00523	validation's multi_logloss: 1.00345
[63]	training's multi_logloss: 1.00523	validation's multi_logloss: 1.00345
[64]	training's multi_logloss: 1.00523	validation's multi_logloss: 1.00345
[65]	training's multi_logloss: 1.00523	validation's multi_logloss: 1.00345
[66]	training's multi_logloss: 1.00523	validation's multi_logloss: 1.00345
[67]	training's multi_logloss: 1.00498	validation's multi_logloss: 1.00311
[68]	training's multi_logloss: 1.00498	validation's multi_logloss: 1.00311
[69]	training's multi_logloss: 1.00498	validation's multi_logloss: 1.00311
[70]	training's multi_logloss: 1.00498	validation's multi_logloss: 1.00311
[71]	training's multi_logloss: 1.00498	validation's multi_logloss: 1.00311
[72]	training's multi_logloss: 1.00498	validation's multi_logloss: 1.00311
[73]	training's multi_logloss: 1.00498	validation's multi_logloss: 1.00311
[74]	training's multi_logloss: 1.00498	validation's multi_logloss: 1.00311
[75]	training's multi_logloss: 1.00498	validation's multi_logloss: 1.00311
[76]	training's multi_logloss: 1.00498	validation's multi_logloss: 1.00311
[77]	training's multi_logloss: 1.00498	validation's multi_logloss: 1.00311
[78]	training's multi_logloss: 1.00498	validation's multi_logloss: 1.00311
[79]	training's multi_logloss: 1.00498	validation's multi_logloss: 1.00311
[80]	training's multi_logloss: 1.00498	validation's multi_logloss: 1.00311
[81]	training's multi_logloss: 1.00498	validation's multi_logloss: 1.00311
[82]	training's multi_logloss: 1.00498	validation's multi_logloss: 1.00311
[83]	training's multi_logloss: 1.00498	validation's multi_logloss: 1.00311
[84]	training's multi_logloss: 1.00466	validation's multi_logloss: 1.00269
[85]	training's multi_logloss: 1.00466	validation's multi_logloss: 1.00269
[86]	training's multi_logloss: 1.00466	validation's multi_logloss: 1.00269
[87]	training's multi_logloss: 1.00466	validation's multi_logloss: 1.00269
[88]	training's multi_logloss: 1.00466	validation's multi_logloss: 1.00269
[89]	training's multi_logloss: 1.00466	validation's multi_logloss: 1.00269
[90]	training's multi_logloss: 1.00466	validation's multi_logloss: 1.00269
[91]	training's multi_logloss: 1.00466	validation's multi_logloss: 1.00269
[92]	training's multi_logloss: 1.00466	validation's multi_logloss: 1.00269
[93]	training's multi_logloss: 1.00466	validation's multi_logloss: 1.00269
[94]	training's multi_logloss: 1.00466	validation's multi_logloss: 1.00269
[95]	training's multi_logloss: 1.00466	validation's multi_logloss: 1.00269
[96]	training's multi_logloss: 1.00466	validation's multi_logloss: 1.00269
[97]	training's multi_logloss: 1.00466	validation's multi_logloss: 1.00269
[98]	training's multi_logloss: 1.00466	validation's multi_logloss: 1.00269
[99]	training's multi_logloss: 1.00466	validation's multi_logloss: 1.00269
[100]	training's multi_logloss: 1.00466	validation's multi_logloss: 1.00269
Did not meet early stopping. Best iteration is:
[84]	training's multi_logloss: 1.00466	validation's multi_logloss: 1.00269
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600
[LightGBM] [Warning] min_gain_to_split is set=5.843997492314925, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.843997492314925
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18825	validation's multi_logloss: 1.18781
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.17626	validation's multi_logloss: 1.17612
[3]	training's multi_logloss: 1.16516	validation's multi_logloss: 1.16554
[4]	training's multi_logloss: 1.15521	validation's multi_logloss: 1.15553
[5]	training's multi_logloss: 1.14586	validation's multi_logloss: 1.14603
[6]	training's multi_logloss: 1.13746	validation's multi_logloss: 1.13764
[7]	training's multi_logloss: 1.12973	validation's multi_logloss: 1.13001
[8]	training's multi_logloss: 1.12245	validation's multi_logloss: 1.12243
[9]	training's multi_logloss: 1.11559	validation's multi_logloss: 1.1154
[10]	training's multi_logloss: 1.10907	validation's multi_logloss: 1.1091
[11]	training's multi_logloss: 1.1031	validation's multi_logloss: 1.10284
[12]	training's multi_logloss: 1.09746	validation's multi_logloss: 1.09676
[13]	training's multi_logloss: 1.09218	validation's multi_logloss: 1.09162
[14]	training's multi_logloss: 1.08732	validation's multi_logloss: 1.08646
[15]	training's multi_logloss: 1.08248	validation's multi_logloss: 1.08168
[16]	training's multi_logloss: 1.07816	validation's multi_logloss: 1.0776
[17]	training's multi_logloss: 1.07421	validation's multi_logloss: 1.07398
[18]	training's multi_logloss: 1.07017	validation's multi_logloss: 1.0699
[19]	training's multi_logloss: 1.06645	validation's multi_logloss: 1.06586
[20]	training's multi_logloss: 1.06481	validation's multi_logloss: 1.06454
[21]	training's multi_logloss: 1.06326	validation's multi_logloss: 1.06284
[22]	training's multi_logloss: 1.06197	validation's multi_logloss: 1.06142
[23]	training's multi_logloss: 1.06197	validation's multi_logloss: 1.06142
[24]	training's multi_logloss: 1.06086	validation's multi_logloss: 1.06064
[25]	training's multi_logloss: 1.05996	validation's multi_logloss: 1.0597
[26]	training's multi_logloss: 1.05924	validation's multi_logloss: 1.05888
[27]	training's multi_logloss: 1.05838	validation's multi_logloss: 1.05823
[28]	training's multi_logloss: 1.05769	validation's multi_logloss: 1.05775
[29]	training's multi_logloss: 1.05706	validation's multi_logloss: 1.05739
[30]	training's multi_logloss: 1.05706	validation's multi_logloss: 1.05739
[31]	training's multi_logloss: 1.05706	validation's multi_logloss: 1.05739
[32]	training's multi_logloss: 1.05651	validation's multi_logloss: 1.05703
[33]	training's multi_logloss: 1.05601	validation's multi_logloss: 1.05659
[34]	training's multi_logloss: 1.05555	validation's multi_logloss: 1.05619
[35]	training's multi_logloss: 1.05555	validation's multi_logloss: 1.05619
[36]	training's multi_logloss: 1.05555	validation's multi_logloss: 1.05619
[37]	training's multi_logloss: 1.05523	validation's multi_logloss: 1.05602
[38]	training's multi_logloss: 1.05523	validation's multi_logloss: 1.05602
[39]	training's multi_logloss: 1.05489	validation's multi_logloss: 1.05571
[40]	training's multi_logloss: 1.05489	validation's multi_logloss: 1.05571
[41]	training's multi_logloss: 1.05489	validation's multi_logloss: 1.05571
[42]	training's multi_logloss: 1.05458	validation's multi_logloss: 1.0555
[43]	training's multi_logloss: 1.05458	validation's multi_logloss: 1.0555
[44]	training's multi_logloss: 1.05458	validation's multi_logloss: 1.0555
[45]	training's multi_logloss: 1.05458	validation's multi_logloss: 1.0555
[46]	training's multi_logloss: 1.05458	validation's multi_logloss: 1.0555
[47]	training's multi_logloss: 1.05458	validation's multi_logloss: 1.0555
[48]	training's multi_logloss: 1.05458	validation's multi_logloss: 1.0555
[49]	training's multi_logloss: 1.05458	validation's multi_logloss: 1.0555
[50]	training's multi_logloss: 1.05458	validation's multi_logloss: 1.0555
[51]	training's multi_logloss: 1.05423	validation's multi_logloss: 1.05508
[52]	training's multi_logloss: 1.05423	validation's multi_logloss: 1.05508
[53]	training's multi_logloss: 1.05423	validation's multi_logloss: 1.05508
[54]	training's multi_logloss: 1.05423	validation's multi_logloss: 1.05508
[55]	training's multi_logloss: 1.05423	validation's multi_logloss: 1.05508
[56]	training's multi_logloss: 1.05423	validation's multi_logloss: 1.05508
[57]	training's multi_logloss: 1.05396	validation's multi_logloss: 1.05479
[58]	training's multi_logloss: 1.05396	validation's multi_logloss: 1.05479
[59]	training's multi_logloss: 1.05396	validation's multi_logloss: 1.05479
[60]	training's multi_logloss: 1.05371	validation's multi_logloss: 1.05472
[61]	training's multi_logloss: 1.05371	validation's multi_logloss: 1.05472
[62]	training's multi_logloss: 1.05371	validation's multi_logloss: 1.05472
[63]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[64]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[65]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[66]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[67]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[68]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[69]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[70]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[71]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[72]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[73]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[74]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[75]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[76]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[77]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[78]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[79]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[80]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[81]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[82]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[83]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
Early stopping, best iteration is:
[63]	training's multi_logloss: 1.05348	validation's multi_logloss: 1.05443
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600
[LightGBM] [Warning] min_gain_to_split is set=5.843997492314925, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.843997492314925
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05212	validation's multi_logloss: 1.0538
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.04455	validation's multi_logloss: 1.04707
[3]	training's multi_logloss: 1.03807	validation's multi_logloss: 1.04153
[4]	training's multi_logloss: 1.03272	validation's multi_logloss: 1.03713
[5]	training's multi_logloss: 1.02913	validation's multi_logloss: 1.0345
[6]	training's multi_logloss: 1.02466	validation's multi_logloss: 1.03091
[7]	training's multi_logloss: 1.02144	validation's multi_logloss: 1.0287
[8]	training's multi_logloss: 1.01851	validation's multi_logloss: 1.02623
[9]	training's multi_logloss: 1.01606	validation's multi_logloss: 1.02422
[10]	training's multi_logloss: 1.01456	validation's multi_logloss: 1.02306
[11]	training's multi_logloss: 1.01273	validation's multi_logloss: 1.02183
[12]	training's multi_logloss: 1.01099	validation's multi_logloss: 1.02061
[13]	training's multi_logloss: 1.00951	validation's multi_logloss: 1.01965
[14]	training's multi_logloss: 1.00837	validation's multi_logloss: 1.01874
[15]	training's multi_logloss: 1.0075	validation's multi_logloss: 1.01814
[16]	training's multi_logloss: 1.00652	validation's multi_logloss: 1.01764
[17]	training's multi_logloss: 1.0056	validation's multi_logloss: 1.01723
[18]	training's multi_logloss: 1.00463	validation's multi_logloss: 1.01647
[19]	training's multi_logloss: 1.00423	validation's multi_logloss: 1.01633
[20]	training's multi_logloss: 1.00387	validation's multi_logloss: 1.01619
[21]	training's multi_logloss: 1.00278	validation's multi_logloss: 1.01552
[22]	training's multi_logloss: 1.00206	validation's multi_logloss: 1.01502
[23]	training's multi_logloss: 1.00176	validation's multi_logloss: 1.01491
[24]	training's multi_logloss: 1.00125	validation's multi_logloss: 1.01437
[25]	training's multi_logloss: 1.00064	validation's multi_logloss: 1.01408
[26]	training's multi_logloss: 1.00064	validation's multi_logloss: 1.01408
[27]	training's multi_logloss: 1.0004	validation's multi_logloss: 1.01389
[28]	training's multi_logloss: 1.0001	validation's multi_logloss: 1.01387
[29]	training's multi_logloss: 0.99984	validation's multi_logloss: 1.0137
[30]	training's multi_logloss: 0.999588	validation's multi_logloss: 1.01349
[31]	training's multi_logloss: 0.999588	validation's multi_logloss: 1.01349
[32]	training's multi_logloss: 0.999328	validation's multi_logloss: 1.01344
[33]	training's multi_logloss: 0.999328	validation's multi_logloss: 1.01344
[34]	training's multi_logloss: 0.999328	validation's multi_logloss: 1.01344
[35]	training's multi_logloss: 0.999328	validation's multi_logloss: 1.01344
[36]	training's multi_logloss: 0.999328	validation's multi_logloss: 1.01344
[37]	training's multi_logloss: 0.999328	validation's multi_logloss: 1.01344
[38]	training's multi_logloss: 0.999328	validation's multi_logloss: 1.01344
[39]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[40]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[41]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[42]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[43]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[44]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[45]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[46]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[47]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[48]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[49]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[50]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[51]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[52]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[53]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[54]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[55]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[56]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[57]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[58]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[59]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
Early stopping, best iteration is:
[39]	training's multi_logloss: 0.999091	validation's multi_logloss: 1.01334
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600
[LightGBM] [Warning] min_gain_to_split is set=5.843997492314925, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.843997492314925
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05139	validation's multi_logloss: 1.052
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.04463	validation's multi_logloss: 1.04624
[3]	training's multi_logloss: 1.03812	validation's multi_logloss: 1.04054
[4]	training's multi_logloss: 1.03404	validation's multi_logloss: 1.037
[5]	training's multi_logloss: 1.02938	validation's multi_logloss: 1.03303
[6]	training's multi_logloss: 1.02657	validation's multi_logloss: 1.03037
[7]	training's multi_logloss: 1.02419	validation's multi_logloss: 1.02833
[8]	training's multi_logloss: 1.02132	validation's multi_logloss: 1.02603
[9]	training's multi_logloss: 1.01916	validation's multi_logloss: 1.02423
[10]	training's multi_logloss: 1.01757	validation's multi_logloss: 1.02291
[11]	training's multi_logloss: 1.01585	validation's multi_logloss: 1.02147
[12]	training's multi_logloss: 1.01455	validation's multi_logloss: 1.02046
[13]	training's multi_logloss: 1.01255	validation's multi_logloss: 1.01887
[14]	training's multi_logloss: 1.01117	validation's multi_logloss: 1.01796
[15]	training's multi_logloss: 1.01018	validation's multi_logloss: 1.01729
[16]	training's multi_logloss: 1.00926	validation's multi_logloss: 1.01637
[17]	training's multi_logloss: 1.00843	validation's multi_logloss: 1.01548
[18]	training's multi_logloss: 1.00747	validation's multi_logloss: 1.01469
[19]	training's multi_logloss: 1.00681	validation's multi_logloss: 1.01417
[20]	training's multi_logloss: 1.00653	validation's multi_logloss: 1.01389
[21]	training's multi_logloss: 1.00582	validation's multi_logloss: 1.01357
[22]	training's multi_logloss: 1.00545	validation's multi_logloss: 1.01316
[23]	training's multi_logloss: 1.0049	validation's multi_logloss: 1.01292
[24]	training's multi_logloss: 1.00461	validation's multi_logloss: 1.01266
[25]	training's multi_logloss: 1.00461	validation's multi_logloss: 1.01266
[26]	training's multi_logloss: 1.00461	validation's multi_logloss: 1.01266
[27]	training's multi_logloss: 1.00461	validation's multi_logloss: 1.01266
[28]	training's multi_logloss: 1.00461	validation's multi_logloss: 1.01266
[29]	training's multi_logloss: 1.00461	validation's multi_logloss: 1.01266
[30]	training's multi_logloss: 1.00429	validation's multi_logloss: 1.01233
[31]	training's multi_logloss: 1.00429	validation's multi_logloss: 1.01233
[32]	training's multi_logloss: 1.00401	validation's multi_logloss: 1.0124
[33]	training's multi_logloss: 1.00401	validation's multi_logloss: 1.0124
[34]	training's multi_logloss: 1.00401	validation's multi_logloss: 1.0124
[35]	training's multi_logloss: 1.00401	validation's multi_logloss: 1.0124
[36]	training's multi_logloss: 1.00401	validation's multi_logloss: 1.0124
[37]	training's multi_logloss: 1.00376	validation's multi_logloss: 1.01224
[38]	training's multi_logloss: 1.00376	validation's multi_logloss: 1.01224
[39]	training's multi_logloss: 1.00376	validation's multi_logloss: 1.01224
[40]	training's multi_logloss: 1.00313	validation's multi_logloss: 1.01191
[41]	training's multi_logloss: 1.00313	validation's multi_logloss: 1.01191
[42]	training's multi_logloss: 1.00313	validation's multi_logloss: 1.01191
[43]	training's multi_logloss: 1.00313	validation's multi_logloss: 1.01191
[44]	training's multi_logloss: 1.00313	validation's multi_logloss: 1.01191
[45]	training's multi_logloss: 1.00313	validation's multi_logloss: 1.01191
[46]	training's multi_logloss: 1.00313	validation's multi_logloss: 1.01191
[47]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.01158
[48]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.01158
[49]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.01158
[50]	training's multi_logloss: 1.00233	validation's multi_logloss: 1.01149
[51]	training's multi_logloss: 1.00233	validation's multi_logloss: 1.01149
[52]	training's multi_logloss: 1.00233	validation's multi_logloss: 1.01149
[53]	training's multi_logloss: 1.00233	validation's multi_logloss: 1.01149
[54]	training's multi_logloss: 1.00211	validation's multi_logloss: 1.01133
[55]	training's multi_logloss: 1.00211	validation's multi_logloss: 1.01133
[56]	training's multi_logloss: 1.00211	validation's multi_logloss: 1.01133
[57]	training's multi_logloss: 1.00211	validation's multi_logloss: 1.01133
[58]	training's multi_logloss: 1.00211	validation's multi_logloss: 1.01133
[59]	training's multi_logloss: 1.00211	validation's multi_logloss: 1.01133
[60]	training's multi_logloss: 1.00211	validation's multi_logloss: 1.01133
[61]	training's multi_logloss: 1.00211	validation's multi_logloss: 1.01133
[62]	training's multi_logloss: 1.00211	validation's multi_logloss: 1.01133
[63]	training's multi_logloss: 1.00211	validation's multi_logloss: 1.01133
[64]	training's multi_logloss: 1.00211	validation's multi_logloss: 1.01133
[65]	training's multi_logloss: 1.00185	validation's multi_logloss: 1.01109
[66]	training's multi_logloss: 1.00159	validation's multi_logloss: 1.01102
[67]	training's multi_logloss: 1.00159	validation's multi_logloss: 1.01102
[68]	training's multi_logloss: 1.00159	validation's multi_logloss: 1.01102
[69]	training's multi_logloss: 1.00159	validation's multi_logloss: 1.01102
[70]	training's multi_logloss: 1.00159	validation's multi_logloss: 1.01102
[71]	training's multi_logloss: 1.00159	validation's multi_logloss: 1.01102
[72]	training's multi_logloss: 1.00159	validation's multi_logloss: 1.01102
[73]	training's multi_logloss: 1.00159	validation's multi_logloss: 1.01102
[74]	training's multi_logloss: 1.00159	validation's multi_logloss: 1.01102
[75]	training's multi_logloss: 1.00159	validation's multi_logloss: 1.01102
[76]	training's multi_logloss: 1.00159	validation's multi_logloss: 1.01102
[77]	training's multi_logloss: 1.00159	validation's multi_logloss: 1.01102
[78]	training's multi_logloss: 1.00134	validation's multi_logloss: 1.01079
[79]	training's multi_logloss: 1.00134	validation's multi_logloss: 1.01079
[80]	training's multi_logloss: 1.00134	validation's multi_logloss: 1.01079
[81]	training's multi_logloss: 1.00134	validation's multi_logloss: 1.01079
[82]	training's multi_logloss: 1.00134	validation's multi_logloss: 1.01079
[83]	training's multi_logloss: 1.00134	validation's multi_logloss: 1.01079
[84]	training's multi_logloss: 1.00134	validation's multi_logloss: 1.01079
[85]	training's multi_logloss: 1.00134	validation's multi_logloss: 1.01079
[86]	training's multi_logloss: 1.00134	validation's multi_logloss: 1.01079
[87]	training's multi_logloss: 1.00134	validation's multi_logloss: 1.01079
[88]	training's multi_logloss: 1.00134	validation's multi_logloss: 1.01079
[89]	training's multi_logloss: 1.00134	validation's multi_logloss: 1.01079
[90]	training's multi_logloss: 1.00134	validation's multi_logloss: 1.01079
[91]	training's multi_logloss: 1.00134	validation's multi_logloss: 1.01079
[92]	training's multi_logloss: 1.00134	validation's multi_logloss: 1.01079
[93]	training's multi_logloss: 1.00134	validation's multi_logloss: 1.01079
[94]	training's multi_logloss: 1.00134	validation's multi_logloss: 1.01079
[95]	training's multi_logloss: 1.00134	validation's multi_logloss: 1.01079
[96]	training's multi_logloss: 1.00134	validation's multi_logloss: 1.01079
[97]	training's multi_logloss: 1.00134	validation's multi_logloss: 1.01079
[98]	training's multi_logloss: 1.00113	validation's multi_logloss: 1.01074
[99]	training's multi_logloss: 1.00113	validation's multi_logloss: 1.01074
[100]	training's multi_logloss: 1.00113	validation's multi_logloss: 1.01074
Did not meet early stopping. Best iteration is:
[98]	training's multi_logloss: 1.00113	validation's multi_logloss: 1.01074
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=5.280319875670063, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.280319875670063
[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04889	validation's multi_logloss: 1.04913
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.04001	validation's multi_logloss: 1.0402
[3]	training's multi_logloss: 1.03255	validation's multi_logloss: 1.03273
[4]	training's multi_logloss: 1.02657	validation's multi_logloss: 1.02607
[5]	training's multi_logloss: 1.02182	validation's multi_logloss: 1.02116
[6]	training's multi_logloss: 1.01771	validation's multi_logloss: 1.0171
[7]	training's multi_logloss: 1.01423	validation's multi_logloss: 1.01357
[8]	training's multi_logloss: 1.01156	validation's multi_logloss: 1.01133
[9]	training's multi_logloss: 1.00942	validation's multi_logloss: 1.00974
[10]	training's multi_logloss: 1.00798	validation's multi_logloss: 1.00848
[11]	training's multi_logloss: 1.00597	validation's multi_logloss: 1.00638
[12]	training's multi_logloss: 1.00408	validation's multi_logloss: 1.00481
[13]	training's multi_logloss: 1.00252	validation's multi_logloss: 1.00355
[14]	training's multi_logloss: 1.00164	validation's multi_logloss: 1.00284
[15]	training's multi_logloss: 1.0008	validation's multi_logloss: 1.00197
[16]	training's multi_logloss: 0.999908	validation's multi_logloss: 1.0012
[17]	training's multi_logloss: 0.999165	validation's multi_logloss: 1.00036
[18]	training's multi_logloss: 0.998643	validation's multi_logloss: 0.999997
[19]	training's multi_logloss: 0.998177	validation's multi_logloss: 0.99971
[20]	training's multi_logloss: 0.997632	validation's multi_logloss: 0.999229
[21]	training's multi_logloss: 0.997429	validation's multi_logloss: 0.999133
[22]	training's multi_logloss: 0.996924	validation's multi_logloss: 0.998659
[23]	training's multi_logloss: 0.99667	validation's multi_logloss: 0.998362
[24]	training's multi_logloss: 0.99667	validation's multi_logloss: 0.998362
[25]	training's multi_logloss: 0.996116	validation's multi_logloss: 0.997912
[26]	training's multi_logloss: 0.995922	validation's multi_logloss: 0.997774
[27]	training's multi_logloss: 0.995922	validation's multi_logloss: 0.997774
[28]	training's multi_logloss: 0.995922	validation's multi_logloss: 0.997774
[29]	training's multi_logloss: 0.995922	validation's multi_logloss: 0.997774
[30]	training's multi_logloss: 0.995922	validation's multi_logloss: 0.997774
[31]	training's multi_logloss: 0.995922	validation's multi_logloss: 0.997774
[32]	training's multi_logloss: 0.995922	validation's multi_logloss: 0.997774
[33]	training's multi_logloss: 0.995922	validation's multi_logloss: 0.997774
[34]	training's multi_logloss: 0.995922	validation's multi_logloss: 0.997774
[35]	training's multi_logloss: 0.995922	validation's multi_logloss: 0.997774
[36]	training's multi_logloss: 0.995922	validation's multi_logloss: 0.997774
[37]	training's multi_logloss: 0.995922	validation's multi_logloss: 0.997774
[38]	training's multi_logloss: 0.995922	validation's multi_logloss: 0.997774
[39]	training's multi_logloss: 0.995922	validation's multi_logloss: 0.997774
[40]	training's multi_logloss: 0.995628	validation's multi_logloss: 0.997627
[41]	training's multi_logloss: 0.995628	validation's multi_logloss: 0.997627
[42]	training's multi_logloss: 0.995628	validation's multi_logloss: 0.997627
[43]	training's multi_logloss: 0.995628	validation's multi_logloss: 0.997627
[44]	training's multi_logloss: 0.995628	validation's multi_logloss: 0.997627
[45]	training's multi_logloss: 0.995628	validation's multi_logloss: 0.997627
[46]	training's multi_logloss: 0.995628	validation's multi_logloss: 0.997627
[47]	training's multi_logloss: 0.995354	validation's multi_logloss: 0.997555
[48]	training's multi_logloss: 0.995354	validation's multi_logloss: 0.997555
[49]	training's multi_logloss: 0.995354	validation's multi_logloss: 0.997555
[50]	training's multi_logloss: 0.995354	validation's multi_logloss: 0.997555
[51]	training's multi_logloss: 0.995354	validation's multi_logloss: 0.997555
[52]	training's multi_logloss: 0.995354	validation's multi_logloss: 0.997555
[53]	training's multi_logloss: 0.995354	validation's multi_logloss: 0.997555
[54]	training's multi_logloss: 0.995354	validation's multi_logloss: 0.997555
[55]	training's multi_logloss: 0.995354	validation's multi_logloss: 0.997555
[56]	training's multi_logloss: 0.995354	validation's multi_logloss: 0.997555
[57]	training's multi_logloss: 0.9952	validation's multi_logloss: 0.997275
[58]	training's multi_logloss: 0.9952	validation's multi_logloss: 0.997275
[59]	training's multi_logloss: 0.9952	validation's multi_logloss: 0.997275
[60]	training's multi_logloss: 0.9952	validation's multi_logloss: 0.997275
[61]	training's multi_logloss: 0.9952	validation's multi_logloss: 0.997275
[62]	training's multi_logloss: 0.9952	validation's multi_logloss: 0.997275
[63]	training's multi_logloss: 0.9952	validation's multi_logloss: 0.997275
[64]	training's multi_logloss: 0.9952	validation's multi_logloss: 0.997275
[65]	training's multi_logloss: 0.995	validation's multi_logloss: 0.997246
[66]	training's multi_logloss: 0.994796	validation's multi_logloss: 0.997112
[67]	training's multi_logloss: 0.994796	validation's multi_logloss: 0.997112
[68]	training's multi_logloss: 0.994796	validation's multi_logloss: 0.997112
[69]	training's multi_logloss: 0.994796	validation's multi_logloss: 0.997112
[70]	training's multi_logloss: 0.994796	validation's multi_logloss: 0.997112
[71]	training's multi_logloss: 0.994796	validation's multi_logloss: 0.997112
[72]	training's multi_logloss: 0.994796	validation's multi_logloss: 0.997112
[73]	training's multi_logloss: 0.994796	validation's multi_logloss: 0.997112
[74]	training's multi_logloss: 0.994796	validation's multi_logloss: 0.997112
[75]	training's multi_logloss: 0.994796	validation's multi_logloss: 0.997112
[76]	training's multi_logloss: 0.994796	validation's multi_logloss: 0.997112
[77]	training's multi_logloss: 0.994796	validation's multi_logloss: 0.997112
[78]	training's multi_logloss: 0.994621	validation's multi_logloss: 0.996857
[79]	training's multi_logloss: 0.994621	validation's multi_logloss: 0.996857
[80]	training's multi_logloss: 0.994621	validation's multi_logloss: 0.996857
[81]	training's multi_logloss: 0.994621	validation's multi_logloss: 0.996857
[82]	training's multi_logloss: 0.994621	validation's multi_logloss: 0.996857
[83]	training's multi_logloss: 0.994621	validation's multi_logloss: 0.996857
[84]	training's multi_logloss: 0.994621	validation's multi_logloss: 0.996857
[85]	training's multi_logloss: 0.994621	validation's multi_logloss: 0.996857
[86]	training's multi_logloss: 0.994621	validation's multi_logloss: 0.996857
[87]	training's multi_logloss: 0.994621	validation's multi_logloss: 0.996857
[88]	training's multi_logloss: 0.994621	validation's multi_logloss: 0.996857
[89]	training's multi_logloss: 0.994621	validation's multi_logloss: 0.996857
[90]	training's multi_logloss: 0.994621	validation's multi_logloss: 0.996857
[91]	training's multi_logloss: 0.994432	validation's multi_logloss: 0.996748
[92]	training's multi_logloss: 0.994432	validation's multi_logloss: 0.996748
[93]	training's multi_logloss: 0.994432	validation's multi_logloss: 0.996748
[94]	training's multi_logloss: 0.994432	validation's multi_logloss: 0.996748
[95]	training's multi_logloss: 0.994432	validation's multi_logloss: 0.996748
[96]	training's multi_logloss: 0.994432	validation's multi_logloss: 0.996748
[97]	training's multi_logloss: 0.994432	validation's multi_logloss: 0.996748
[98]	training's multi_logloss: 0.994432	validation's multi_logloss: 0.996748
[99]	training's multi_logloss: 0.994432	validation's multi_logloss: 0.996748
[100]	training's multi_logloss: 0.994432	validation's multi_logloss: 0.996748
Did not meet early stopping. Best iteration is:
[91]	training's multi_logloss: 0.994432	validation's multi_logloss: 0.996748
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=5.280319875670063, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.280319875670063
[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18525	validation's multi_logloss: 1.18547
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.13712	validation's multi_logloss: 1.13845
[3]	training's multi_logloss: 1.10329	validation's multi_logloss: 1.10597
[4]	training's multi_logloss: 1.0787	validation's multi_logloss: 1.08148
[5]	training's multi_logloss: 1.06098	validation's multi_logloss: 1.06375
[6]	training's multi_logloss: 1.05494	validation's multi_logloss: 1.05767
[7]	training's multi_logloss: 1.04201	validation's multi_logloss: 1.04481
[8]	training's multi_logloss: 1.03815	validation's multi_logloss: 1.04057
[9]	training's multi_logloss: 1.03463	validation's multi_logloss: 1.03699
[10]	training's multi_logloss: 1.02658	validation's multi_logloss: 1.02934
[11]	training's multi_logloss: 1.02381	validation's multi_logloss: 1.02665
[12]	training's multi_logloss: 1.02118	validation's multi_logloss: 1.02407
[13]	training's multi_logloss: 1.01923	validation's multi_logloss: 1.02214
[14]	training's multi_logloss: 1.01729	validation's multi_logloss: 1.02029
[15]	training's multi_logloss: 1.01541	validation's multi_logloss: 1.01874
[16]	training's multi_logloss: 1.01359	validation's multi_logloss: 1.01701
[17]	training's multi_logloss: 1.01193	validation's multi_logloss: 1.01558
[18]	training's multi_logloss: 1.01036	validation's multi_logloss: 1.01399
[19]	training's multi_logloss: 1.00908	validation's multi_logloss: 1.01261
[20]	training's multi_logloss: 1.00585	validation's multi_logloss: 1.00922
[21]	training's multi_logloss: 1.0048	validation's multi_logloss: 1.00798
[22]	training's multi_logloss: 1.00381	validation's multi_logloss: 1.00714
[23]	training's multi_logloss: 1.0029	validation's multi_logloss: 1.00636
[24]	training's multi_logloss: 1.00206	validation's multi_logloss: 1.00564
[25]	training's multi_logloss: 1.00129	validation's multi_logloss: 1.00484
[26]	training's multi_logloss: 1.00057	validation's multi_logloss: 1.00418
[27]	training's multi_logloss: 1.00015	validation's multi_logloss: 1.00392
[28]	training's multi_logloss: 0.999494	validation's multi_logloss: 1.00325
[29]	training's multi_logloss: 0.997695	validation's multi_logloss: 1.00152
[30]	training's multi_logloss: 0.997375	validation's multi_logloss: 1.00119
[31]	training's multi_logloss: 0.997075	validation's multi_logloss: 1.0009
[32]	training's multi_logloss: 0.996452	validation's multi_logloss: 1.00025
[33]	training's multi_logloss: 0.99591	validation's multi_logloss: 0.999734
[34]	training's multi_logloss: 0.995599	validation's multi_logloss: 0.999476
[35]	training's multi_logloss: 0.995599	validation's multi_logloss: 0.999476
[36]	training's multi_logloss: 0.995352	validation's multi_logloss: 0.999234
[37]	training's multi_logloss: 0.995067	validation's multi_logloss: 0.998838
[38]	training's multi_logloss: 0.995067	validation's multi_logloss: 0.998838
[39]	training's multi_logloss: 0.995067	validation's multi_logloss: 0.998838
[40]	training's multi_logloss: 0.995067	validation's multi_logloss: 0.998838
[41]	training's multi_logloss: 0.995067	validation's multi_logloss: 0.998838
[42]	training's multi_logloss: 0.994802	validation's multi_logloss: 0.998687
[43]	training's multi_logloss: 0.994802	validation's multi_logloss: 0.998687
[44]	training's multi_logloss: 0.994802	validation's multi_logloss: 0.998687
[45]	training's multi_logloss: 0.994522	validation's multi_logloss: 0.998431
[46]	training's multi_logloss: 0.994522	validation's multi_logloss: 0.998431
[47]	training's multi_logloss: 0.994285	validation's multi_logloss: 0.99814
[48]	training's multi_logloss: 0.994285	validation's multi_logloss: 0.99814
[49]	training's multi_logloss: 0.994285	validation's multi_logloss: 0.99814
[50]	training's multi_logloss: 0.994285	validation's multi_logloss: 0.99814
[51]	training's multi_logloss: 0.994065	validation's multi_logloss: 0.99797
[52]	training's multi_logloss: 0.994065	validation's multi_logloss: 0.99797
[53]	training's multi_logloss: 0.994065	validation's multi_logloss: 0.99797
[54]	training's multi_logloss: 0.994065	validation's multi_logloss: 0.99797
[55]	training's multi_logloss: 0.994065	validation's multi_logloss: 0.99797
[56]	training's multi_logloss: 0.994065	validation's multi_logloss: 0.99797
[57]	training's multi_logloss: 0.993801	validation's multi_logloss: 0.997674
[58]	training's multi_logloss: 0.993596	validation's multi_logloss: 0.997601
[59]	training's multi_logloss: 0.993596	validation's multi_logloss: 0.997601
[60]	training's multi_logloss: 0.993596	validation's multi_logloss: 0.997601
[61]	training's multi_logloss: 0.993596	validation's multi_logloss: 0.997601
[62]	training's multi_logloss: 0.99334	validation's multi_logloss: 0.997335
[63]	training's multi_logloss: 0.99334	validation's multi_logloss: 0.997335
[64]	training's multi_logloss: 0.99334	validation's multi_logloss: 0.997335
[65]	training's multi_logloss: 0.99334	validation's multi_logloss: 0.997335
[66]	training's multi_logloss: 0.99334	validation's multi_logloss: 0.997335
[67]	training's multi_logloss: 0.99334	validation's multi_logloss: 0.997335
[68]	training's multi_logloss: 0.99334	validation's multi_logloss: 0.997335
[69]	training's multi_logloss: 0.99334	validation's multi_logloss: 0.997335
[70]	training's multi_logloss: 0.99334	validation's multi_logloss: 0.997335
[71]	training's multi_logloss: 0.99334	validation's multi_logloss: 0.997335
[72]	training's multi_logloss: 0.99334	validation's multi_logloss: 0.997335
[73]	training's multi_logloss: 0.993088	validation's multi_logloss: 0.996992
[74]	training's multi_logloss: 0.993088	validation's multi_logloss: 0.996992
[75]	training's multi_logloss: 0.993088	validation's multi_logloss: 0.996992
[76]	training's multi_logloss: 0.993088	validation's multi_logloss: 0.996992
[77]	training's multi_logloss: 0.993088	validation's multi_logloss: 0.996992
[78]	training's multi_logloss: 0.993088	validation's multi_logloss: 0.996992
[79]	training's multi_logloss: 0.993088	validation's multi_logloss: 0.996992
[80]	training's multi_logloss: 0.993088	validation's multi_logloss: 0.996992
[81]	training's multi_logloss: 0.993088	validation's multi_logloss: 0.996992
[82]	training's multi_logloss: 0.993088	validation's multi_logloss: 0.996992
[83]	training's multi_logloss: 0.993088	validation's multi_logloss: 0.996992
[84]	training's multi_logloss: 0.993088	validation's multi_logloss: 0.996992
[85]	training's multi_logloss: 0.993088	validation's multi_logloss: 0.996992
[86]	training's multi_logloss: 0.993088	validation's multi_logloss: 0.996992
[87]	training's multi_logloss: 0.993088	validation's multi_logloss: 0.996992
[88]	training's multi_logloss: 0.993088	validation's multi_logloss: 0.996992
[89]	training's multi_logloss: 0.993088	validation's multi_logloss: 0.996992
[90]	training's multi_logloss: 0.993088	validation's multi_logloss: 0.996992
[91]	training's multi_logloss: 0.993088	validation's multi_logloss: 0.996992
[92]	training's multi_logloss: 0.993088	validation's multi_logloss: 0.996992
[93]	training's multi_logloss: 0.992634	validation's multi_logloss: 0.996665
[94]	training's multi_logloss: 0.992634	validation's multi_logloss: 0.996665
[95]	training's multi_logloss: 0.992457	validation's multi_logloss: 0.996586
[96]	training's multi_logloss: 0.992457	validation's multi_logloss: 0.996586
[97]	training's multi_logloss: 0.992457	validation's multi_logloss: 0.996586
[98]	training's multi_logloss: 0.992457	validation's multi_logloss: 0.996586
[99]	training's multi_logloss: 0.992457	validation's multi_logloss: 0.996586
[100]	training's multi_logloss: 0.992457	validation's multi_logloss: 0.996586
Did not meet early stopping. Best iteration is:
[95]	training's multi_logloss: 0.992457	validation's multi_logloss: 0.996586
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=5.280319875670063, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.280319875670063
[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04789	validation's multi_logloss: 1.05009
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03864	validation's multi_logloss: 1.04291
[3]	training's multi_logloss: 1.03082	validation's multi_logloss: 1.03672
[4]	training's multi_logloss: 1.02418	validation's multi_logloss: 1.03194
[5]	training's multi_logloss: 1.0186	validation's multi_logloss: 1.02792
[6]	training's multi_logloss: 1.01396	validation's multi_logloss: 1.02511
[7]	training's multi_logloss: 1.01008	validation's multi_logloss: 1.02267
[8]	training's multi_logloss: 1.00669	validation's multi_logloss: 1.02071
[9]	training's multi_logloss: 1.00401	validation's multi_logloss: 1.01867
[10]	training's multi_logloss: 1.00213	validation's multi_logloss: 1.01765
[11]	training's multi_logloss: 1.00042	validation's multi_logloss: 1.01658
[12]	training's multi_logloss: 0.99886	validation's multi_logloss: 1.01583
[13]	training's multi_logloss: 0.997553	validation's multi_logloss: 1.01518
[14]	training's multi_logloss: 0.996428	validation's multi_logloss: 1.01467
[15]	training's multi_logloss: 0.995512	validation's multi_logloss: 1.01422
[16]	training's multi_logloss: 0.995224	validation's multi_logloss: 1.01409
[17]	training's multi_logloss: 0.994561	validation's multi_logloss: 1.01371
[18]	training's multi_logloss: 0.993359	validation's multi_logloss: 1.01324
[19]	training's multi_logloss: 0.992811	validation's multi_logloss: 1.01286
[20]	training's multi_logloss: 0.992328	validation's multi_logloss: 1.01251
[21]	training's multi_logloss: 0.991603	validation's multi_logloss: 1.01211
[22]	training's multi_logloss: 0.991136	validation's multi_logloss: 1.01172
[23]	training's multi_logloss: 0.990897	validation's multi_logloss: 1.01159
[24]	training's multi_logloss: 0.990468	validation's multi_logloss: 1.01139
[25]	training's multi_logloss: 0.990033	validation's multi_logloss: 1.01131
[26]	training's multi_logloss: 0.990033	validation's multi_logloss: 1.01131
[27]	training's multi_logloss: 0.990033	validation's multi_logloss: 1.01131
[28]	training's multi_logloss: 0.990033	validation's multi_logloss: 1.01131
[29]	training's multi_logloss: 0.990033	validation's multi_logloss: 1.01131
[30]	training's multi_logloss: 0.990033	validation's multi_logloss: 1.01131
[31]	training's multi_logloss: 0.990033	validation's multi_logloss: 1.01131
[32]	training's multi_logloss: 0.989805	validation's multi_logloss: 1.01125
[33]	training's multi_logloss: 0.989624	validation's multi_logloss: 1.01121
[34]	training's multi_logloss: 0.989624	validation's multi_logloss: 1.01121
[35]	training's multi_logloss: 0.989421	validation's multi_logloss: 1.011
[36]	training's multi_logloss: 0.989421	validation's multi_logloss: 1.011
[37]	training's multi_logloss: 0.989421	validation's multi_logloss: 1.011
[38]	training's multi_logloss: 0.989421	validation's multi_logloss: 1.011
[39]	training's multi_logloss: 0.989421	validation's multi_logloss: 1.011
[40]	training's multi_logloss: 0.989421	validation's multi_logloss: 1.011
[41]	training's multi_logloss: 0.989185	validation's multi_logloss: 1.0109
[42]	training's multi_logloss: 0.989185	validation's multi_logloss: 1.0109
[43]	training's multi_logloss: 0.989185	validation's multi_logloss: 1.0109
[44]	training's multi_logloss: 0.988998	validation's multi_logloss: 1.0109
[45]	training's multi_logloss: 0.988998	validation's multi_logloss: 1.0109
[46]	training's multi_logloss: 0.988998	validation's multi_logloss: 1.0109
[47]	training's multi_logloss: 0.988998	validation's multi_logloss: 1.0109
[48]	training's multi_logloss: 0.988998	validation's multi_logloss: 1.0109
[49]	training's multi_logloss: 0.988998	validation's multi_logloss: 1.0109
[50]	training's multi_logloss: 0.988998	validation's multi_logloss: 1.0109
[51]	training's multi_logloss: 0.988998	validation's multi_logloss: 1.0109
[52]	training's multi_logloss: 0.988998	validation's multi_logloss: 1.0109
[53]	training's multi_logloss: 0.98881	validation's multi_logloss: 1.01089
[54]	training's multi_logloss: 0.98881	validation's multi_logloss: 1.01089
[55]	training's multi_logloss: 0.98881	validation's multi_logloss: 1.01089
[56]	training's multi_logloss: 0.98881	validation's multi_logloss: 1.01089
[57]	training's multi_logloss: 0.98881	validation's multi_logloss: 1.01089
[58]	training's multi_logloss: 0.98881	validation's multi_logloss: 1.01089
[59]	training's multi_logloss: 0.98881	validation's multi_logloss: 1.01089
[60]	training's multi_logloss: 0.98881	validation's multi_logloss: 1.01089
[61]	training's multi_logloss: 0.98881	validation's multi_logloss: 1.01089
[62]	training's multi_logloss: 0.98881	validation's multi_logloss: 1.01089
[63]	training's multi_logloss: 0.98881	validation's multi_logloss: 1.01089
[64]	training's multi_logloss: 0.98881	validation's multi_logloss: 1.01089
[65]	training's multi_logloss: 0.988607	validation's multi_logloss: 1.01085
[66]	training's multi_logloss: 0.988607	validation's multi_logloss: 1.01085
[67]	training's multi_logloss: 0.988607	validation's multi_logloss: 1.01085
[68]	training's multi_logloss: 0.988607	validation's multi_logloss: 1.01085
[69]	training's multi_logloss: 0.988607	validation's multi_logloss: 1.01085
[70]	training's multi_logloss: 0.988607	validation's multi_logloss: 1.01085
[71]	training's multi_logloss: 0.988607	validation's multi_logloss: 1.01085
[72]	training's multi_logloss: 0.988607	validation's multi_logloss: 1.01085
[73]	training's multi_logloss: 0.988607	validation's multi_logloss: 1.01085
[74]	training's multi_logloss: 0.988607	validation's multi_logloss: 1.01085
[75]	training's multi_logloss: 0.988417	validation's multi_logloss: 1.0109
[76]	training's multi_logloss: 0.988417	validation's multi_logloss: 1.0109
[77]	training's multi_logloss: 0.988417	validation's multi_logloss: 1.0109
[78]	training's multi_logloss: 0.988417	validation's multi_logloss: 1.0109
[79]	training's multi_logloss: 0.988417	validation's multi_logloss: 1.0109
[80]	training's multi_logloss: 0.988417	validation's multi_logloss: 1.0109
[81]	training's multi_logloss: 0.988417	validation's multi_logloss: 1.0109
[82]	training's multi_logloss: 0.988417	validation's multi_logloss: 1.0109
[83]	training's multi_logloss: 0.988235	validation's multi_logloss: 1.01083
[84]	training's multi_logloss: 0.988235	validation's multi_logloss: 1.01083
[85]	training's multi_logloss: 0.988235	validation's multi_logloss: 1.01083
[86]	training's multi_logloss: 0.988235	validation's multi_logloss: 1.01083
[87]	training's multi_logloss: 0.988235	validation's multi_logloss: 1.01083
[88]	training's multi_logloss: 0.988235	validation's multi_logloss: 1.01083
[89]	training's multi_logloss: 0.988235	validation's multi_logloss: 1.01083
[90]	training's multi_logloss: 0.988235	validation's multi_logloss: 1.01083
[91]	training's multi_logloss: 0.988235	validation's multi_logloss: 1.01083
[92]	training's multi_logloss: 0.988235	validation's multi_logloss: 1.01083
[93]	training's multi_logloss: 0.988235	validation's multi_logloss: 1.01083
[94]	training's multi_logloss: 0.988235	validation's multi_logloss: 1.01083
[95]	training's multi_logloss: 0.988235	validation's multi_logloss: 1.01083
[96]	training's multi_logloss: 0.988235	validation's multi_logloss: 1.01083
[97]	training's multi_logloss: 0.988235	validation's multi_logloss: 1.01083
[98]	training's multi_logloss: 0.988235	validation's multi_logloss: 1.01083
[99]	training's multi_logloss: 0.988235	validation's multi_logloss: 1.01083
[100]	training's multi_logloss: 0.988021	validation's multi_logloss: 1.01066
Did not meet early stopping. Best iteration is:
[100]	training's multi_logloss: 0.988021	validation's multi_logloss: 1.01066
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=5.280319875670063, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.280319875670063
[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04828	validation's multi_logloss: 1.04938
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03932	validation's multi_logloss: 1.04111
[3]	training's multi_logloss: 1.03141	validation's multi_logloss: 1.03447
[4]	training's multi_logloss: 1.0253	validation's multi_logloss: 1.02943
[5]	training's multi_logloss: 1.01996	validation's multi_logloss: 1.02446
[6]	training's multi_logloss: 1.01559	validation's multi_logloss: 1.02076
[7]	training's multi_logloss: 1.01219	validation's multi_logloss: 1.01803
[8]	training's multi_logloss: 1.00931	validation's multi_logloss: 1.01594
[9]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.01417
[10]	training's multi_logloss: 1.00479	validation's multi_logloss: 1.013
[11]	training's multi_logloss: 1.00316	validation's multi_logloss: 1.01191
[12]	training's multi_logloss: 1.00161	validation's multi_logloss: 1.01082
[13]	training's multi_logloss: 1.00033	validation's multi_logloss: 1.00985
[14]	training's multi_logloss: 0.999509	validation's multi_logloss: 1.00903
[15]	training's multi_logloss: 0.998737	validation's multi_logloss: 1.00877
[16]	training's multi_logloss: 0.998002	validation's multi_logloss: 1.00833
[17]	training's multi_logloss: 0.99707	validation's multi_logloss: 1.00751
[18]	training's multi_logloss: 0.996425	validation's multi_logloss: 1.00706
[19]	training's multi_logloss: 0.99616	validation's multi_logloss: 1.0069
[20]	training's multi_logloss: 0.995948	validation's multi_logloss: 1.0067
[21]	training's multi_logloss: 0.995535	validation's multi_logloss: 1.00674
[22]	training's multi_logloss: 0.995267	validation's multi_logloss: 1.00642
[23]	training's multi_logloss: 0.995053	validation's multi_logloss: 1.00634
[24]	training's multi_logloss: 0.994885	validation's multi_logloss: 1.0062
[25]	training's multi_logloss: 0.994885	validation's multi_logloss: 1.0062
[26]	training's multi_logloss: 0.994885	validation's multi_logloss: 1.0062
[27]	training's multi_logloss: 0.994885	validation's multi_logloss: 1.0062
[28]	training's multi_logloss: 0.994885	validation's multi_logloss: 1.0062
[29]	training's multi_logloss: 0.994885	validation's multi_logloss: 1.0062
[30]	training's multi_logloss: 0.99469	validation's multi_logloss: 1.00606
[31]	training's multi_logloss: 0.99469	validation's multi_logloss: 1.00606
[32]	training's multi_logloss: 0.99469	validation's multi_logloss: 1.00606
[33]	training's multi_logloss: 0.99469	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 0.99469	validation's multi_logloss: 1.00606
[35]	training's multi_logloss: 0.99469	validation's multi_logloss: 1.00606
[36]	training's multi_logloss: 0.99469	validation's multi_logloss: 1.00606
[37]	training's multi_logloss: 0.99469	validation's multi_logloss: 1.00606
[38]	training's multi_logloss: 0.99469	validation's multi_logloss: 1.00606
[39]	training's multi_logloss: 0.99469	validation's multi_logloss: 1.00606
[40]	training's multi_logloss: 0.994174	validation's multi_logloss: 1.00579
[41]	training's multi_logloss: 0.994174	validation's multi_logloss: 1.00579
[42]	training's multi_logloss: 0.994174	validation's multi_logloss: 1.00579
[43]	training's multi_logloss: 0.994174	validation's multi_logloss: 1.00579
[44]	training's multi_logloss: 0.994174	validation's multi_logloss: 1.00579
[45]	training's multi_logloss: 0.993939	validation's multi_logloss: 1.00573
[46]	training's multi_logloss: 0.993939	validation's multi_logloss: 1.00573
[47]	training's multi_logloss: 0.993939	validation's multi_logloss: 1.00573
[48]	training's multi_logloss: 0.993754	validation's multi_logloss: 1.00575
[49]	training's multi_logloss: 0.993754	validation's multi_logloss: 1.00575
[50]	training's multi_logloss: 0.993532	validation's multi_logloss: 1.00568
[51]	training's multi_logloss: 0.993532	validation's multi_logloss: 1.00568
[52]	training's multi_logloss: 0.993532	validation's multi_logloss: 1.00568
[53]	training's multi_logloss: 0.993532	validation's multi_logloss: 1.00568
[54]	training's multi_logloss: 0.993343	validation's multi_logloss: 1.00563
[55]	training's multi_logloss: 0.993343	validation's multi_logloss: 1.00563
[56]	training's multi_logloss: 0.993343	validation's multi_logloss: 1.00563
[57]	training's multi_logloss: 0.993343	validation's multi_logloss: 1.00563
[58]	training's multi_logloss: 0.993343	validation's multi_logloss: 1.00563
[59]	training's multi_logloss: 0.993343	validation's multi_logloss: 1.00563
[60]	training's multi_logloss: 0.993343	validation's multi_logloss: 1.00563
[61]	training's multi_logloss: 0.993343	validation's multi_logloss: 1.00563
[62]	training's multi_logloss: 0.993146	validation's multi_logloss: 1.00551
[63]	training's multi_logloss: 0.993146	validation's multi_logloss: 1.00551
[64]	training's multi_logloss: 0.993146	validation's multi_logloss: 1.00551
[65]	training's multi_logloss: 0.993146	validation's multi_logloss: 1.00551
[66]	training's multi_logloss: 0.992966	validation's multi_logloss: 1.00544
[67]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[68]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[69]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[70]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[71]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[72]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[73]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[74]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[75]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[76]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[77]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[78]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[79]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[80]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[81]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[82]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[83]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[84]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[85]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[86]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[87]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
Early stopping, best iteration is:
[67]	training's multi_logloss: 0.99276	validation's multi_logloss: 1.00526
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=5.330042347420331, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.330042347420331
[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04964	validation's multi_logloss: 1.04986
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.04119	validation's multi_logloss: 1.04135
[3]	training's multi_logloss: 1.03399	validation's multi_logloss: 1.03414
[4]	training's multi_logloss: 1.02814	validation's multi_logloss: 1.02765
[5]	training's multi_logloss: 1.02345	validation's multi_logloss: 1.0228
[6]	training's multi_logloss: 1.01914	validation's multi_logloss: 1.01858
[7]	training's multi_logloss: 1.01584	validation's multi_logloss: 1.01549
[8]	training's multi_logloss: 1.01315	validation's multi_logloss: 1.01321
[9]	training's multi_logloss: 1.01079	validation's multi_logloss: 1.01131
[10]	training's multi_logloss: 1.00888	validation's multi_logloss: 1.00949
[11]	training's multi_logloss: 1.0071	validation's multi_logloss: 1.00784
[12]	training's multi_logloss: 1.00522	validation's multi_logloss: 1.00626
[13]	training's multi_logloss: 1.00365	validation's multi_logloss: 1.00498
[14]	training's multi_logloss: 1.00274	validation's multi_logloss: 1.00403
[15]	training's multi_logloss: 1.00171	validation's multi_logloss: 1.00298
[16]	training's multi_logloss: 1.00076	validation's multi_logloss: 1.00241
[17]	training's multi_logloss: 1.00001	validation's multi_logloss: 1.00148
[18]	training's multi_logloss: 0.999467	validation's multi_logloss: 1.0011
[19]	training's multi_logloss: 0.999012	validation's multi_logloss: 1.00067
[20]	training's multi_logloss: 0.998406	validation's multi_logloss: 1.0003
[21]	training's multi_logloss: 0.998222	validation's multi_logloss: 1.00011
[22]	training's multi_logloss: 0.997733	validation's multi_logloss: 0.999649
[23]	training's multi_logloss: 0.997483	validation's multi_logloss: 0.999354
[24]	training's multi_logloss: 0.997483	validation's multi_logloss: 0.999354
[25]	training's multi_logloss: 0.99704	validation's multi_logloss: 0.998992
[26]	training's multi_logloss: 0.996854	validation's multi_logloss: 0.998858
[27]	training's multi_logloss: 0.996854	validation's multi_logloss: 0.998858
[28]	training's multi_logloss: 0.996854	validation's multi_logloss: 0.998858
[29]	training's multi_logloss: 0.996854	validation's multi_logloss: 0.998858
[30]	training's multi_logloss: 0.996854	validation's multi_logloss: 0.998858
[31]	training's multi_logloss: 0.996854	validation's multi_logloss: 0.998858
[32]	training's multi_logloss: 0.996854	validation's multi_logloss: 0.998858
[33]	training's multi_logloss: 0.996854	validation's multi_logloss: 0.998858
[34]	training's multi_logloss: 0.996854	validation's multi_logloss: 0.998858
[35]	training's multi_logloss: 0.996854	validation's multi_logloss: 0.998858
[36]	training's multi_logloss: 0.996669	validation's multi_logloss: 0.998761
[37]	training's multi_logloss: 0.996669	validation's multi_logloss: 0.998761
[38]	training's multi_logloss: 0.996669	validation's multi_logloss: 0.998761
[39]	training's multi_logloss: 0.996669	validation's multi_logloss: 0.998761
[40]	training's multi_logloss: 0.996371	validation's multi_logloss: 0.998601
[41]	training's multi_logloss: 0.996371	validation's multi_logloss: 0.998601
[42]	training's multi_logloss: 0.996371	validation's multi_logloss: 0.998601
[43]	training's multi_logloss: 0.996205	validation's multi_logloss: 0.998504
[44]	training's multi_logloss: 0.996205	validation's multi_logloss: 0.998504
[45]	training's multi_logloss: 0.996005	validation's multi_logloss: 0.998331
[46]	training's multi_logloss: 0.996005	validation's multi_logloss: 0.998331
[47]	training's multi_logloss: 0.995736	validation's multi_logloss: 0.998256
[48]	training's multi_logloss: 0.995736	validation's multi_logloss: 0.998256
[49]	training's multi_logloss: 0.995736	validation's multi_logloss: 0.998256
[50]	training's multi_logloss: 0.995736	validation's multi_logloss: 0.998256
[51]	training's multi_logloss: 0.995736	validation's multi_logloss: 0.998256
[52]	training's multi_logloss: 0.995736	validation's multi_logloss: 0.998256
[53]	training's multi_logloss: 0.995736	validation's multi_logloss: 0.998256
[54]	training's multi_logloss: 0.995736	validation's multi_logloss: 0.998256
[55]	training's multi_logloss: 0.995736	validation's multi_logloss: 0.998256
[56]	training's multi_logloss: 0.995736	validation's multi_logloss: 0.998256
[57]	training's multi_logloss: 0.995736	validation's multi_logloss: 0.998256
[58]	training's multi_logloss: 0.995736	validation's multi_logloss: 0.998256
[59]	training's multi_logloss: 0.995736	validation's multi_logloss: 0.998256
[60]	training's multi_logloss: 0.995736	validation's multi_logloss: 0.998256
[61]	training's multi_logloss: 0.995578	validation's multi_logloss: 0.99821
[62]	training's multi_logloss: 0.995578	validation's multi_logloss: 0.99821
[63]	training's multi_logloss: 0.995578	validation's multi_logloss: 0.99821
[64]	training's multi_logloss: 0.995578	validation's multi_logloss: 0.99821
[65]	training's multi_logloss: 0.995399	validation's multi_logloss: 0.998186
[66]	training's multi_logloss: 0.995183	validation's multi_logloss: 0.99804
[67]	training's multi_logloss: 0.995183	validation's multi_logloss: 0.99804
[68]	training's multi_logloss: 0.995183	validation's multi_logloss: 0.99804
[69]	training's multi_logloss: 0.995183	validation's multi_logloss: 0.99804
[70]	training's multi_logloss: 0.995183	validation's multi_logloss: 0.99804
[71]	training's multi_logloss: 0.995183	validation's multi_logloss: 0.99804
[72]	training's multi_logloss: 0.995183	validation's multi_logloss: 0.99804
[73]	training's multi_logloss: 0.995183	validation's multi_logloss: 0.99804
[74]	training's multi_logloss: 0.995183	validation's multi_logloss: 0.99804
[75]	training's multi_logloss: 0.995183	validation's multi_logloss: 0.99804
[76]	training's multi_logloss: 0.995183	validation's multi_logloss: 0.99804
[77]	training's multi_logloss: 0.995183	validation's multi_logloss: 0.99804
[78]	training's multi_logloss: 0.995007	validation's multi_logloss: 0.997785
[79]	training's multi_logloss: 0.995007	validation's multi_logloss: 0.997785
[80]	training's multi_logloss: 0.995007	validation's multi_logloss: 0.997785
[81]	training's multi_logloss: 0.995007	validation's multi_logloss: 0.997785
[82]	training's multi_logloss: 0.995007	validation's multi_logloss: 0.997785
[83]	training's multi_logloss: 0.994833	validation's multi_logloss: 0.997697
[84]	training's multi_logloss: 0.994653	validation's multi_logloss: 0.997666
[85]	training's multi_logloss: 0.994653	validation's multi_logloss: 0.997666
[86]	training's multi_logloss: 0.994653	validation's multi_logloss: 0.997666
[87]	training's multi_logloss: 0.994653	validation's multi_logloss: 0.997666
[88]	training's multi_logloss: 0.994653	validation's multi_logloss: 0.997666
[89]	training's multi_logloss: 0.994653	validation's multi_logloss: 0.997666
[90]	training's multi_logloss: 0.994653	validation's multi_logloss: 0.997666
[91]	training's multi_logloss: 0.994653	validation's multi_logloss: 0.997666
[92]	training's multi_logloss: 0.994653	validation's multi_logloss: 0.997666
[93]	training's multi_logloss: 0.994653	validation's multi_logloss: 0.997666
[94]	training's multi_logloss: 0.994653	validation's multi_logloss: 0.997666
[95]	training's multi_logloss: 0.994653	validation's multi_logloss: 0.997666
[96]	training's multi_logloss: 0.994653	validation's multi_logloss: 0.997666
[97]	training's multi_logloss: 0.994653	validation's multi_logloss: 0.997666
[98]	training's multi_logloss: 0.994653	validation's multi_logloss: 0.997666
[99]	training's multi_logloss: 0.994653	validation's multi_logloss: 0.997666
[100]	training's multi_logloss: 0.994653	validation's multi_logloss: 0.997666
Did not meet early stopping. Best iteration is:
[84]	training's multi_logloss: 0.994653	validation's multi_logloss: 0.997666
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=5.330042347420331, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.330042347420331
[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18593	validation's multi_logloss: 1.18613
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.14059	validation's multi_logloss: 1.14195
[3]	training's multi_logloss: 1.10787	validation's multi_logloss: 1.11052
[4]	training's multi_logloss: 1.08359	validation's multi_logloss: 1.08635
[5]	training's multi_logloss: 1.06573	validation's multi_logloss: 1.06868
[6]	training's multi_logloss: 1.05969	validation's multi_logloss: 1.06261
[7]	training's multi_logloss: 1.04652	validation's multi_logloss: 1.04952
[8]	training's multi_logloss: 1.04243	validation's multi_logloss: 1.04515
[9]	training's multi_logloss: 1.03356	validation's multi_logloss: 1.03625
[10]	training's multi_logloss: 1.03019	validation's multi_logloss: 1.03341
[11]	training's multi_logloss: 1.02705	validation's multi_logloss: 1.03033
[12]	training's multi_logloss: 1.02463	validation's multi_logloss: 1.02787
[13]	training's multi_logloss: 1.02236	validation's multi_logloss: 1.02579
[14]	training's multi_logloss: 1.02034	validation's multi_logloss: 1.02385
[15]	training's multi_logloss: 1.0184	validation's multi_logloss: 1.02225
[16]	training's multi_logloss: 1.0165	validation's multi_logloss: 1.02043
[17]	training's multi_logloss: 1.01475	validation's multi_logloss: 1.0189
[18]	training's multi_logloss: 1.01311	validation's multi_logloss: 1.01724
[19]	training's multi_logloss: 1.01175	validation's multi_logloss: 1.01578
[20]	training's multi_logloss: 1.00826	validation's multi_logloss: 1.0123
[21]	training's multi_logloss: 1.00711	validation's multi_logloss: 1.01097
[22]	training's multi_logloss: 1.00424	validation's multi_logloss: 1.0085
[23]	training's multi_logloss: 1.00339	validation's multi_logloss: 1.00777
[24]	training's multi_logloss: 1.00256	validation's multi_logloss: 1.00709
[25]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00629
[26]	training's multi_logloss: 1.00109	validation's multi_logloss: 1.00565
[27]	training's multi_logloss: 1.00038	validation's multi_logloss: 1.00505
[28]	training's multi_logloss: 0.999757	validation's multi_logloss: 1.00442
[29]	training's multi_logloss: 0.999083	validation's multi_logloss: 1.00387
[30]	training's multi_logloss: 0.998771	validation's multi_logloss: 1.00354
[31]	training's multi_logloss: 0.998424	validation's multi_logloss: 1.0032
[32]	training's multi_logloss: 0.997598	validation's multi_logloss: 1.00255
[33]	training's multi_logloss: 0.996984	validation's multi_logloss: 1.00187
[34]	training's multi_logloss: 0.9964	validation's multi_logloss: 1.00133
[35]	training's multi_logloss: 0.9964	validation's multi_logloss: 1.00133
[36]	training's multi_logloss: 0.996166	validation's multi_logloss: 1.00111
[37]	training's multi_logloss: 0.995636	validation's multi_logloss: 1.0005
[38]	training's multi_logloss: 0.995636	validation's multi_logloss: 1.0005
[39]	training's multi_logloss: 0.995636	validation's multi_logloss: 1.0005
[40]	training's multi_logloss: 0.995636	validation's multi_logloss: 1.0005
[41]	training's multi_logloss: 0.995636	validation's multi_logloss: 1.0005
[42]	training's multi_logloss: 0.995326	validation's multi_logloss: 1.00031
[43]	training's multi_logloss: 0.995326	validation's multi_logloss: 1.00031
[44]	training's multi_logloss: 0.995326	validation's multi_logloss: 1.00031
[45]	training's multi_logloss: 0.995068	validation's multi_logloss: 1.00008
[46]	training's multi_logloss: 0.995068	validation's multi_logloss: 1.00008
[47]	training's multi_logloss: 0.994847	validation's multi_logloss: 0.999804
[48]	training's multi_logloss: 0.994847	validation's multi_logloss: 0.999804
[49]	training's multi_logloss: 0.994847	validation's multi_logloss: 0.999804
[50]	training's multi_logloss: 0.994847	validation's multi_logloss: 0.999804
[51]	training's multi_logloss: 0.99464	validation's multi_logloss: 0.999646
[52]	training's multi_logloss: 0.99464	validation's multi_logloss: 0.999646
[53]	training's multi_logloss: 0.99464	validation's multi_logloss: 0.999646
[54]	training's multi_logloss: 0.99464	validation's multi_logloss: 0.999646
[55]	training's multi_logloss: 0.99464	validation's multi_logloss: 0.999646
[56]	training's multi_logloss: 0.99464	validation's multi_logloss: 0.999646
[57]	training's multi_logloss: 0.994366	validation's multi_logloss: 0.999342
[58]	training's multi_logloss: 0.994366	validation's multi_logloss: 0.999342
[59]	training's multi_logloss: 0.994366	validation's multi_logloss: 0.999342
[60]	training's multi_logloss: 0.994366	validation's multi_logloss: 0.999342
[61]	training's multi_logloss: 0.994366	validation's multi_logloss: 0.999342
[62]	training's multi_logloss: 0.994366	validation's multi_logloss: 0.999342
[63]	training's multi_logloss: 0.994366	validation's multi_logloss: 0.999342
[64]	training's multi_logloss: 0.994366	validation's multi_logloss: 0.999342
[65]	training's multi_logloss: 0.994366	validation's multi_logloss: 0.999342
[66]	training's multi_logloss: 0.994366	validation's multi_logloss: 0.999342
[67]	training's multi_logloss: 0.994366	validation's multi_logloss: 0.999342
[68]	training's multi_logloss: 0.994366	validation's multi_logloss: 0.999342
[69]	training's multi_logloss: 0.994366	validation's multi_logloss: 0.999342
[70]	training's multi_logloss: 0.994366	validation's multi_logloss: 0.999342
[71]	training's multi_logloss: 0.994366	validation's multi_logloss: 0.999342
[72]	training's multi_logloss: 0.994366	validation's multi_logloss: 0.999342
[73]	training's multi_logloss: 0.994072	validation's multi_logloss: 0.998951
[74]	training's multi_logloss: 0.994072	validation's multi_logloss: 0.998951
[75]	training's multi_logloss: 0.994072	validation's multi_logloss: 0.998951
[76]	training's multi_logloss: 0.994072	validation's multi_logloss: 0.998951
[77]	training's multi_logloss: 0.994072	validation's multi_logloss: 0.998951
[78]	training's multi_logloss: 0.994072	validation's multi_logloss: 0.998951
[79]	training's multi_logloss: 0.994072	validation's multi_logloss: 0.998951
[80]	training's multi_logloss: 0.994072	validation's multi_logloss: 0.998951
[81]	training's multi_logloss: 0.993833	validation's multi_logloss: 0.998689
[82]	training's multi_logloss: 0.993833	validation's multi_logloss: 0.998689
[83]	training's multi_logloss: 0.993833	validation's multi_logloss: 0.998689
[84]	training's multi_logloss: 0.993833	validation's multi_logloss: 0.998689
[85]	training's multi_logloss: 0.993833	validation's multi_logloss: 0.998689
[86]	training's multi_logloss: 0.993631	validation's multi_logloss: 0.998558
[87]	training's multi_logloss: 0.993631	validation's multi_logloss: 0.998558
[88]	training's multi_logloss: 0.993631	validation's multi_logloss: 0.998558
[89]	training's multi_logloss: 0.993413	validation's multi_logloss: 0.998304
[90]	training's multi_logloss: 0.993413	validation's multi_logloss: 0.998304
[91]	training's multi_logloss: 0.992789	validation's multi_logloss: 0.997841
[92]	training's multi_logloss: 0.992789	validation's multi_logloss: 0.997841
[93]	training's multi_logloss: 0.99238	validation's multi_logloss: 0.997548
[94]	training's multi_logloss: 0.99238	validation's multi_logloss: 0.997548
[95]	training's multi_logloss: 0.992219	validation's multi_logloss: 0.997477
[96]	training's multi_logloss: 0.992219	validation's multi_logloss: 0.997477
[97]	training's multi_logloss: 0.992219	validation's multi_logloss: 0.997477
[98]	training's multi_logloss: 0.992219	validation's multi_logloss: 0.997477
[99]	training's multi_logloss: 0.992219	validation's multi_logloss: 0.997477
[100]	training's multi_logloss: 0.992219	validation's multi_logloss: 0.997477
Did not meet early stopping. Best iteration is:
[95]	training's multi_logloss: 0.992219	validation's multi_logloss: 0.997477
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=5.330042347420331, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.330042347420331
[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04872	validation's multi_logloss: 1.05077
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.04003	validation's multi_logloss: 1.044
[3]	training's multi_logloss: 1.03248	validation's multi_logloss: 1.038
[4]	training's multi_logloss: 1.026	validation's multi_logloss: 1.0333
[5]	training's multi_logloss: 1.02051	validation's multi_logloss: 1.02929
[6]	training's multi_logloss: 1.01587	validation's multi_logloss: 1.02643
[7]	training's multi_logloss: 1.01201	validation's multi_logloss: 1.02396
[8]	training's multi_logloss: 1.00847	validation's multi_logloss: 1.02193
[9]	training's multi_logloss: 1.00574	validation's multi_logloss: 1.02015
[10]	training's multi_logloss: 1.00379	validation's multi_logloss: 1.01906
[11]	training's multi_logloss: 1.002	validation's multi_logloss: 1.01792
[12]	training's multi_logloss: 1.00033	validation's multi_logloss: 1.01698
[13]	training's multi_logloss: 0.998813	validation's multi_logloss: 1.01623
[14]	training's multi_logloss: 0.997622	validation's multi_logloss: 1.01565
[15]	training's multi_logloss: 0.996489	validation's multi_logloss: 1.01494
[16]	training's multi_logloss: 0.995697	validation's multi_logloss: 1.01448
[17]	training's multi_logloss: 0.995036	validation's multi_logloss: 1.01411
[18]	training's multi_logloss: 0.993725	validation's multi_logloss: 1.01384
[19]	training's multi_logloss: 0.993184	validation's multi_logloss: 1.01346
[20]	training's multi_logloss: 0.992685	validation's multi_logloss: 1.01309
[21]	training's multi_logloss: 0.991974	validation's multi_logloss: 1.01269
[22]	training's multi_logloss: 0.991504	validation's multi_logloss: 1.0123
[23]	training's multi_logloss: 0.991247	validation's multi_logloss: 1.01215
[24]	training's multi_logloss: 0.990834	validation's multi_logloss: 1.01188
[25]	training's multi_logloss: 0.990389	validation's multi_logloss: 1.01179
[26]	training's multi_logloss: 0.990389	validation's multi_logloss: 1.01179
[27]	training's multi_logloss: 0.990389	validation's multi_logloss: 1.01179
[28]	training's multi_logloss: 0.990208	validation's multi_logloss: 1.01179
[29]	training's multi_logloss: 0.989856	validation's multi_logloss: 1.01159
[30]	training's multi_logloss: 0.989856	validation's multi_logloss: 1.01159
[31]	training's multi_logloss: 0.989856	validation's multi_logloss: 1.01159
[32]	training's multi_logloss: 0.989638	validation's multi_logloss: 1.01153
[33]	training's multi_logloss: 0.989465	validation's multi_logloss: 1.01148
[34]	training's multi_logloss: 0.989465	validation's multi_logloss: 1.01148
[35]	training's multi_logloss: 0.989284	validation's multi_logloss: 1.0113
[36]	training's multi_logloss: 0.989284	validation's multi_logloss: 1.0113
[37]	training's multi_logloss: 0.989284	validation's multi_logloss: 1.0113
[38]	training's multi_logloss: 0.989284	validation's multi_logloss: 1.0113
[39]	training's multi_logloss: 0.989284	validation's multi_logloss: 1.0113
[40]	training's multi_logloss: 0.989284	validation's multi_logloss: 1.0113
[41]	training's multi_logloss: 0.98906	validation's multi_logloss: 1.01121
[42]	training's multi_logloss: 0.98906	validation's multi_logloss: 1.01121
[43]	training's multi_logloss: 0.98906	validation's multi_logloss: 1.01121
[44]	training's multi_logloss: 0.98906	validation's multi_logloss: 1.01121
[45]	training's multi_logloss: 0.98906	validation's multi_logloss: 1.01121
[46]	training's multi_logloss: 0.98906	validation's multi_logloss: 1.01121
[47]	training's multi_logloss: 0.98906	validation's multi_logloss: 1.01121
[48]	training's multi_logloss: 0.988876	validation's multi_logloss: 1.01121
[49]	training's multi_logloss: 0.988876	validation's multi_logloss: 1.01121
[50]	training's multi_logloss: 0.988876	validation's multi_logloss: 1.01121
[51]	training's multi_logloss: 0.988876	validation's multi_logloss: 1.01121
[52]	training's multi_logloss: 0.988876	validation's multi_logloss: 1.01121
[53]	training's multi_logloss: 0.988688	validation's multi_logloss: 1.01119
[54]	training's multi_logloss: 0.988688	validation's multi_logloss: 1.01119
[55]	training's multi_logloss: 0.988688	validation's multi_logloss: 1.01119
[56]	training's multi_logloss: 0.988688	validation's multi_logloss: 1.01119
[57]	training's multi_logloss: 0.988688	validation's multi_logloss: 1.01119
[58]	training's multi_logloss: 0.988688	validation's multi_logloss: 1.01119
[59]	training's multi_logloss: 0.988688	validation's multi_logloss: 1.01119
[60]	training's multi_logloss: 0.988688	validation's multi_logloss: 1.01119
[61]	training's multi_logloss: 0.988688	validation's multi_logloss: 1.01119
[62]	training's multi_logloss: 0.988688	validation's multi_logloss: 1.01119
[63]	training's multi_logloss: 0.988688	validation's multi_logloss: 1.01119
[64]	training's multi_logloss: 0.988688	validation's multi_logloss: 1.01119
[65]	training's multi_logloss: 0.988489	validation's multi_logloss: 1.01115
[66]	training's multi_logloss: 0.988489	validation's multi_logloss: 1.01115
[67]	training's multi_logloss: 0.988489	validation's multi_logloss: 1.01115
[68]	training's multi_logloss: 0.988489	validation's multi_logloss: 1.01115
[69]	training's multi_logloss: 0.988489	validation's multi_logloss: 1.01115
[70]	training's multi_logloss: 0.988489	validation's multi_logloss: 1.01115
[71]	training's multi_logloss: 0.988489	validation's multi_logloss: 1.01115
[72]	training's multi_logloss: 0.988489	validation's multi_logloss: 1.01115
[73]	training's multi_logloss: 0.988489	validation's multi_logloss: 1.01115
[74]	training's multi_logloss: 0.988489	validation's multi_logloss: 1.01115
[75]	training's multi_logloss: 0.988302	validation's multi_logloss: 1.01119
[76]	training's multi_logloss: 0.988302	validation's multi_logloss: 1.01119
[77]	training's multi_logloss: 0.988302	validation's multi_logloss: 1.01119
[78]	training's multi_logloss: 0.988141	validation's multi_logloss: 1.0111
[79]	training's multi_logloss: 0.988141	validation's multi_logloss: 1.0111
[80]	training's multi_logloss: 0.988141	validation's multi_logloss: 1.0111
[81]	training's multi_logloss: 0.988141	validation's multi_logloss: 1.0111
[82]	training's multi_logloss: 0.988141	validation's multi_logloss: 1.0111
[83]	training's multi_logloss: 0.98797	validation's multi_logloss: 1.01103
[84]	training's multi_logloss: 0.98797	validation's multi_logloss: 1.01103
[85]	training's multi_logloss: 0.98797	validation's multi_logloss: 1.01103
[86]	training's multi_logloss: 0.98797	validation's multi_logloss: 1.01103
[87]	training's multi_logloss: 0.98797	validation's multi_logloss: 1.01103
[88]	training's multi_logloss: 0.98797	validation's multi_logloss: 1.01103
[89]	training's multi_logloss: 0.98797	validation's multi_logloss: 1.01103
[90]	training's multi_logloss: 0.98797	validation's multi_logloss: 1.01103
[91]	training's multi_logloss: 0.98797	validation's multi_logloss: 1.01103
[92]	training's multi_logloss: 0.98797	validation's multi_logloss: 1.01103
[93]	training's multi_logloss: 0.98797	validation's multi_logloss: 1.01103
[94]	training's multi_logloss: 0.98797	validation's multi_logloss: 1.01103
[95]	training's multi_logloss: 0.98797	validation's multi_logloss: 1.01103
[96]	training's multi_logloss: 0.98797	validation's multi_logloss: 1.01103
[97]	training's multi_logloss: 0.98797	validation's multi_logloss: 1.01103
[98]	training's multi_logloss: 0.98797	validation's multi_logloss: 1.01103
[99]	training's multi_logloss: 0.98797	validation's multi_logloss: 1.01103
[100]	training's multi_logloss: 0.987767	validation's multi_logloss: 1.01087
Did not meet early stopping. Best iteration is:
[100]	training's multi_logloss: 0.987767	validation's multi_logloss: 1.01087
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=5.330042347420331, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.330042347420331
[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04907	validation's multi_logloss: 1.05013
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.04058	validation's multi_logloss: 1.04228
[3]	training's multi_logloss: 1.03293	validation's multi_logloss: 1.03584
[4]	training's multi_logloss: 1.02696	validation's multi_logloss: 1.03066
[5]	training's multi_logloss: 1.02184	validation's multi_logloss: 1.02589
[6]	training's multi_logloss: 1.01752	validation's multi_logloss: 1.02229
[7]	training's multi_logloss: 1.01401	validation's multi_logloss: 1.01957
[8]	training's multi_logloss: 1.01107	validation's multi_logloss: 1.01747
[9]	training's multi_logloss: 1.0087	validation's multi_logloss: 1.01552
[10]	training's multi_logloss: 1.00647	validation's multi_logloss: 1.01424
[11]	training's multi_logloss: 1.00476	validation's multi_logloss: 1.01307
[12]	training's multi_logloss: 1.00317	validation's multi_logloss: 1.01194
[13]	training's multi_logloss: 1.00192	validation's multi_logloss: 1.01102
[14]	training's multi_logloss: 1.00089	validation's multi_logloss: 1.01003
[15]	training's multi_logloss: 1.00011	validation's multi_logloss: 1.00973
[16]	training's multi_logloss: 0.999295	validation's multi_logloss: 1.00926
[17]	training's multi_logloss: 0.998364	validation's multi_logloss: 1.00859
[18]	training's multi_logloss: 0.997484	validation's multi_logloss: 1.00817
[19]	training's multi_logloss: 0.996793	validation's multi_logloss: 1.00753
[20]	training's multi_logloss: 0.996591	validation's multi_logloss: 1.00734
[21]	training's multi_logloss: 0.996103	validation's multi_logloss: 1.00717
[22]	training's multi_logloss: 0.995839	validation's multi_logloss: 1.00685
[23]	training's multi_logloss: 0.995632	validation's multi_logloss: 1.00677
[24]	training's multi_logloss: 0.995473	validation's multi_logloss: 1.00663
[25]	training's multi_logloss: 0.995473	validation's multi_logloss: 1.00663
[26]	training's multi_logloss: 0.995473	validation's multi_logloss: 1.00663
[27]	training's multi_logloss: 0.995473	validation's multi_logloss: 1.00663
[28]	training's multi_logloss: 0.995473	validation's multi_logloss: 1.00663
[29]	training's multi_logloss: 0.995473	validation's multi_logloss: 1.00663
[30]	training's multi_logloss: 0.995284	validation's multi_logloss: 1.0065
[31]	training's multi_logloss: 0.995284	validation's multi_logloss: 1.0065
[32]	training's multi_logloss: 0.995284	validation's multi_logloss: 1.0065
[33]	training's multi_logloss: 0.995284	validation's multi_logloss: 1.0065
[34]	training's multi_logloss: 0.995284	validation's multi_logloss: 1.0065
[35]	training's multi_logloss: 0.995019	validation's multi_logloss: 1.00641
[36]	training's multi_logloss: 0.994822	validation's multi_logloss: 1.00627
[37]	training's multi_logloss: 0.994822	validation's multi_logloss: 1.00627
[38]	training's multi_logloss: 0.994822	validation's multi_logloss: 1.00627
[39]	training's multi_logloss: 0.994822	validation's multi_logloss: 1.00627
[40]	training's multi_logloss: 0.994351	validation's multi_logloss: 1.00602
[41]	training's multi_logloss: 0.994351	validation's multi_logloss: 1.00602
[42]	training's multi_logloss: 0.994351	validation's multi_logloss: 1.00602
[43]	training's multi_logloss: 0.994351	validation's multi_logloss: 1.00602
[44]	training's multi_logloss: 0.994351	validation's multi_logloss: 1.00602
[45]	training's multi_logloss: 0.994351	validation's multi_logloss: 1.00602
[46]	training's multi_logloss: 0.994351	validation's multi_logloss: 1.00602
[47]	training's multi_logloss: 0.99418	validation's multi_logloss: 1.00599
[48]	training's multi_logloss: 0.994005	validation's multi_logloss: 1.00601
[49]	training's multi_logloss: 0.994005	validation's multi_logloss: 1.00601
[50]	training's multi_logloss: 0.993804	validation's multi_logloss: 1.00595
[51]	training's multi_logloss: 0.993804	validation's multi_logloss: 1.00595
[52]	training's multi_logloss: 0.993804	validation's multi_logloss: 1.00595
[53]	training's multi_logloss: 0.993804	validation's multi_logloss: 1.00595
[54]	training's multi_logloss: 0.993804	validation's multi_logloss: 1.00595
[55]	training's multi_logloss: 0.993804	validation's multi_logloss: 1.00595
[56]	training's multi_logloss: 0.993804	validation's multi_logloss: 1.00595
[57]	training's multi_logloss: 0.993804	validation's multi_logloss: 1.00595
[58]	training's multi_logloss: 0.993804	validation's multi_logloss: 1.00595
[59]	training's multi_logloss: 0.993804	validation's multi_logloss: 1.00595
[60]	training's multi_logloss: 0.993804	validation's multi_logloss: 1.00595
[61]	training's multi_logloss: 0.993407	validation's multi_logloss: 1.00563
[62]	training's multi_logloss: 0.993407	validation's multi_logloss: 1.00563
[63]	training's multi_logloss: 0.993407	validation's multi_logloss: 1.00563
[64]	training's multi_logloss: 0.993407	validation's multi_logloss: 1.00563
[65]	training's multi_logloss: 0.993407	validation's multi_logloss: 1.00563
[66]	training's multi_logloss: 0.993234	validation's multi_logloss: 1.00555
[67]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[68]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[69]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[70]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[71]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[72]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[73]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[74]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[75]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[76]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[77]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[78]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[79]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[80]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[81]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[82]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[83]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[84]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[85]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[86]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[87]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
Early stopping, best iteration is:
[67]	training's multi_logloss: 0.993057	validation's multi_logloss: 1.0054
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300
[LightGBM] [Warning] min_gain_to_split is set=5.435366888172552, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.435366888172552
[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05106	validation's multi_logloss: 1.05068
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.04208	validation's multi_logloss: 1.04154
[3]	training's multi_logloss: 1.03525	validation's multi_logloss: 1.03493
[4]	training's multi_logloss: 1.02866	validation's multi_logloss: 1.02778
[5]	training's multi_logloss: 1.02429	validation's multi_logloss: 1.02321
[6]	training's multi_logloss: 1.01961	validation's multi_logloss: 1.0188
[7]	training's multi_logloss: 1.01618	validation's multi_logloss: 1.01518
[8]	training's multi_logloss: 1.01344	validation's multi_logloss: 1.01252
[9]	training's multi_logloss: 1.01129	validation's multi_logloss: 1.01077
[10]	training's multi_logloss: 1.00987	validation's multi_logloss: 1.00942
[11]	training's multi_logloss: 1.00817	validation's multi_logloss: 1.00748
[12]	training's multi_logloss: 1.00687	validation's multi_logloss: 1.00634
[13]	training's multi_logloss: 1.00567	validation's multi_logloss: 1.00525
[14]	training's multi_logloss: 1.00447	validation's multi_logloss: 1.00377
[15]	training's multi_logloss: 1.00377	validation's multi_logloss: 1.00314
[16]	training's multi_logloss: 1.00305	validation's multi_logloss: 1.00262
[17]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.0018
[18]	training's multi_logloss: 1.00194	validation's multi_logloss: 1.00169
[19]	training's multi_logloss: 1.0014	validation's multi_logloss: 1.00126
[20]	training's multi_logloss: 1.00089	validation's multi_logloss: 1.00066
[21]	training's multi_logloss: 1.00089	validation's multi_logloss: 1.00066
[22]	training's multi_logloss: 1.00031	validation's multi_logloss: 1.00021
[23]	training's multi_logloss: 1.00031	validation's multi_logloss: 1.00021
[24]	training's multi_logloss: 1.00008	validation's multi_logloss: 1.00001
[25]	training's multi_logloss: 0.999639	validation's multi_logloss: 0.999794
[26]	training's multi_logloss: 0.999397	validation's multi_logloss: 0.999635
[27]	training's multi_logloss: 0.999397	validation's multi_logloss: 0.999635
[28]	training's multi_logloss: 0.999397	validation's multi_logloss: 0.999635
[29]	training's multi_logloss: 0.999397	validation's multi_logloss: 0.999635
[30]	training's multi_logloss: 0.999397	validation's multi_logloss: 0.999635
[31]	training's multi_logloss: 0.999397	validation's multi_logloss: 0.999635
[32]	training's multi_logloss: 0.999162	validation's multi_logloss: 0.999565
[33]	training's multi_logloss: 0.999162	validation's multi_logloss: 0.999565
[34]	training's multi_logloss: 0.999162	validation's multi_logloss: 0.999565
[35]	training's multi_logloss: 0.998883	validation's multi_logloss: 0.999329
[36]	training's multi_logloss: 0.998883	validation's multi_logloss: 0.999329
[37]	training's multi_logloss: 0.998663	validation's multi_logloss: 0.999002
[38]	training's multi_logloss: 0.998663	validation's multi_logloss: 0.999002
[39]	training's multi_logloss: 0.998663	validation's multi_logloss: 0.999002
[40]	training's multi_logloss: 0.998295	validation's multi_logloss: 0.9988
[41]	training's multi_logloss: 0.99803	validation's multi_logloss: 0.998524
[42]	training's multi_logloss: 0.99803	validation's multi_logloss: 0.998524
[43]	training's multi_logloss: 0.99803	validation's multi_logloss: 0.998524
[44]	training's multi_logloss: 0.99803	validation's multi_logloss: 0.998524
[45]	training's multi_logloss: 0.997775	validation's multi_logloss: 0.998255
[46]	training's multi_logloss: 0.997775	validation's multi_logloss: 0.998255
[47]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[48]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[49]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[50]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[51]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[52]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[53]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[54]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[55]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[56]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[57]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[58]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[59]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[60]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[61]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[62]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[63]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[64]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[65]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[66]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[67]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
Early stopping, best iteration is:
[47]	training's multi_logloss: 0.997586	validation's multi_logloss: 0.997976
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300
[LightGBM] [Warning] min_gain_to_split is set=5.435366888172552, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.435366888172552
[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18659	validation's multi_logloss: 1.18663
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.13915	validation's multi_logloss: 1.13891
[3]	training's multi_logloss: 1.10634	validation's multi_logloss: 1.10659
[4]	training's multi_logloss: 1.09721	validation's multi_logloss: 1.09762
[5]	training's multi_logloss: 1.07463	validation's multi_logloss: 1.07532
[6]	training's multi_logloss: 1.06779	validation's multi_logloss: 1.06897
[7]	training's multi_logloss: 1.06279	validation's multi_logloss: 1.06389
[8]	training's multi_logloss: 1.0584	validation's multi_logloss: 1.05989
[9]	training's multi_logloss: 1.04485	validation's multi_logloss: 1.04677
[10]	training's multi_logloss: 1.04098	validation's multi_logloss: 1.04303
[11]	training's multi_logloss: 1.03744	validation's multi_logloss: 1.03955
[12]	training's multi_logloss: 1.03451	validation's multi_logloss: 1.03681
[13]	training's multi_logloss: 1.03175	validation's multi_logloss: 1.03428
[14]	training's multi_logloss: 1.02885	validation's multi_logloss: 1.03151
[15]	training's multi_logloss: 1.02648	validation's multi_logloss: 1.02921
[16]	training's multi_logloss: 1.02415	validation's multi_logloss: 1.02701
[17]	training's multi_logloss: 1.02193	validation's multi_logloss: 1.02496
[18]	training's multi_logloss: 1.01679	validation's multi_logloss: 1.01977
[19]	training's multi_logloss: 1.0151	validation's multi_logloss: 1.01846
[20]	training's multi_logloss: 1.01121	validation's multi_logloss: 1.01445
[21]	training's multi_logloss: 1.00979	validation's multi_logloss: 1.01276
[22]	training's multi_logloss: 1.00861	validation's multi_logloss: 1.01174
[23]	training's multi_logloss: 1.00761	validation's multi_logloss: 1.01084
[24]	training's multi_logloss: 1.00651	validation's multi_logloss: 1.00985
[25]	training's multi_logloss: 1.00552	validation's multi_logloss: 1.00904
[26]	training's multi_logloss: 1.00459	validation's multi_logloss: 1.00822
[27]	training's multi_logloss: 1.00378	validation's multi_logloss: 1.00763
[28]	training's multi_logloss: 1.00296	validation's multi_logloss: 1.00694
[29]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.00487
[30]	training's multi_logloss: 1.00061	validation's multi_logloss: 1.00453
[31]	training's multi_logloss: 1.00061	validation's multi_logloss: 1.00453
[32]	training's multi_logloss: 1.00021	validation's multi_logloss: 1.00414
[33]	training's multi_logloss: 1.00021	validation's multi_logloss: 1.00414
[34]	training's multi_logloss: 0.999481	validation's multi_logloss: 1.00349
[35]	training's multi_logloss: 0.999481	validation's multi_logloss: 1.00349
[36]	training's multi_logloss: 0.999481	validation's multi_logloss: 1.00349
[37]	training's multi_logloss: 0.999481	validation's multi_logloss: 1.00349
[38]	training's multi_logloss: 0.999481	validation's multi_logloss: 1.00349
[39]	training's multi_logloss: 0.999481	validation's multi_logloss: 1.00349
[40]	training's multi_logloss: 0.999176	validation's multi_logloss: 1.00313
[41]	training's multi_logloss: 0.999176	validation's multi_logloss: 1.00313
[42]	training's multi_logloss: 0.998738	validation's multi_logloss: 1.00271
[43]	training's multi_logloss: 0.998421	validation's multi_logloss: 1.00229
[44]	training's multi_logloss: 0.998421	validation's multi_logloss: 1.00229
[45]	training's multi_logloss: 0.998082	validation's multi_logloss: 1.00188
[46]	training's multi_logloss: 0.998082	validation's multi_logloss: 1.00188
[47]	training's multi_logloss: 0.997757	validation's multi_logloss: 1.0016
[48]	training's multi_logloss: 0.997757	validation's multi_logloss: 1.0016
[49]	training's multi_logloss: 0.997492	validation's multi_logloss: 1.00145
[50]	training's multi_logloss: 0.997492	validation's multi_logloss: 1.00145
[51]	training's multi_logloss: 0.997236	validation's multi_logloss: 1.00123
[52]	training's multi_logloss: 0.997236	validation's multi_logloss: 1.00123
[53]	training's multi_logloss: 0.997236	validation's multi_logloss: 1.00123
[54]	training's multi_logloss: 0.996954	validation's multi_logloss: 1.00117
[55]	training's multi_logloss: 0.996954	validation's multi_logloss: 1.00117
[56]	training's multi_logloss: 0.996954	validation's multi_logloss: 1.00117
[57]	training's multi_logloss: 0.996954	validation's multi_logloss: 1.00117
[58]	training's multi_logloss: 0.996954	validation's multi_logloss: 1.00117
[59]	training's multi_logloss: 0.996954	validation's multi_logloss: 1.00117
[60]	training's multi_logloss: 0.996756	validation's multi_logloss: 1.00097
[61]	training's multi_logloss: 0.996756	validation's multi_logloss: 1.00097
[62]	training's multi_logloss: 0.996756	validation's multi_logloss: 1.00097
[63]	training's multi_logloss: 0.996215	validation's multi_logloss: 1.00046
[64]	training's multi_logloss: 0.996215	validation's multi_logloss: 1.00046
[65]	training's multi_logloss: 0.996215	validation's multi_logloss: 1.00046
[66]	training's multi_logloss: 0.996215	validation's multi_logloss: 1.00046
[67]	training's multi_logloss: 0.996215	validation's multi_logloss: 1.00046
[68]	training's multi_logloss: 0.996215	validation's multi_logloss: 1.00046
[69]	training's multi_logloss: 0.996215	validation's multi_logloss: 1.00046
[70]	training's multi_logloss: 0.996215	validation's multi_logloss: 1.00046
[71]	training's multi_logloss: 0.995726	validation's multi_logloss: 1.00003
[72]	training's multi_logloss: 0.995726	validation's multi_logloss: 1.00003
[73]	training's multi_logloss: 0.995726	validation's multi_logloss: 1.00003
[74]	training's multi_logloss: 0.995726	validation's multi_logloss: 1.00003
[75]	training's multi_logloss: 0.995726	validation's multi_logloss: 1.00003
[76]	training's multi_logloss: 0.99533	validation's multi_logloss: 0.999649
[77]	training's multi_logloss: 0.99533	validation's multi_logloss: 0.999649
[1]	training's multi_logloss: 1.05282	validation's multi_logloss: 1.05204
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.04611	validation's multi_logloss: 1.04528
[3]	training's multi_logloss: 1.0408	validation's multi_logloss: 1.03988
[4]	training's multi_logloss: 1.0361	validation's multi_logloss: 1.03487
[5]	training's multi_logloss: 1.03252	validation's multi_logloss: 1.03108
[6]	training's multi_logloss: 1.02943	validation's multi_logloss: 1.02745
[7]	training's multi_logloss: 1.02585	validation's multi_logloss: 1.0243
[8]	training's multi_logloss: 1.02345	validation's multi_logloss: 1.02151
[9]	training's multi_logloss: 1.02084	validation's multi_logloss: 1.01871
[10]	training's multi_logloss: 1.01925	validation's multi_logloss: 1.01715
[11]	training's multi_logloss: 1.01707	validation's multi_logloss: 1.01493
[12]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01258
[13]	training's multi_logloss: 1.01328	validation's multi_logloss: 1.01099
[14]	training's multi_logloss: 1.01199	validation's multi_logloss: 1.00995
[15]	training's multi_logloss: 1.01085	validation's multi_logloss: 1.00868
[16]	training's multi_logloss: 1.0098	validation's multi_logloss: 1.00763
[17]	training's multi_logloss: 1.00871	validation's multi_logloss: 1.00669
[18]	training's multi_logloss: 1.00772	validation's multi_logloss: 1.00586
[19]	training's multi_logloss: 1.00673	validation's multi_logloss: 1.00475
[20]	training's multi_logloss: 1.00588	validation's multi_logloss: 1.00379
[21]	training's multi_logloss: 1.00525	validation's multi_logloss: 1.00302
[22]	training's multi_logloss: 1.00459	validation's multi_logloss: 1.00224
[23]	training's multi_logloss: 1.00406	validation's multi_logloss: 1.00186
[24]	training's multi_logloss: 1.00359	validation's multi_logloss: 1.00166
[25]	training's multi_logloss: 1.00266	validation's multi_logloss: 1.00089
[26]	training's multi_logloss: 1.00205	validation's multi_logloss: 1.00033
[27]	training's multi_logloss: 1.00185	validation's multi_logloss: 1.00014
[28]	training's multi_logloss: 1.00137	validation's multi_logloss: 0.999973
[29]	training's multi_logloss: 1.00098	validation's multi_logloss: 0.999371
[30]	training's multi_logloss: 1.00098	validation's multi_logloss: 0.999371
[31]	training's multi_logloss: 1.00062	validation's multi_logloss: 0.999182
[32]	training's multi_logloss: 1.00028	validation's multi_logloss: 0.998934
[33]	training's multi_logloss: 1.00012	validation's multi_logloss: 0.998933
[34]	training's multi_logloss: 0.999903	validation's multi_logloss: 0.99891
[35]	training's multi_logloss: 0.999753	validation's multi_logloss: 0.998724
[36]	training's multi_logloss: 0.999753	validation's multi_logloss: 0.998724
[37]	training's multi_logloss: 0.999587	validation's multi_logloss: 0.998464
[38]	training's multi_logloss: 0.999466	validation's multi_logloss: 0.998348
[39]	training's multi_logloss: 0.999466	validation's multi_logloss: 0.998348
[40]	training's multi_logloss: 0.999466	validation's multi_logloss: 0.998348
[41]	training's multi_logloss: 0.999293	validation's multi_logloss: 0.998116
[42]	training's multi_logloss: 0.999133	validation's multi_logloss: 0.997928
[43]	training's multi_logloss: 0.998986	validation's multi_logloss: 0.997872
[44]	training's multi_logloss: 0.998986	validation's multi_logloss: 0.997872
[45]	training's multi_logloss: 0.998986	validation's multi_logloss: 0.997872
[46]	training's multi_logloss: 0.998986	validation's multi_logloss: 0.997872
[47]	training's multi_logloss: 0.998986	validation's multi_logloss: 0.997872
[48]	training's multi_logloss: 0.998986	validation's multi_logloss: 0.997872
[49]	training's multi_logloss: 0.998986	validation's multi_logloss: 0.997872
[50]	training's multi_logloss: 0.998986	validation's multi_logloss: 0.997872
[51]	training's multi_logloss: 0.998986	validation's multi_logloss: 0.997872
[52]	training's multi_logloss: 0.998844	validation's multi_logloss: 0.997702
[53]	training's multi_logloss: 0.998698	validation's multi_logloss: 0.997523
[54]	training's multi_logloss: 0.998547	validation's multi_logloss: 0.99741
[55]	training's multi_logloss: 0.998547	validation's multi_logloss: 0.99741
[56]	training's multi_logloss: 0.9984	validation's multi_logloss: 0.99723
[57]	training's multi_logloss: 0.9984	validation's multi_logloss: 0.99723
[58]	training's multi_logloss: 0.9984	validation's multi_logloss: 0.99723
[59]	training's multi_logloss: 0.9984	validation's multi_logloss: 0.99723
[60]	training's multi_logloss: 0.9984	validation's multi_logloss: 0.99723
[61]	training's multi_logloss: 0.998174	validation's multi_logloss: 0.997181
[62]	training's multi_logloss: 0.998174	validation's multi_logloss: 0.997181
[63]	training's multi_logloss: 0.998174	validation's multi_logloss: 0.997181
[64]	training's multi_logloss: 0.998174	validation's multi_logloss: 0.997181
[65]	training's multi_logloss: 0.998174	validation's multi_logloss: 0.997181
[66]	training's multi_logloss: 0.998174	validation's multi_logloss: 0.997181
[67]	training's multi_logloss: 0.998174	validation's multi_logloss: 0.997181
[68]	training's multi_logloss: 0.998174	validation's multi_logloss: 0.997181
[69]	training's multi_logloss: 0.997891	validation's multi_logloss: 0.996971
[70]	training's multi_logloss: 0.997891	validation's multi_logloss: 0.996971
[71]	training's multi_logloss: 0.997891	validation's multi_logloss: 0.996971
[72]	training's multi_logloss: 0.997891	validation's multi_logloss: 0.996971
[73]	training's multi_logloss: 0.997758	validation's multi_logloss: 0.996826
[74]	training's multi_logloss: 0.997758	validation's multi_logloss: 0.996826
[75]	training's multi_logloss: 0.997758	validation's multi_logloss: 0.996826
[76]	training's multi_logloss: 0.997758	validation's multi_logloss: 0.996826
[77]	training's multi_logloss: 0.997631	validation's multi_logloss: 0.99667
[78]	training's multi_logloss: 0.997631	validation's multi_logloss: 0.99667
[79]	training's multi_logloss: 0.997631	validation's multi_logloss: 0.99667
[80]	training's multi_logloss: 0.997631	validation's multi_logloss: 0.99667
[81]	training's multi_logloss: 0.997631	validation's multi_logloss: 0.99667
[82]	training's multi_logloss: 0.997631	validation's multi_logloss: 0.99667
[83]	training's multi_logloss: 0.99751	validation's multi_logloss: 0.996697
[84]	training's multi_logloss: 0.997326	validation's multi_logloss: 0.996421
[85]	training's multi_logloss: 0.997326	validation's multi_logloss: 0.996421
[86]	training's multi_logloss: 0.997326	validation's multi_logloss: 0.996421
[87]	training's multi_logloss: 0.997326	validation's multi_logloss: 0.996421
[88]	training's multi_logloss: 0.997326	validation's multi_logloss: 0.996421
[89]	training's multi_logloss: 0.997326	validation's multi_logloss: 0.996421
[90]	training's multi_logloss: 0.997326	validation's multi_logloss: 0.996421
[91]	training's multi_logloss: 0.997326	validation's multi_logloss: 0.996421
[92]	training's multi_logloss: 0.997326	validation's multi_logloss: 0.996421
[93]	training's multi_logloss: 0.997326	validation's multi_logloss: 0.996421
[94]	training's multi_logloss: 0.997326	validation's multi_logloss: 0.996421
[95]	training's multi_logloss: 0.997326	validation's multi_logloss: 0.996421
[96]	training's multi_logloss: 0.997326	validation's multi_logloss: 0.996421
[97]	training's multi_logloss: 0.997326	validation's multi_logloss: 0.996421
[98]	training's multi_logloss: 0.997326	validation's multi_logloss: 0.996421
[99]	training's multi_logloss: 0.997326	validation's multi_logloss: 0.996421
[100]	training's multi_logloss: 0.997326	validation's multi_logloss: 0.996421
Did not meet early stopping. Best iteration is:
[84]	training's multi_logloss: 0.997326	validation's multi_logloss: 0.996421
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700
[LightGBM] [Warning] min_gain_to_split is set=5.110633770266954, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.110633770266954
[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05302	validation's multi_logloss: 1.05268
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.04608	validation's multi_logloss: 1.04585
[3]	training's multi_logloss: 1.0405	validation's multi_logloss: 1.04072
[4]	training's multi_logloss: 1.03585	validation's multi_logloss: 1.03654
[5]	training's multi_logloss: 1.03214	validation's multi_logloss: 1.03262
[6]	training's multi_logloss: 1.02806	validation's multi_logloss: 1.02867
[7]	training's multi_logloss: 1.02502	validation's multi_logloss: 1.02613
[8]	training's multi_logloss: 1.02172	validation's multi_logloss: 1.02295
[9]	training's multi_logloss: 1.01923	validation's multi_logloss: 1.02007
[10]	training's multi_logloss: 1.01713	validation's multi_logloss: 1.01845
[11]	training's multi_logloss: 1.01528	validation's multi_logloss: 1.01631
[12]	training's multi_logloss: 1.01353	validation's multi_logloss: 1.01464
[13]	training's multi_logloss: 1.01175	validation's multi_logloss: 1.01327
[14]	training's multi_logloss: 1.01056	validation's multi_logloss: 1.01247
[15]	training's multi_logloss: 1.00918	validation's multi_logloss: 1.01121
[16]	training's multi_logloss: 1.00784	validation's multi_logloss: 1.00969
[17]	training's multi_logloss: 1.00692	validation's multi_logloss: 1.00864
[18]	training's multi_logloss: 1.00601	validation's multi_logloss: 1.00793
[19]	training's multi_logloss: 1.0052	validation's multi_logloss: 1.00714
[20]	training's multi_logloss: 1.00439	validation's multi_logloss: 1.00628
[21]	training's multi_logloss: 1.00372	validation's multi_logloss: 1.00589
[22]	training's multi_logloss: 1.00313	validation's multi_logloss: 1.00518
[23]	training's multi_logloss: 1.00254	validation's multi_logloss: 1.00472
[24]	training's multi_logloss: 1.00186	validation's multi_logloss: 1.00445
[25]	training's multi_logloss: 1.0014	validation's multi_logloss: 1.00392
[26]	training's multi_logloss: 1.00093	validation's multi_logloss: 1.00368
[27]	training's multi_logloss: 1.0005	validation's multi_logloss: 1.00355
[28]	training's multi_logloss: 1.00007	validation's multi_logloss: 1.00347
[29]	training's multi_logloss: 0.999873	validation's multi_logloss: 1.00336
[30]	training's multi_logloss: 0.999666	validation's multi_logloss: 1.0032
[31]	training's multi_logloss: 0.999666	validation's multi_logloss: 1.0032
[32]	training's multi_logloss: 0.999413	validation's multi_logloss: 1.00279
[33]	training's multi_logloss: 0.998985	validation's multi_logloss: 1.0022
[34]	training's multi_logloss: 0.998816	validation's multi_logloss: 1.00207
[35]	training's multi_logloss: 0.998816	validation's multi_logloss: 1.00207
[36]	training's multi_logloss: 0.998816	validation's multi_logloss: 1.00207
[37]	training's multi_logloss: 0.998477	validation's multi_logloss: 1.00184
[38]	training's multi_logloss: 0.998477	validation's multi_logloss: 1.00184
[39]	training's multi_logloss: 0.998096	validation's multi_logloss: 1.00166
[40]	training's multi_logloss: 0.998096	validation's multi_logloss: 1.00166
[41]	training's multi_logloss: 0.998096	validation's multi_logloss: 1.00166
[42]	training's multi_logloss: 0.997968	validation's multi_logloss: 1.0017
[43]	training's multi_logloss: 0.997836	validation's multi_logloss: 1.00159
[44]	training's multi_logloss: 0.997836	validation's multi_logloss: 1.00159
[45]	training's multi_logloss: 0.997685	validation's multi_logloss: 1.00139
[46]	training's multi_logloss: 0.997685	validation's multi_logloss: 1.00139
[47]	training's multi_logloss: 0.997487	validation's multi_logloss: 1.00103
[48]	training's multi_logloss: 0.997487	validation's multi_logloss: 1.00103
[49]	training's multi_logloss: 0.997487	validation's multi_logloss: 1.00103
[50]	training's multi_logloss: 0.997487	validation's multi_logloss: 1.00103
[51]	training's multi_logloss: 0.997304	validation's multi_logloss: 1.00093
[52]	training's multi_logloss: 0.997151	validation's multi_logloss: 1.00098
[53]	training's multi_logloss: 0.997151	validation's multi_logloss: 1.00098
[54]	training's multi_logloss: 0.997151	validation's multi_logloss: 1.00098
[55]	training's multi_logloss: 0.997151	validation's multi_logloss: 1.00098
[56]	training's multi_logloss: 0.997151	validation's multi_logloss: 1.00098
[57]	training's multi_logloss: 0.996998	validation's multi_logloss: 1.00091
[58]	training's multi_logloss: 0.996998	validation's multi_logloss: 1.00091
[59]	training's multi_logloss: 0.996998	validation's multi_logloss: 1.00091
[60]	training's multi_logloss: 0.996859	validation's multi_logloss: 1.00099
[61]	training's multi_logloss: 0.996859	validation's multi_logloss: 1.00099
[62]	training's multi_logloss: 0.996859	validation's multi_logloss: 1.00099
[63]	training's multi_logloss: 0.996859	validation's multi_logloss: 1.00099
[64]	training's multi_logloss: 0.996734	validation's multi_logloss: 1.00079
[65]	training's multi_logloss: 0.996734	validation's multi_logloss: 1.00079
[66]	training's multi_logloss: 0.996734	validation's multi_logloss: 1.00079
[67]	training's multi_logloss: 0.996734	validation's multi_logloss: 1.00079
[68]	training's multi_logloss: 0.996734	validation's multi_logloss: 1.00079
[69]	training's multi_logloss: 0.996734	validation's multi_logloss: 1.00079
[70]	training's multi_logloss: 0.996734	validation's multi_logloss: 1.00079
[71]	training's multi_logloss: 0.996734	validation's multi_logloss: 1.00079
[72]	training's multi_logloss: 0.996734	validation's multi_logloss: 1.00079
[73]	training's multi_logloss: 0.996734	validation's multi_logloss: 1.00079
[74]	training's multi_logloss: 0.996585	validation's multi_logloss: 1.00067
[75]	training's multi_logloss: 0.996585	validation's multi_logloss: 1.00067
[76]	training's multi_logloss: 0.996585	validation's multi_logloss: 1.00067
[77]	training's multi_logloss: 0.996585	validation's multi_logloss: 1.00067
[78]	training's multi_logloss: 0.996585	validation's multi_logloss: 1.00067
[79]	training's multi_logloss: 0.996439	validation's multi_logloss: 1.00058
[80]	training's multi_logloss: 0.996439	validation's multi_logloss: 1.00058
[81]	training's multi_logloss: 0.996439	validation's multi_logloss: 1.00058
[82]	training's multi_logloss: 0.996439	validation's multi_logloss: 1.00058
[83]	training's multi_logloss: 0.996439	validation's multi_logloss: 1.00058
[84]	training's multi_logloss: 0.996439	validation's multi_logloss: 1.00058
[85]	training's multi_logloss: 0.996439	validation's multi_logloss: 1.00058
[86]	training's multi_logloss: 0.996439	validation's multi_logloss: 1.00058
[87]	training's multi_logloss: 0.996439	validation's multi_logloss: 1.00058
[88]	training's multi_logloss: 0.996439	validation's multi_logloss: 1.00058
[89]	training's multi_logloss: 0.996439	validation's multi_logloss: 1.00058
[90]	training's multi_logloss: 0.996439	validation's multi_logloss: 1.00058
[91]	training's multi_logloss: 0.996317	validation's multi_logloss: 1.00057
[92]	training's multi_logloss: 0.996317	validation's multi_logloss: 1.00057
[93]	training's multi_logloss: 0.996317	validation's multi_logloss: 1.00057
[94]	training's multi_logloss: 0.996317	validation's multi_logloss: 1.00057
[95]	training's multi_logloss: 0.99619	validation's multi_logloss: 1.00047
[96]	training's multi_logloss: 0.99619	validation's multi_logloss: 1.00047
[97]	training's multi_logloss: 0.99619	validation's multi_logloss: 1.00047
[98]	training's multi_logloss: 0.996074	validation's multi_logloss: 1.00056
[99]	training's multi_logloss: 0.996074	validation's multi_logloss: 1.00056
[100]	training's multi_logloss: 0.996074	validation's multi_logloss: 1.00056
Did not meet early stopping. Best iteration is:
[98]	training's multi_logloss: 0.996074	validation's multi_logloss: 1.00056
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700
[LightGBM] [Warning] min_gain_to_split is set=5.110633770266954, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.110633770266954
[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05186	validation's multi_logloss: 1.05304
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.04489	validation's multi_logloss: 1.04793
[3]	training's multi_logloss: 1.03888	validation's multi_logloss: 1.04306
[4]	training's multi_logloss: 1.03379	validation's multi_logloss: 1.03931
[5]	training's multi_logloss: 1.02957	validation's multi_logloss: 1.03589
[6]	training's multi_logloss: 1.02565	validation's multi_logloss: 1.03279
[7]	training's multi_logloss: 1.022	validation's multi_logloss: 1.03038
[8]	training's multi_logloss: 1.01923	validation's multi_logloss: 1.02806
[9]	training's multi_logloss: 1.01591	validation's multi_logloss: 1.02553
[10]	training's multi_logloss: 1.01363	validation's multi_logloss: 1.02396
[11]	training's multi_logloss: 1.01124	validation's multi_logloss: 1.02225
[12]	training's multi_logloss: 1.0089	validation's multi_logloss: 1.02058
[13]	training's multi_logloss: 1.00709	validation's multi_logloss: 1.01922
[14]	training's multi_logloss: 1.00509	validation's multi_logloss: 1.01828
[15]	training's multi_logloss: 1.00402	validation's multi_logloss: 1.01777
[16]	training's multi_logloss: 1.00275	validation's multi_logloss: 1.01692
[17]	training's multi_logloss: 1.00165	validation's multi_logloss: 1.01593
[18]	training's multi_logloss: 1.00076	validation's multi_logloss: 1.01519
[19]	training's multi_logloss: 0.999849	validation's multi_logloss: 1.01463
[20]	training's multi_logloss: 0.999217	validation's multi_logloss: 1.01425
[21]	training's multi_logloss: 0.998315	validation's multi_logloss: 1.01365
[22]	training's multi_logloss: 0.997512	validation's multi_logloss: 1.0134
[23]	training's multi_logloss: 0.996963	validation's multi_logloss: 1.01297
[24]	training's multi_logloss: 0.996429	validation's multi_logloss: 1.0125
[25]	training's multi_logloss: 0.995821	validation's multi_logloss: 1.01232
[26]	training's multi_logloss: 0.995409	validation's multi_logloss: 1.01207
[27]	training's multi_logloss: 0.995166	validation's multi_logloss: 1.0121
[28]	training's multi_logloss: 0.994931	validation's multi_logloss: 1.01213
[29]	training's multi_logloss: 0.994545	validation's multi_logloss: 1.01199
[30]	training's multi_logloss: 0.994143	validation's multi_logloss: 1.01187
[31]	training's multi_logloss: 0.994143	validation's multi_logloss: 1.01187
[32]	training's multi_logloss: 0.993712	validation's multi_logloss: 1.01184
[33]	training's multi_logloss: 0.993533	validation's multi_logloss: 1.01187
[34]	training's multi_logloss: 0.993533	validation's multi_logloss: 1.01187
[35]	training's multi_logloss: 0.993533	validation's multi_logloss: 1.01187
[36]	training's multi_logloss: 0.993533	validation's multi_logloss: 1.01187
[37]	training's multi_logloss: 0.993533	validation's multi_logloss: 1.01187
[38]	training's multi_logloss: 0.993533	validation's multi_logloss: 1.01187
[39]	training's multi_logloss: 0.993313	validation's multi_logloss: 1.01201
[40]	training's multi_logloss: 0.993313	validation's multi_logloss: 1.01201
[41]	training's multi_logloss: 0.992943	validation's multi_logloss: 1.012
[42]	training's multi_logloss: 0.992732	validation's multi_logloss: 1.01202
[43]	training's multi_logloss: 0.992732	validation's multi_logloss: 1.01202
[44]	training's multi_logloss: 0.992562	validation's multi_logloss: 1.01207
[45]	training's multi_logloss: 0.992562	validation's multi_logloss: 1.01207
[46]	training's multi_logloss: 0.992562	validation's multi_logloss: 1.01207
[47]	training's multi_logloss: 0.992562	validation's multi_logloss: 1.01207
[48]	training's multi_logloss: 0.992413	validation's multi_logloss: 1.01214
[49]	training's multi_logloss: 0.99224	validation's multi_logloss: 1.01201
[50]	training's multi_logloss: 0.99224	validation's multi_logloss: 1.01201
[51]	training's multi_logloss: 0.99224	validation's multi_logloss: 1.01201
[52]	training's multi_logloss: 0.99224	validation's multi_logloss: 1.01201
Early stopping, best iteration is:
[32]	training's multi_logloss: 0.993712	validation's multi_logloss: 1.01184
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700
[LightGBM] [Warning] min_gain_to_split is set=5.110633770266954, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.110633770266954
[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05209	validation's multi_logloss: 1.05238
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.04534	validation's multi_logloss: 1.04637
[3]	training's multi_logloss: 1.03871	validation's multi_logloss: 1.04055
[4]	training's multi_logloss: 1.03398	validation's multi_logloss: 1.03693
[5]	training's multi_logloss: 1.02977	validation's multi_logloss: 1.03389
[6]	training's multi_logloss: 1.02623	validation's multi_logloss: 1.02994
[7]	training's multi_logloss: 1.02264	validation's multi_logloss: 1.02697
[8]	training's multi_logloss: 1.02	validation's multi_logloss: 1.02486
[9]	training's multi_logloss: 1.01772	validation's multi_logloss: 1.02263
[10]	training's multi_logloss: 1.01546	validation's multi_logloss: 1.02064
[11]	training's multi_logloss: 1.01339	validation's multi_logloss: 1.01923
[12]	training's multi_logloss: 1.01179	validation's multi_logloss: 1.01799
[13]	training's multi_logloss: 1.00987	validation's multi_logloss: 1.01603
[14]	training's multi_logloss: 1.00836	validation's multi_logloss: 1.01447
[15]	training's multi_logloss: 1.0071	validation's multi_logloss: 1.01353
[16]	training's multi_logloss: 1.00585	validation's multi_logloss: 1.01249
[17]	training's multi_logloss: 1.00491	validation's multi_logloss: 1.01172
[18]	training's multi_logloss: 1.00412	validation's multi_logloss: 1.01105
[19]	training's multi_logloss: 1.00322	validation's multi_logloss: 1.0103
[20]	training's multi_logloss: 1.00238	validation's multi_logloss: 1.00966
[21]	training's multi_logloss: 1.00166	validation's multi_logloss: 1.00967
[22]	training's multi_logloss: 1.00098	validation's multi_logloss: 1.00919
[23]	training's multi_logloss: 1.00042	validation's multi_logloss: 1.00909
[24]	training's multi_logloss: 0.999848	validation's multi_logloss: 1.00858
[25]	training's multi_logloss: 0.999341	validation's multi_logloss: 1.00812
[26]	training's multi_logloss: 0.998898	validation's multi_logloss: 1.00775
[27]	training's multi_logloss: 0.998466	validation's multi_logloss: 1.00736
[28]	training's multi_logloss: 0.998027	validation's multi_logloss: 1.00729
[29]	training's multi_logloss: 0.998027	validation's multi_logloss: 1.00729
[30]	training's multi_logloss: 0.997823	validation's multi_logloss: 1.00711
[31]	training's multi_logloss: 0.997598	validation's multi_logloss: 1.00721
[32]	training's multi_logloss: 0.997195	validation's multi_logloss: 1.00694
[33]	training's multi_logloss: 0.997195	validation's multi_logloss: 1.00694
[34]	training's multi_logloss: 0.997195	validation's multi_logloss: 1.00694
[35]	training's multi_logloss: 0.997195	validation's multi_logloss: 1.00694
[36]	training's multi_logloss: 0.997002	validation's multi_logloss: 1.00697
[37]	training's multi_logloss: 0.996835	validation's multi_logloss: 1.00697
[38]	training's multi_logloss: 0.99667	validation's multi_logloss: 1.00687
[39]	training's multi_logloss: 0.996488	validation's multi_logloss: 1.00662
[40]	training's multi_logloss: 0.996173	validation's multi_logloss: 1.00638
[41]	training's multi_logloss: 0.996173	validation's multi_logloss: 1.00638
[42]	training's multi_logloss: 0.995978	validation's multi_logloss: 1.00635
[43]	training's multi_logloss: 0.995797	validation's multi_logloss: 1.00629
[44]	training's multi_logloss: 0.995628	validation's multi_logloss: 1.00613
[45]	training's multi_logloss: 0.995628	validation's multi_logloss: 1.00613
[46]	training's multi_logloss: 0.995321	validation's multi_logloss: 1.00592
[47]	training's multi_logloss: 0.995321	validation's multi_logloss: 1.00592
[48]	training's multi_logloss: 0.995321	validation's multi_logloss: 1.00592
[49]	training's multi_logloss: 0.995321	validation's multi_logloss: 1.00592
[50]	training's multi_logloss: 0.995147	validation's multi_logloss: 1.00595
[51]	training's multi_logloss: 0.994982	validation's multi_logloss: 1.00598
[52]	training's multi_logloss: 0.994982	validation's multi_logloss: 1.00598
[53]	training's multi_logloss: 0.994982	validation's multi_logloss: 1.00598
[54]	training's multi_logloss: 0.994815	validation's multi_logloss: 1.00581
[55]	training's multi_logloss: 0.994815	validation's multi_logloss: 1.00581
[56]	training's multi_logloss: 0.994815	validation's multi_logloss: 1.00581
[57]	training's multi_logloss: 0.994815	validation's multi_logloss: 1.00581
[58]	training's multi_logloss: 0.994653	validation's multi_logloss: 1.00564
[59]	training's multi_logloss: 0.994653	validation's multi_logloss: 1.00564
[60]	training's multi_logloss: 0.994653	validation's multi_logloss: 1.00564
[61]	training's multi_logloss: 0.994653	validation's multi_logloss: 1.00564
[62]	training's multi_logloss: 0.994653	validation's multi_logloss: 1.00564
[63]	training's multi_logloss: 0.994653	validation's multi_logloss: 1.00564
[64]	training's multi_logloss: 0.994653	validation's multi_logloss: 1.00564
[65]	training's multi_logloss: 0.994653	validation's multi_logloss: 1.00564
[66]	training's multi_logloss: 0.994653	validation's multi_logloss: 1.00564
[67]	training's multi_logloss: 0.994491	validation's multi_logloss: 1.00555
[68]	training's multi_logloss: 0.994491	validation's multi_logloss: 1.00555
[69]	training's multi_logloss: 0.994491	validation's multi_logloss: 1.00555
[70]	training's multi_logloss: 0.994491	validation's multi_logloss: 1.00555
[71]	training's multi_logloss: 0.994491	validation's multi_logloss: 1.00555
[72]	training's multi_logloss: 0.994491	validation's multi_logloss: 1.00555
[73]	training's multi_logloss: 0.994491	validation's multi_logloss: 1.00555
[74]	training's multi_logloss: 0.994491	validation's multi_logloss: 1.00555
[75]	training's multi_logloss: 0.994491	validation's multi_logloss: 1.00555
[76]	training's multi_logloss: 0.994491	validation's multi_logloss: 1.00555
[77]	training's multi_logloss: 0.994491	validation's multi_logloss: 1.00555
[78]	training's multi_logloss: 0.994348	validation's multi_logloss: 1.00543
[79]	training's multi_logloss: 0.994348	validation's multi_logloss: 1.00543
[80]	training's multi_logloss: 0.994348	validation's multi_logloss: 1.00543
[81]	training's multi_logloss: 0.994348	validation's multi_logloss: 1.00543
[82]	training's multi_logloss: 0.994348	validation's multi_logloss: 1.00543
[83]	training's multi_logloss: 0.994348	validation's multi_logloss: 1.00543
[84]	training's multi_logloss: 0.994348	validation's multi_logloss: 1.00543
[85]	training's multi_logloss: 0.994348	validation's multi_logloss: 1.00543
[86]	training's multi_logloss: 0.994233	validation's multi_logloss: 1.00551
[87]	training's multi_logloss: 0.994233	validation's multi_logloss: 1.00551
[88]	training's multi_logloss: 0.994233	validation's multi_logloss: 1.00551
[89]	training's multi_logloss: 0.994233	validation's multi_logloss: 1.00551
[90]	training's multi_logloss: 0.994233	validation's multi_logloss: 1.00551
[91]	training's multi_logloss: 0.994233	validation's multi_logloss: 1.00551
[92]	training's multi_logloss: 0.994233	validation's multi_logloss: 1.00551
[93]	training's multi_logloss: 0.994233	validation's multi_logloss: 1.00551
[94]	training's multi_logloss: 0.994233	validation's multi_logloss: 1.00551
[95]	training's multi_logloss: 0.994233	validation's multi_logloss: 1.00551
[96]	training's multi_logloss: 0.994233	validation's multi_logloss: 1.00551
[97]	training's multi_logloss: 0.994233	validation's multi_logloss: 1.00551
[98]	training's multi_logloss: 0.994121	validation's multi_logloss: 1.00545
Early stopping, best iteration is:
[78]	training's multi_logloss: 0.994348	validation's multi_logloss: 1.00543
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800
[LightGBM] [Warning] min_gain_to_split is set=4.378213245865176, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.378213245865176
[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.08276	validation's multi_logloss: 1.08244
[4]	training's multi_logloss: 1.08276	validation's multi_logloss: 1.08244
[5]	training's multi_logloss: 1.08276	validation's multi_logloss: 1.08244
[6]	training's multi_logloss: 1.08276	validation's multi_logloss: 1.08244
[7]	training's multi_logloss: 1.07069	validation's multi_logloss: 1.06999
[8]	training's multi_logloss: 1.05947	validation's multi_logloss: 1.0585
[9]	training's multi_logloss: 1.05315	validation's multi_logloss: 1.05187
[10]	training's multi_logloss: 1.05315	validation's multi_logloss: 1.05187
[11]	training's multi_logloss: 1.04755	validation's multi_logloss: 1.046
[12]	training's multi_logloss: 1.0437	validation's multi_logloss: 1.04231
[13]	training's multi_logloss: 1.03995	validation's multi_logloss: 1.03811
[14]	training's multi_logloss: 1.03623	validation's multi_logloss: 1.03496
[15]	training's multi_logloss: 1.03623	validation's multi_logloss: 1.03496
[16]	training's multi_logloss: 1.03326	validation's multi_logloss: 1.03162
[17]	training's multi_logloss: 1.03326	validation's multi_logloss: 1.03162
[18]	training's multi_logloss: 1.031	validation's multi_logloss: 1.02988
[19]	training's multi_logloss: 1.02898	validation's multi_logloss: 1.02778
[20]	training's multi_logloss: 1.02898	validation's multi_logloss: 1.02778
[21]	training's multi_logloss: 1.02898	validation's multi_logloss: 1.02778
[1]	training's multi_logloss: 1.04591	validation's multi_logloss: 1.04527
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03551	validation's multi_logloss: 1.03495
[3]	training's multi_logloss: 1.02631	validation's multi_logloss: 1.02546
[4]	training's multi_logloss: 1.02021	validation's multi_logloss: 1.01935
[5]	training's multi_logloss: 1.0155	validation's multi_logloss: 1.01506
[6]	training's multi_logloss: 1.01172	validation's multi_logloss: 1.01151
[7]	training's multi_logloss: 1.00797	validation's multi_logloss: 1.00839
[8]	training's multi_logloss: 1.00545	validation's multi_logloss: 1.0064
[9]	training's multi_logloss: 1.00388	validation's multi_logloss: 1.00514
[10]	training's multi_logloss: 1.00232	validation's multi_logloss: 1.00387
[11]	training's multi_logloss: 1.00027	validation's multi_logloss: 1.00214
[12]	training's multi_logloss: 0.99858	validation's multi_logloss: 1.00108
[13]	training's multi_logloss: 0.997204	validation's multi_logloss: 0.999656
[14]	training's multi_logloss: 0.996647	validation's multi_logloss: 0.999155
[15]	training's multi_logloss: 0.995988	validation's multi_logloss: 0.99871
[16]	training's multi_logloss: 0.995624	validation's multi_logloss: 0.998421
[17]	training's multi_logloss: 0.994965	validation's multi_logloss: 0.997849
[18]	training's multi_logloss: 0.994426	validation's multi_logloss: 0.997026
[19]	training's multi_logloss: 0.994209	validation's multi_logloss: 0.996949
[20]	training's multi_logloss: 0.993796	validation's multi_logloss: 0.996615
[21]	training's multi_logloss: 0.993796	validation's multi_logloss: 0.996615
[22]	training's multi_logloss: 0.993262	validation's multi_logloss: 0.996112
[23]	training's multi_logloss: 0.993262	validation's multi_logloss: 0.996112
[24]	training's multi_logloss: 0.993262	validation's multi_logloss: 0.996112
[25]	training's multi_logloss: 0.993262	validation's multi_logloss: 0.996112
[26]	training's multi_logloss: 0.993262	validation's multi_logloss: 0.996112
[27]	training's multi_logloss: 0.993262	validation's multi_logloss: 0.996112
[28]	training's multi_logloss: 0.993262	validation's multi_logloss: 0.996112
[29]	training's multi_logloss: 0.993262	validation's multi_logloss: 0.996112
[30]	training's multi_logloss: 0.993262	validation's multi_logloss: 0.996112
[31]	training's multi_logloss: 0.993262	validation's multi_logloss: 0.996112
[32]	training's multi_logloss: 0.993035	validation's multi_logloss: 0.996124
[33]	training's multi_logloss: 0.993035	validation's multi_logloss: 0.996124
[34]	training's multi_logloss: 0.993035	validation's multi_logloss: 0.996124
[35]	training's multi_logloss: 0.992762	validation's multi_logloss: 0.995844
[36]	training's multi_logloss: 0.992762	validation's multi_logloss: 0.995844
[37]	training's multi_logloss: 0.992762	validation's multi_logloss: 0.995844
[38]	training's multi_logloss: 0.992762	validation's multi_logloss: 0.995844
[39]	training's multi_logloss: 0.992762	validation's multi_logloss: 0.995844
[40]	training's multi_logloss: 0.992762	validation's multi_logloss: 0.995844
[41]	training's multi_logloss: 0.992762	validation's multi_logloss: 0.995844
[42]	training's multi_logloss: 0.992762	validation's multi_logloss: 0.995844
[43]	training's multi_logloss: 0.992519	validation's multi_logloss: 0.995582
[44]	training's multi_logloss: 0.992519	validation's multi_logloss: 0.995582
[45]	training's multi_logloss: 0.992519	validation's multi_logloss: 0.995582
[46]	training's multi_logloss: 0.992519	validation's multi_logloss: 0.995582
[47]	training's multi_logloss: 0.992519	validation's multi_logloss: 0.995582
[48]	training's multi_logloss: 0.992519	validation's multi_logloss: 0.995582
[49]	training's multi_logloss: 0.992338	validation's multi_logloss: 0.995277
[50]	training's multi_logloss: 0.992338	validation's multi_logloss: 0.995277
[51]	training's multi_logloss: 0.992338	validation's multi_logloss: 0.995277
[52]	training's multi_logloss: 0.992338	validation's multi_logloss: 0.995277
[53]	training's multi_logloss: 0.992338	validation's multi_logloss: 0.995277
[54]	training's multi_logloss: 0.992338	validation's multi_logloss: 0.995277
[55]	training's multi_logloss: 0.992338	validation's multi_logloss: 0.995277
[56]	training's multi_logloss: 0.992338	validation's multi_logloss: 0.995277
[57]	training's multi_logloss: 0.992338	validation's multi_logloss: 0.995277
[58]	training's multi_logloss: 0.992338	validation's multi_logloss: 0.995277
[59]	training's multi_logloss: 0.992338	validation's multi_logloss: 0.995277
[60]	training's multi_logloss: 0.992338	validation's multi_logloss: 0.995277
[61]	training's multi_logloss: 0.992156	validation's multi_logloss: 0.995271
[62]	training's multi_logloss: 0.992156	validation's multi_logloss: 0.995271
[63]	training's multi_logloss: 0.992156	validation's multi_logloss: 0.995271
[64]	training's multi_logloss: 0.992156	validation's multi_logloss: 0.995271
[65]	training's multi_logloss: 0.992156	validation's multi_logloss: 0.995271
[66]	training's multi_logloss: 0.99196	validation's multi_logloss: 0.995182
[67]	training's multi_logloss: 0.991796	validation's multi_logloss: 0.994893
[68]	training's multi_logloss: 0.991796	validation's multi_logloss: 0.994893
[69]	training's multi_logloss: 0.991796	validation's multi_logloss: 0.994893
[70]	training's multi_logloss: 0.991796	validation's multi_logloss: 0.994893
[71]	training's multi_logloss: 0.991796	validation's multi_logloss: 0.994893
[72]	training's multi_logloss: 0.991796	validation's multi_logloss: 0.994893
[73]	training's multi_logloss: 0.991624	validation's multi_logloss: 0.994938
[74]	training's multi_logloss: 0.991624	validation's multi_logloss: 0.994938
[75]	training's multi_logloss: 0.991624	validation's multi_logloss: 0.994938
[76]	training's multi_logloss: 0.991624	validation's multi_logloss: 0.994938
[77]	training's multi_logloss: 0.99146	validation's multi_logloss: 0.994898
[78]	training's multi_logloss: 0.99146	validation's multi_logloss: 0.994898
[79]	training's multi_logloss: 0.99146	validation's multi_logloss: 0.994898
[80]	training's multi_logloss: 0.99146	validation's multi_logloss: 0.994898
[81]	training's multi_logloss: 0.99146	validation's multi_logloss: 0.994898
[82]	training's multi_logloss: 0.99146	validation's multi_logloss: 0.994898
[83]	training's multi_logloss: 0.99146	validation's multi_logloss: 0.994898
[84]	training's multi_logloss: 0.991292	validation's multi_logloss: 0.994622
[85]	training's multi_logloss: 0.991292	validation's multi_logloss: 0.994622
[86]	training's multi_logloss: 0.991292	validation's multi_logloss: 0.994622
[87]	training's multi_logloss: 0.991292	validation's multi_logloss: 0.994622
[88]	training's multi_logloss: 0.991292	validation's multi_logloss: 0.994622
[89]	training's multi_logloss: 0.991292	validation's multi_logloss: 0.994622
[90]	training's multi_logloss: 0.991292	validation's multi_logloss: 0.994622
[91]	training's multi_logloss: 0.991292	validation's multi_logloss: 0.994622
[92]	training's multi_logloss: 0.991292	validation's multi_logloss: 0.994622
[93]	training's multi_logloss: 0.991292	validation's multi_logloss: 0.994622
[94]	training's multi_logloss: 0.991292	validation's multi_logloss: 0.994622
[95]	training's multi_logloss: 0.991292	validation's multi_logloss: 0.994622
[96]	training's multi_logloss: 0.991292	validation's multi_logloss: 0.994622
[97]	training's multi_logloss: 0.991292	validation's multi_logloss: 0.994622
[98]	training's multi_logloss: 0.991292	validation's multi_logloss: 0.994622
[99]	training's multi_logloss: 0.991292	validation's multi_logloss: 0.994622
[100]	training's multi_logloss: 0.991292	validation's multi_logloss: 0.994622
Did not meet early stopping. Best iteration is:
[84]	training's multi_logloss: 0.991292	validation's multi_logloss: 0.994622
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=7.057319987448937, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.057319987448937
[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04659	validation's multi_logloss: 1.04551
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03668	validation's multi_logloss: 1.035
[3]	training's multi_logloss: 1.02767	validation's multi_logloss: 1.02675
[4]	training's multi_logloss: 1.0212	validation's multi_logloss: 1.02028
[5]	training's multi_logloss: 1.01576	validation's multi_logloss: 1.01525
[6]	training's multi_logloss: 1.0111	validation's multi_logloss: 1.01101
[7]	training's multi_logloss: 1.00786	validation's multi_logloss: 1.00876
[8]	training's multi_logloss: 1.00509	validation's multi_logloss: 1.00613
[9]	training's multi_logloss: 1.00307	validation's multi_logloss: 1.00463
[10]	training's multi_logloss: 1.00127	validation's multi_logloss: 1.00291
[11]	training's multi_logloss: 1.00005	validation's multi_logloss: 1.00141
[12]	training's multi_logloss: 0.998742	validation's multi_logloss: 1.00007
[13]	training's multi_logloss: 0.997745	validation's multi_logloss: 0.999274
[14]	training's multi_logloss: 0.996644	validation's multi_logloss: 0.998565
[15]	training's multi_logloss: 0.995465	validation's multi_logloss: 0.997494
[16]	training's multi_logloss: 0.995215	validation's multi_logloss: 0.997251
[17]	training's multi_logloss: 0.994715	validation's multi_logloss: 0.99683
[18]	training's multi_logloss: 0.994448	validation's multi_logloss: 0.996832
[19]	training's multi_logloss: 0.994448	validation's multi_logloss: 0.996832
[20]	training's multi_logloss: 0.99406	validation's multi_logloss: 0.996244
[21]	training's multi_logloss: 0.993579	validation's multi_logloss: 0.99547
[22]	training's multi_logloss: 0.993579	validation's multi_logloss: 0.99547
[23]	training's multi_logloss: 0.993579	validation's multi_logloss: 0.99547
[24]	training's multi_logloss: 0.993167	validation's multi_logloss: 0.995436
[25]	training's multi_logloss: 0.993167	validation's multi_logloss: 0.995436
[26]	training's multi_logloss: 0.992929	validation's multi_logloss: 0.995327
[27]	training's multi_logloss: 0.992929	validation's multi_logloss: 0.995327
[28]	training's multi_logloss: 0.992767	validation's multi_logloss: 0.99528
[29]	training's multi_logloss: 0.992767	validation's multi_logloss: 0.99528
[30]	training's multi_logloss: 0.992767	validation's multi_logloss: 0.99528
[31]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[32]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[33]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[34]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[35]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[36]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[37]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[38]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[39]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[40]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[41]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[42]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[43]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[44]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[45]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[46]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[47]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[48]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[49]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[50]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[51]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995016
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=7.057319987448937, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.057319987448937
[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.045	validation's multi_logloss: 1.04795
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03393	validation's multi_logloss: 1.03992
[3]	training's multi_logloss: 1.02466	validation's multi_logloss: 1.03335
[4]	training's multi_logloss: 1.01748	validation's multi_logloss: 1.02845
[5]	training's multi_logloss: 1.01128	validation's multi_logloss: 1.02383
[6]	training's multi_logloss: 1.00753	validation's multi_logloss: 1.02108
[7]	training's multi_logloss: 1.00441	validation's multi_logloss: 1.01857
[8]	training's multi_logloss: 1.00118	validation's multi_logloss: 1.01751
[9]	training's multi_logloss: 0.998446	validation's multi_logloss: 1.01681
[10]	training's multi_logloss: 0.996555	validation's multi_logloss: 1.01602
[11]	training's multi_logloss: 0.994672	validation's multi_logloss: 1.01452
[12]	training's multi_logloss: 0.993424	validation's multi_logloss: 1.01425
[13]	training's multi_logloss: 0.992305	validation's multi_logloss: 1.014
[14]	training's multi_logloss: 0.991242	validation's multi_logloss: 1.01355
[15]	training's multi_logloss: 0.990372	validation's multi_logloss: 1.01307
[16]	training's multi_logloss: 0.98978	validation's multi_logloss: 1.01269
[17]	training's multi_logloss: 0.989122	validation's multi_logloss: 1.01239
[18]	training's multi_logloss: 0.988127	validation's multi_logloss: 1.01201
[19]	training's multi_logloss: 0.988127	validation's multi_logloss: 1.01201
[20]	training's multi_logloss: 0.987852	validation's multi_logloss: 1.01192
[21]	training's multi_logloss: 0.98737	validation's multi_logloss: 1.01147
[22]	training's multi_logloss: 0.987118	validation's multi_logloss: 1.01131
[23]	training's multi_logloss: 0.986907	validation's multi_logloss: 1.01133
[24]	training's multi_logloss: 0.986539	validation's multi_logloss: 1.01103
[25]	training's multi_logloss: 0.986352	validation's multi_logloss: 1.01115
[26]	training's multi_logloss: 0.986352	validation's multi_logloss: 1.01115
[27]	training's multi_logloss: 0.986352	validation's multi_logloss: 1.01115
[28]	training's multi_logloss: 0.986352	validation's multi_logloss: 1.01115
[29]	training's multi_logloss: 0.986165	validation's multi_logloss: 1.01105
[30]	training's multi_logloss: 0.986165	validation's multi_logloss: 1.01105
[31]	training's multi_logloss: 0.986165	validation's multi_logloss: 1.01105
[32]	training's multi_logloss: 0.986165	validation's multi_logloss: 1.01105
[33]	training's multi_logloss: 0.986165	validation's multi_logloss: 1.01105
[34]	training's multi_logloss: 0.986165	validation's multi_logloss: 1.01105
[35]	training's multi_logloss: 0.985996	validation's multi_logloss: 1.01104
[36]	training's multi_logloss: 0.985996	validation's multi_logloss: 1.01104
[37]	training's multi_logloss: 0.985996	validation's multi_logloss: 1.01104
[38]	training's multi_logloss: 0.985996	validation's multi_logloss: 1.01104
[39]	training's multi_logloss: 0.985996	validation's multi_logloss: 1.01104
[40]	training's multi_logloss: 0.985996	validation's multi_logloss: 1.01104
[41]	training's multi_logloss: 0.985996	validation's multi_logloss: 1.01104
[42]	training's multi_logloss: 0.985805	validation's multi_logloss: 1.01107
[43]	training's multi_logloss: 0.985805	validation's multi_logloss: 1.01107
[44]	training's multi_logloss: 0.985598	validation's multi_logloss: 1.01111
Early stopping, best iteration is:
[24]	training's multi_logloss: 0.986539	validation's multi_logloss: 1.01103
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=7.057319987448937, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.057319987448937
[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04475	validation's multi_logloss: 1.04635
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03436	validation's multi_logloss: 1.03807
[3]	training's multi_logloss: 1.02474	validation's multi_logloss: 1.02981
[4]	training's multi_logloss: 1.01809	validation's multi_logloss: 1.02436
[5]	training's multi_logloss: 1.01287	validation's multi_logloss: 1.02021
[6]	training's multi_logloss: 1.00882	validation's multi_logloss: 1.01676
[7]	training's multi_logloss: 1.00606	validation's multi_logloss: 1.01473
[8]	training's multi_logloss: 1.0033	validation's multi_logloss: 1.0127
[9]	training's multi_logloss: 1.00089	validation's multi_logloss: 1.01082
[10]	training's multi_logloss: 0.998844	validation's multi_logloss: 1.00958
[11]	training's multi_logloss: 0.997095	validation's multi_logloss: 1.00831
[12]	training's multi_logloss: 0.99573	validation's multi_logloss: 1.00759
[13]	training's multi_logloss: 0.994634	validation's multi_logloss: 1.00649
[14]	training's multi_logloss: 0.993594	validation's multi_logloss: 1.00633
[15]	training's multi_logloss: 0.993025	validation's multi_logloss: 1.00618
[16]	training's multi_logloss: 0.993025	validation's multi_logloss: 1.00618
[17]	training's multi_logloss: 0.992692	validation's multi_logloss: 1.00592
[18]	training's multi_logloss: 0.992114	validation's multi_logloss: 1.00517
[19]	training's multi_logloss: 0.991804	validation's multi_logloss: 1.00502
[20]	training's multi_logloss: 0.991804	validation's multi_logloss: 1.00502
[21]	training's multi_logloss: 0.991133	validation's multi_logloss: 1.00498
[22]	training's multi_logloss: 0.990912	validation's multi_logloss: 1.00467
[23]	training's multi_logloss: 0.990912	validation's multi_logloss: 1.00467
[24]	training's multi_logloss: 0.990912	validation's multi_logloss: 1.00467
[25]	training's multi_logloss: 0.990912	validation's multi_logloss: 1.00467
[26]	training's multi_logloss: 0.990687	validation's multi_logloss: 1.00457
[27]	training's multi_logloss: 0.990687	validation's multi_logloss: 1.00457
[28]	training's multi_logloss: 0.990451	validation's multi_logloss: 1.00447
[29]	training's multi_logloss: 0.990451	validation's multi_logloss: 1.00447
[30]	training's multi_logloss: 0.990233	validation's multi_logloss: 1.00436
[31]	training's multi_logloss: 0.990233	validation's multi_logloss: 1.00436
[32]	training's multi_logloss: 0.989988	validation's multi_logloss: 1.00415
[33]	training's multi_logloss: 0.989748	validation's multi_logloss: 1.00397
[34]	training's multi_logloss: 0.989748	validation's multi_logloss: 1.00397
[35]	training's multi_logloss: 0.989748	validation's multi_logloss: 1.00397
[36]	training's multi_logloss: 0.989748	validation's multi_logloss: 1.00397
[37]	training's multi_logloss: 0.989748	validation's multi_logloss: 1.00397
[38]	training's multi_logloss: 0.989748	validation's multi_logloss: 1.00397
[39]	training's multi_logloss: 0.989748	validation's multi_logloss: 1.00397
[40]	training's multi_logloss: 0.989232	validation's multi_logloss: 1.00394
[41]	training's multi_logloss: 0.989232	validation's multi_logloss: 1.00394
[42]	training's multi_logloss: 0.989232	validation's multi_logloss: 1.00394
[43]	training's multi_logloss: 0.989232	validation's multi_logloss: 1.00394
[44]	training's multi_logloss: 0.989051	validation's multi_logloss: 1.00385
[45]	training's multi_logloss: 0.989051	validation's multi_logloss: 1.00385
[46]	training's multi_logloss: 0.989051	validation's multi_logloss: 1.00385
[47]	training's multi_logloss: 0.989051	validation's multi_logloss: 1.00385
[48]	training's multi_logloss: 0.988878	validation's multi_logloss: 1.00391
[49]	training's multi_logloss: 0.988878	validation's multi_logloss: 1.00391
[50]	training's multi_logloss: 0.988878	validation's multi_logloss: 1.00391
[51]	training's multi_logloss: 0.988878	validation's multi_logloss: 1.00391
[52]	training's multi_logloss: 0.988878	validation's multi_logloss: 1.00391
[53]	training's multi_logloss: 0.988878	validation's multi_logloss: 1.00391
[54]	training's multi_logloss: 0.988878	validation's multi_logloss: 1.00391
[55]	training's multi_logloss: 0.988878	validation's multi_logloss: 1.00391
[56]	training's multi_logloss: 0.988878	validation's multi_logloss: 1.00391
[57]	training's multi_logloss: 0.988878	validation's multi_logloss: 1.00391
[58]	training's multi_logloss: 0.988878	validation's multi_logloss: 1.00391
[59]	training's multi_logloss: 0.988671	validation's multi_logloss: 1.00378
[60]	training's multi_logloss: 0.988671	validation's multi_logloss: 1.00378
[61]	training's multi_logloss: 0.988484	validation's multi_logloss: 1.00381
[62]	training's multi_logloss: 0.988484	validation's multi_logloss: 1.00381
[63]	training's multi_logloss: 0.988484	validation's multi_logloss: 1.00381
[64]	training's multi_logloss: 0.988484	validation's multi_logloss: 1.00381
[65]	training's multi_logloss: 0.988484	validation's multi_logloss: 1.00381
[66]	training's multi_logloss: 0.988484	validation's multi_logloss: 1.00381
[67]	training's multi_logloss: 0.988484	validation's multi_logloss: 1.00381
[68]	training's multi_logloss: 0.988484	validation's multi_logloss: 1.00381
[69]	training's multi_logloss: 0.988484	validation's multi_logloss: 1.00381
[70]	training's multi_logloss: 0.988484	validation's multi_logloss: 1.00381
[71]	training's multi_logloss: 0.988484	validation's multi_logloss: 1.00381
[72]	training's multi_logloss: 0.988484	validation's multi_logloss: 1.00381
[73]	training's multi_logloss: 0.988484	validation's multi_logloss: 1.00381
[74]	training's multi_logloss: 0.988484	validation's multi_logloss: 1.00381
[75]	training's multi_logloss: 0.988484	validation's multi_logloss: 1.00381
[76]	training's multi_logloss: 0.988484	validation's multi_logloss: 1.00381
[77]	training's multi_logloss: 0.988484	validation's multi_logloss: 1.00381
[78]	training's multi_logloss: 0.988484	validation's multi_logloss: 1.00381
[79]	training's multi_logloss: 0.988484	validation's multi_logloss: 1.00381
Early stopping, best iteration is:
[59]	training's multi_logloss: 0.988671	validation's multi_logloss: 1.00378
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900
[LightGBM] [Warning] min_gain_to_split is set=7.372541584539943, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.372541584539943
[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04773	validation's multi_logloss: 1.04723
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03804	validation's multi_logloss: 1.03734
[3]	training's multi_logloss: 1.0301	validation's multi_logloss: 1.02972
[4]	training's multi_logloss: 1.02441	validation's multi_logloss: 1.02335
[5]	training's multi_logloss: 1.01972	validation's multi_logloss: 1.0191
[6]	training's multi_logloss: 1.01509	validation's multi_logloss: 1.01486
[7]	training's multi_logloss: 1.01159	validation's multi_logloss: 1.01167
[8]	training's multi_logloss: 1.00936	validation's multi_logloss: 1.00945
[9]	training's multi_logloss: 1.00754	validation's multi_logloss: 1.00758
[10]	training's multi_logloss: 1.00573	validation's multi_logloss: 1.00568
[11]	training's multi_logloss: 1.00389	validation's multi_logloss: 1.00482
[12]	training's multi_logloss: 1.00243	validation's multi_logloss: 1.00368
[13]	training's multi_logloss: 1.00111	validation's multi_logloss: 1.00255
[14]	training's multi_logloss: 1.00008	validation's multi_logloss: 1.00155
[15]	training's multi_logloss: 0.999361	validation's multi_logloss: 1.00104
[16]	training's multi_logloss: 0.998694	validation's multi_logloss: 1.00053
[17]	training's multi_logloss: 0.997941	validation's multi_logloss: 0.999777
[18]	training's multi_logloss: 0.997356	validation's multi_logloss: 0.999035
[19]	training's multi_logloss: 0.997098	validation's multi_logloss: 0.998912
[20]	training's multi_logloss: 0.996867	validation's multi_logloss: 0.998668
[21]	training's multi_logloss: 0.996867	validation's multi_logloss: 0.998668
[22]	training's multi_logloss: 0.996366	validation's multi_logloss: 0.998161
[23]	training's multi_logloss: 0.996366	validation's multi_logloss: 0.998161
[24]	training's multi_logloss: 0.996366	validation's multi_logloss: 0.998161
[25]	training's multi_logloss: 0.996134	validation's multi_logloss: 0.997863
[26]	training's multi_logloss: 0.996134	validation's multi_logloss: 0.997863
[27]	training's multi_logloss: 0.996134	validation's multi_logloss: 0.997863
[28]	training's multi_logloss: 0.995823	validation's multi_logloss: 0.997803
[29]	training's multi_logloss: 0.995823	validation's multi_logloss: 0.997803
[30]	training's multi_logloss: 0.995823	validation's multi_logloss: 0.997803
[31]	training's multi_logloss: 0.995823	validation's multi_logloss: 0.997803
[32]	training's multi_logloss: 0.99555	validation's multi_logloss: 0.997786
[33]	training's multi_logloss: 0.995343	validation's multi_logloss: 0.997349
[34]	training's multi_logloss: 0.99509	validation's multi_logloss: 0.99732
[35]	training's multi_logloss: 0.99509	validation's multi_logloss: 0.99732
[36]	training's multi_logloss: 0.99509	validation's multi_logloss: 0.99732
[37]	training's multi_logloss: 0.99509	validation's multi_logloss: 0.99732
[38]	training's multi_logloss: 0.99509	validation's multi_logloss: 0.99732
[39]	training's multi_logloss: 0.99509	validation's multi_logloss: 0.99732
[40]	training's multi_logloss: 0.99509	validation's multi_logloss: 0.99732
[41]	training's multi_logloss: 0.994854	validation's multi_logloss: 0.997076
[42]	training's multi_logloss: 0.994854	validation's multi_logloss: 0.997076
[43]	training's multi_logloss: 0.994854	validation's multi_logloss: 0.997076
[44]	training's multi_logloss: 0.994854	validation's multi_logloss: 0.997076
[45]	training's multi_logloss: 0.994427	validation's multi_logloss: 0.996528
[46]	training's multi_logloss: 0.994427	validation's multi_logloss: 0.996528
[47]	training's multi_logloss: 0.993992	validation's multi_logloss: 0.996117
[48]	training's multi_logloss: 0.993992	validation's multi_logloss: 0.996117
[49]	training's multi_logloss: 0.993992	validation's multi_logloss: 0.996117
[50]	training's multi_logloss: 0.993992	validation's multi_logloss: 0.996117
[51]	training's multi_logloss: 0.993992	validation's multi_logloss: 0.996117
[52]	training's multi_logloss: 0.993992	validation's multi_logloss: 0.996117
[53]	training's multi_logloss: 0.993992	validation's multi_logloss: 0.996117
[54]	training's multi_logloss: 0.993992	validation's multi_logloss: 0.996117
[55]	training's multi_logloss: 0.993992	validation's multi_logloss: 0.996117
[56]	training's multi_logloss: 0.993992	validation's multi_logloss: 0.996117
[57]	training's multi_logloss: 0.993992	validation's multi_logloss: 0.996117
[58]	training's multi_logloss: 0.993992	validation's multi_logloss: 0.996117
[59]	training's multi_logloss: 0.993992	validation's multi_logloss: 0.996117
[60]	training's multi_logloss: 0.993992	validation's multi_logloss: 0.996117
[61]	training's multi_logloss: 0.993992	validation's multi_logloss: 0.996117
[62]	training's multi_logloss: 0.993992	validation's multi_logloss: 0.996117
[63]	training's multi_logloss: 0.993992	validation's multi_logloss: 0.996117
[64]	training's multi_logloss: 0.993992	validation's multi_logloss: 0.996117
[65]	training's multi_logloss: 0.993786	validation's multi_logloss: 0.99618
[66]	training's multi_logloss: 0.993786	validation's multi_logloss: 0.99618
[67]	training's multi_logloss: 0.993786	validation's multi_logloss: 0.99618
Early stopping, best iteration is:
[47]	training's multi_logloss: 0.993992	validation's multi_logloss: 0.996117
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900
[LightGBM] [Warning] min_gain_to_split is set=7.372541584539943, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.372541584539943
[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04867	validation's multi_logloss: 1.04823
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03864	validation's multi_logloss: 1.03814
[3]	training's multi_logloss: 1.03112	validation's multi_logloss: 1.03104
[4]	training's multi_logloss: 1.02513	validation's multi_logloss: 1.02508
[5]	training's multi_logloss: 1.02024	validation's multi_logloss: 1.01996
[6]	training's multi_logloss: 1.01593	validation's multi_logloss: 1.01545
[7]	training's multi_logloss: 1.01229	validation's multi_logloss: 1.0128
[8]	training's multi_logloss: 1.00998	validation's multi_logloss: 1.01071
[9]	training's multi_logloss: 1.00717	validation's multi_logloss: 1.00772
[10]	training's multi_logloss: 1.00528	validation's multi_logloss: 1.00623
[11]	training's multi_logloss: 1.00319	validation's multi_logloss: 1.0042
[12]	training's multi_logloss: 1.0018	validation's multi_logloss: 1.00291
[13]	training's multi_logloss: 1.00104	validation's multi_logloss: 1.00263
[14]	training's multi_logloss: 0.999981	validation's multi_logloss: 1.00196
[15]	training's multi_logloss: 0.999355	validation's multi_logloss: 1.00142
[16]	training's multi_logloss: 0.999355	validation's multi_logloss: 1.00142
[17]	training's multi_logloss: 0.998463	validation's multi_logloss: 1.0005
[18]	training's multi_logloss: 0.997879	validation's multi_logloss: 0.999629
[19]	training's multi_logloss: 0.997357	validation's multi_logloss: 0.999411
[20]	training's multi_logloss: 0.997051	validation's multi_logloss: 0.999176
[21]	training's multi_logloss: 0.996302	validation's multi_logloss: 0.998254
[22]	training's multi_logloss: 0.99599	validation's multi_logloss: 0.998173
[23]	training's multi_logloss: 0.99599	validation's multi_logloss: 0.998173
[24]	training's multi_logloss: 0.99599	validation's multi_logloss: 0.998173
[25]	training's multi_logloss: 0.99599	validation's multi_logloss: 0.998173
[26]	training's multi_logloss: 0.995517	validation's multi_logloss: 0.997835
[27]	training's multi_logloss: 0.995517	validation's multi_logloss: 0.997835
[28]	training's multi_logloss: 0.995517	validation's multi_logloss: 0.997835
[29]	training's multi_logloss: 0.995517	validation's multi_logloss: 0.997835
[30]	training's multi_logloss: 0.995517	validation's multi_logloss: 0.997835
[31]	training's multi_logloss: 0.995517	validation's multi_logloss: 0.997835
[32]	training's multi_logloss: 0.995517	validation's multi_logloss: 0.997835
[33]	training's multi_logloss: 0.995517	validation's multi_logloss: 0.997835
[34]	training's multi_logloss: 0.995517	validation's multi_logloss: 0.997835
[35]	training's multi_logloss: 0.995517	validation's multi_logloss: 0.997835
[36]	training's multi_logloss: 0.995517	validation's multi_logloss: 0.997835
[37]	training's multi_logloss: 0.995517	validation's multi_logloss: 0.997835
[38]	training's multi_logloss: 0.995517	validation's multi_logloss: 0.997835
[39]	training's multi_logloss: 0.995517	validation's multi_logloss: 0.997835
[40]	training's multi_logloss: 0.995517	validation's multi_logloss: 0.997835
[41]	training's multi_logloss: 0.995517	validation's multi_logloss: 0.997835
[42]	training's multi_logloss: 0.995232	validation's multi_logloss: 0.99762
[43]	training's multi_logloss: 0.995	validation's multi_logloss: 0.997662
[44]	training's multi_logloss: 0.995	validation's multi_logloss: 0.997662
[45]	training's multi_logloss: 0.994735	validation's multi_logloss: 0.997428
[46]	training's multi_logloss: 0.994735	validation's multi_logloss: 0.997428
[47]	training's multi_logloss: 0.994735	validation's multi_logloss: 0.997428
[48]	training's multi_logloss: 0.994735	validation's multi_logloss: 0.997428
[49]	training's multi_logloss: 0.994528	validation's multi_logloss: 0.997377
[50]	training's multi_logloss: 0.994528	validation's multi_logloss: 0.997377
[51]	training's multi_logloss: 0.994327	validation's multi_logloss: 0.997173
[52]	training's multi_logloss: 0.994327	validation's multi_logloss: 0.997173
[53]	training's multi_logloss: 0.994327	validation's multi_logloss: 0.997173
[54]	training's multi_logloss: 0.994327	validation's multi_logloss: 0.997173
[55]	training's multi_logloss: 0.994327	validation's multi_logloss: 0.997173
[56]	training's multi_logloss: 0.994327	validation's multi_logloss: 0.997173
[57]	training's multi_logloss: 0.994327	validation's multi_logloss: 0.997173
[58]	training's multi_logloss: 0.994327	validation's multi_logloss: 0.997173
[59]	training's multi_logloss: 0.994327	validation's multi_logloss: 0.997173
[60]	training's multi_logloss: 0.993913	validation's multi_logloss: 0.996752
[61]	training's multi_logloss: 0.993913	validation's multi_logloss: 0.996752
[62]	training's multi_logloss: 0.993913	validation's multi_logloss: 0.996752
[63]	training's multi_logloss: 0.993913	validation's multi_logloss: 0.996752
[64]	training's multi_logloss: 0.993913	validation's multi_logloss: 0.996752
[65]	training's multi_logloss: 0.993913	validation's multi_logloss: 0.996752
[66]	training's multi_logloss: 0.993913	validation's multi_logloss: 0.996752
[67]	training's multi_logloss: 0.993913	validation's multi_logloss: 0.996752
[68]	training's multi_logloss: 0.993913	validation's multi_logloss: 0.996752
[69]	training's multi_logloss: 0.993913	validation's multi_logloss: 0.996752
[70]	training's multi_logloss: 0.993913	validation's multi_logloss: 0.996752
[71]	training's multi_logloss: 0.993913	validation's multi_logloss: 0.996752
[72]	training's multi_logloss: 0.993913	validation's multi_logloss: 0.996752
[73]	training's multi_logloss: 0.993913	validation's multi_logloss: 0.996752
[74]	training's multi_logloss: 0.993913	validation's multi_logloss: 0.996752
[75]	training's multi_logloss: 0.993913	validation's multi_logloss: 0.996752
[76]	training's multi_logloss: 0.993913	validation's multi_logloss: 0.996752
[77]	training's multi_logloss: 0.993913	validation's multi_logloss: 0.996752
[78]	training's multi_logloss: 0.993913	validation's multi_logloss: 0.996752
[79]	training's multi_logloss: 0.993717	validation's multi_logloss: 0.996473
[80]	training's multi_logloss: 0.993717	validation's multi_logloss: 0.996473
[81]	training's multi_logloss: 0.993717	validation's multi_logloss: 0.996473
[82]	training's multi_logloss: 0.993717	validation's multi_logloss: 0.996473
[83]	training's multi_logloss: 0.993717	validation's multi_logloss: 0.996473
[84]	training's multi_logloss: 0.993717	validation's multi_logloss: 0.996473
[85]	training's multi_logloss: 0.993717	validation's multi_logloss: 0.996473
[86]	training's multi_logloss: 0.993502	validation's multi_logloss: 0.996483
[87]	training's multi_logloss: 0.993348	validation's multi_logloss: 0.996507
[88]	training's multi_logloss: 0.993348	validation's multi_logloss: 0.996507
[89]	training's multi_logloss: 0.993129	validation's multi_logloss: 0.996234
[90]	training's multi_logloss: 0.993129	validation's multi_logloss: 0.996234
[91]	training's multi_logloss: 0.992945	validation's multi_logloss: 0.996194
[92]	training's multi_logloss: 0.992945	validation's multi_logloss: 0.996194
[93]	training's multi_logloss: 0.992945	validation's multi_logloss: 0.996194
[94]	training's multi_logloss: 0.992945	validation's multi_logloss: 0.996194
[95]	training's multi_logloss: 0.992945	validation's multi_logloss: 0.996194
[96]	training's multi_logloss: 0.992945	validation's multi_logloss: 0.996194
[97]	training's multi_logloss: 0.992945	validation's multi_logloss: 0.996194
[98]	training's multi_logloss: 0.992758	validation's multi_logloss: 0.996291
[99]	training's multi_logloss: 0.992758	validation's multi_logloss: 0.996291
[100]	training's multi_logloss: 0.992758	validation's multi_logloss: 0.996291
Did not meet early stopping. Best iteration is:
[98]	training's multi_logloss: 0.992758	validation's multi_logloss: 0.996291
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900
[LightGBM] [Warning] min_gain_to_split is set=7.372541584539943, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.372541584539943
[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04682	validation's multi_logloss: 1.04976
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03579	validation's multi_logloss: 1.04168
[3]	training's multi_logloss: 1.02822	validation's multi_logloss: 1.03606
[4]	training's multi_logloss: 1.02102	validation's multi_logloss: 1.03056
[5]	training's multi_logloss: 1.01519	validation's multi_logloss: 1.02595
[6]	training's multi_logloss: 1.01129	validation's multi_logloss: 1.02298
[7]	training's multi_logloss: 1.00782	validation's multi_logloss: 1.02058
[8]	training's multi_logloss: 1.0046	validation's multi_logloss: 1.01841
[9]	training's multi_logloss: 1.00219	validation's multi_logloss: 1.01715
[10]	training's multi_logloss: 0.999927	validation's multi_logloss: 1.01572
[11]	training's multi_logloss: 0.998693	validation's multi_logloss: 1.01517
[12]	training's multi_logloss: 0.997167	validation's multi_logloss: 1.01452
[13]	training's multi_logloss: 0.996021	validation's multi_logloss: 1.014
[14]	training's multi_logloss: 0.995202	validation's multi_logloss: 1.01357
[15]	training's multi_logloss: 0.99482	validation's multi_logloss: 1.01344
[16]	training's multi_logloss: 0.994121	validation's multi_logloss: 1.01288
[17]	training's multi_logloss: 0.993253	validation's multi_logloss: 1.01275
[18]	training's multi_logloss: 0.992426	validation's multi_logloss: 1.01249
[19]	training's multi_logloss: 0.992151	validation's multi_logloss: 1.01226
[20]	training's multi_logloss: 0.99194	validation's multi_logloss: 1.01209
[21]	training's multi_logloss: 0.991281	validation's multi_logloss: 1.0118
[22]	training's multi_logloss: 0.991037	validation's multi_logloss: 1.01159
[23]	training's multi_logloss: 0.991037	validation's multi_logloss: 1.01159
[24]	training's multi_logloss: 0.990535	validation's multi_logloss: 1.01099
[25]	training's multi_logloss: 0.990203	validation's multi_logloss: 1.01086
[26]	training's multi_logloss: 0.989892	validation's multi_logloss: 1.01084
[27]	training's multi_logloss: 0.989892	validation's multi_logloss: 1.01084
[28]	training's multi_logloss: 0.989892	validation's multi_logloss: 1.01084
[29]	training's multi_logloss: 0.989505	validation's multi_logloss: 1.01077
[30]	training's multi_logloss: 0.989505	validation's multi_logloss: 1.01077
[31]	training's multi_logloss: 0.989257	validation's multi_logloss: 1.01082
[32]	training's multi_logloss: 0.989257	validation's multi_logloss: 1.01082
[33]	training's multi_logloss: 0.989257	validation's multi_logloss: 1.01082
[34]	training's multi_logloss: 0.989257	validation's multi_logloss: 1.01082
[35]	training's multi_logloss: 0.989062	validation's multi_logloss: 1.01062
[36]	training's multi_logloss: 0.989062	validation's multi_logloss: 1.01062
[37]	training's multi_logloss: 0.989062	validation's multi_logloss: 1.01062
[38]	training's multi_logloss: 0.989062	validation's multi_logloss: 1.01062
[39]	training's multi_logloss: 0.989062	validation's multi_logloss: 1.01062
[40]	training's multi_logloss: 0.989062	validation's multi_logloss: 1.01062
[41]	training's multi_logloss: 0.989062	validation's multi_logloss: 1.01062
[42]	training's multi_logloss: 0.98878	validation's multi_logloss: 1.01062
[43]	training's multi_logloss: 0.98878	validation's multi_logloss: 1.01062
[44]	training's multi_logloss: 0.98878	validation's multi_logloss: 1.01062
[45]	training's multi_logloss: 0.98878	validation's multi_logloss: 1.01062
[46]	training's multi_logloss: 0.98878	validation's multi_logloss: 1.01062
[47]	training's multi_logloss: 0.98878	validation's multi_logloss: 1.01062
[48]	training's multi_logloss: 0.98878	validation's multi_logloss: 1.01062
[49]	training's multi_logloss: 0.98878	validation's multi_logloss: 1.01062
[50]	training's multi_logloss: 0.98878	validation's multi_logloss: 1.01062
[51]	training's multi_logloss: 0.98878	validation's multi_logloss: 1.01062
[52]	training's multi_logloss: 0.98878	validation's multi_logloss: 1.01062
[53]	training's multi_logloss: 0.988516	validation's multi_logloss: 1.01066
[54]	training's multi_logloss: 0.988516	validation's multi_logloss: 1.01066
[55]	training's multi_logloss: 0.988292	validation's multi_logloss: 1.01044
[56]	training's multi_logloss: 0.988292	validation's multi_logloss: 1.01044
[57]	training's multi_logloss: 0.988292	validation's multi_logloss: 1.01044
[58]	training's multi_logloss: 0.988292	validation's multi_logloss: 1.01044
[59]	training's multi_logloss: 0.988106	validation's multi_logloss: 1.01036
[60]	training's multi_logloss: 0.98791	validation's multi_logloss: 1.01029
[61]	training's multi_logloss: 0.98791	validation's multi_logloss: 1.01029
[62]	training's multi_logloss: 0.98791	validation's multi_logloss: 1.01029
[63]	training's multi_logloss: 0.98791	validation's multi_logloss: 1.01029
[64]	training's multi_logloss: 0.98791	validation's multi_logloss: 1.01029
[65]	training's multi_logloss: 0.98791	validation's multi_logloss: 1.01029
[66]	training's multi_logloss: 0.98768	validation's multi_logloss: 1.01021
[67]	training's multi_logloss: 0.98768	validation's multi_logloss: 1.01021
[68]	training's multi_logloss: 0.98768	validation's multi_logloss: 1.01021
[69]	training's multi_logloss: 0.98768	validation's multi_logloss: 1.01021
[70]	training's multi_logloss: 0.98768	validation's multi_logloss: 1.01021
[71]	training's multi_logloss: 0.987463	validation's multi_logloss: 1.0102
[72]	training's multi_logloss: 0.987463	validation's multi_logloss: 1.0102
[73]	training's multi_logloss: 0.987463	validation's multi_logloss: 1.0102
[74]	training's multi_logloss: 0.987463	validation's multi_logloss: 1.0102
[75]	training's multi_logloss: 0.987251	validation's multi_logloss: 1.01024
[76]	training's multi_logloss: 0.987251	validation's multi_logloss: 1.01024
[77]	training's multi_logloss: 0.987251	validation's multi_logloss: 1.01024
[78]	training's multi_logloss: 0.987251	validation's multi_logloss: 1.01024
[79]	training's multi_logloss: 0.987251	validation's multi_logloss: 1.01024
[80]	training's multi_logloss: 0.987088	validation's multi_logloss: 1.01004
[81]	training's multi_logloss: 0.987088	validation's multi_logloss: 1.01004
[82]	training's multi_logloss: 0.987088	validation's multi_logloss: 1.01004
[83]	training's multi_logloss: 0.987088	validation's multi_logloss: 1.01004
[84]	training's multi_logloss: 0.987088	validation's multi_logloss: 1.01004
[85]	training's multi_logloss: 0.987088	validation's multi_logloss: 1.01004
[86]	training's multi_logloss: 0.987088	validation's multi_logloss: 1.01004
[87]	training's multi_logloss: 0.987088	validation's multi_logloss: 1.01004
[88]	training's multi_logloss: 0.987088	validation's multi_logloss: 1.01004
[89]	training's multi_logloss: 0.987088	validation's multi_logloss: 1.01004
[90]	training's multi_logloss: 0.987088	validation's multi_logloss: 1.01004
[91]	training's multi_logloss: 0.987088	validation's multi_logloss: 1.01004
[92]	training's multi_logloss: 0.987088	validation's multi_logloss: 1.01004
[93]	training's multi_logloss: 0.986923	validation's multi_logloss: 1.00993
[94]	training's multi_logloss: 0.986923	validation's multi_logloss: 1.00993
[95]	training's multi_logloss: 0.986923	validation's multi_logloss: 1.00993
[96]	training's multi_logloss: 0.986923	validation's multi_logloss: 1.00993
[97]	training's multi_logloss: 0.986923	validation's multi_logloss: 1.00993
[98]	training's multi_logloss: 0.986923	validation's multi_logloss: 1.00993
[99]	training's multi_logloss: 0.986803	validation's multi_logloss: 1.00984
[100]	training's multi_logloss: 0.986803	validation's multi_logloss: 1.00984
Did not meet early stopping. Best iteration is:
[99]	training's multi_logloss: 0.986803	validation's multi_logloss: 1.00984
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900
[LightGBM] [Warning] min_gain_to_split is set=7.372541584539943, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.372541584539943
[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04752	validation's multi_logloss: 1.0483
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03824	validation's multi_logloss: 1.04059
[3]	training's multi_logloss: 1.02978	validation's multi_logloss: 1.03302
[4]	training's multi_logloss: 1.02422	validation's multi_logloss: 1.02811
[5]	training's multi_logloss: 1.01889	validation's multi_logloss: 1.02369
[6]	training's multi_logloss: 1.01494	validation's multi_logloss: 1.02058
[7]	training's multi_logloss: 1.0111	validation's multi_logloss: 1.01752
[8]	training's multi_logloss: 1.00802	validation's multi_logloss: 1.0152
[9]	training's multi_logloss: 1.00554	validation's multi_logloss: 1.01292
[10]	training's multi_logloss: 1.0034	validation's multi_logloss: 1.01164
[11]	training's multi_logloss: 1.00194	validation's multi_logloss: 1.01073
[12]	training's multi_logloss: 1.0004	validation's multi_logloss: 1.0099
[13]	training's multi_logloss: 0.999472	validation's multi_logloss: 1.00911
[14]	training's multi_logloss: 0.998793	validation's multi_logloss: 1.00885
[15]	training's multi_logloss: 0.998046	validation's multi_logloss: 1.00861
[16]	training's multi_logloss: 0.997387	validation's multi_logloss: 1.00796
[17]	training's multi_logloss: 0.996497	validation's multi_logloss: 1.00744
[18]	training's multi_logloss: 0.99589	validation's multi_logloss: 1.00663
[19]	training's multi_logloss: 0.995515	validation's multi_logloss: 1.00625
[20]	training's multi_logloss: 0.995515	validation's multi_logloss: 1.00625
[21]	training's multi_logloss: 0.99495	validation's multi_logloss: 1.00617
[22]	training's multi_logloss: 0.994179	validation's multi_logloss: 1.00566
[23]	training's multi_logloss: 0.993938	validation's multi_logloss: 1.00548
[24]	training's multi_logloss: 0.993938	validation's multi_logloss: 1.00548
[25]	training's multi_logloss: 0.993627	validation's multi_logloss: 1.00527
[26]	training's multi_logloss: 0.993627	validation's multi_logloss: 1.00527
[27]	training's multi_logloss: 0.993627	validation's multi_logloss: 1.00527
[28]	training's multi_logloss: 0.993627	validation's multi_logloss: 1.00527
[29]	training's multi_logloss: 0.993627	validation's multi_logloss: 1.00527
[30]	training's multi_logloss: 0.993627	validation's multi_logloss: 1.00527
[31]	training's multi_logloss: 0.993627	validation's multi_logloss: 1.00527
[32]	training's multi_logloss: 0.993627	validation's multi_logloss: 1.00527
[33]	training's multi_logloss: 0.993627	validation's multi_logloss: 1.00527
[34]	training's multi_logloss: 0.993627	validation's multi_logloss: 1.00527
[35]	training's multi_logloss: 0.993627	validation's multi_logloss: 1.00527
[36]	training's multi_logloss: 0.993381	validation's multi_logloss: 1.0052
[37]	training's multi_logloss: 0.993381	validation's multi_logloss: 1.0052
[38]	training's multi_logloss: 0.993381	validation's multi_logloss: 1.0052
[39]	training's multi_logloss: 0.993101	validation's multi_logloss: 1.00509
[40]	training's multi_logloss: 0.99267	validation's multi_logloss: 1.00498
[41]	training's multi_logloss: 0.99267	validation's multi_logloss: 1.00498
[42]	training's multi_logloss: 0.99267	validation's multi_logloss: 1.00498
[43]	training's multi_logloss: 0.99267	validation's multi_logloss: 1.00498
[44]	training's multi_logloss: 0.99267	validation's multi_logloss: 1.00498
[45]	training's multi_logloss: 0.992418	validation's multi_logloss: 1.00481
[46]	training's multi_logloss: 0.992136	validation's multi_logloss: 1.00463
[47]	training's multi_logloss: 0.992136	validation's multi_logloss: 1.00463
[48]	training's multi_logloss: 0.992136	validation's multi_logloss: 1.00463
[49]	training's multi_logloss: 0.992136	validation's multi_logloss: 1.00463
[50]	training's multi_logloss: 0.99199	validation's multi_logloss: 1.00472
[51]	training's multi_logloss: 0.99199	validation's multi_logloss: 1.00472
[52]	training's multi_logloss: 0.99199	validation's multi_logloss: 1.00472
[53]	training's multi_logloss: 0.99199	validation's multi_logloss: 1.00472
[54]	training's multi_logloss: 0.991742	validation's multi_logloss: 1.00458
[55]	training's multi_logloss: 0.991742	validation's multi_logloss: 1.00458
[56]	training's multi_logloss: 0.991742	validation's multi_logloss: 1.00458
[57]	training's multi_logloss: 0.991742	validation's multi_logloss: 1.00458
[58]	training's multi_logloss: 0.991512	validation's multi_logloss: 1.00441
[59]	training's multi_logloss: 0.991512	validation's multi_logloss: 1.00441
[60]	training's multi_logloss: 0.991293	validation's multi_logloss: 1.0043
[61]	training's multi_logloss: 0.991293	validation's multi_logloss: 1.0043
[62]	training's multi_logloss: 0.991293	validation's multi_logloss: 1.0043
[63]	training's multi_logloss: 0.991293	validation's multi_logloss: 1.0043
[64]	training's multi_logloss: 0.991293	validation's multi_logloss: 1.0043
[65]	training's multi_logloss: 0.991293	validation's multi_logloss: 1.0043
[66]	training's multi_logloss: 0.991293	validation's multi_logloss: 1.0043
[67]	training's multi_logloss: 0.991293	validation's multi_logloss: 1.0043
[68]	training's multi_logloss: 0.991293	validation's multi_logloss: 1.0043
[69]	training's multi_logloss: 0.991293	validation's multi_logloss: 1.0043
[70]	training's multi_logloss: 0.991293	validation's multi_logloss: 1.0043
[71]	training's multi_logloss: 0.991293	validation's multi_logloss: 1.0043
[72]	training's multi_logloss: 0.991293	validation's multi_logloss: 1.0043
[73]	training's multi_logloss: 0.991293	validation's multi_logloss: 1.0043
[74]	training's multi_logloss: 0.991293	validation's multi_logloss: 1.0043
[75]	training's multi_logloss: 0.991293	validation's multi_logloss: 1.0043
[76]	training's multi_logloss: 0.991293	validation's multi_logloss: 1.0043
[77]	training's multi_logloss: 0.9911	validation's multi_logloss: 1.00412
[78]	training's multi_logloss: 0.9911	validation's multi_logloss: 1.00412
[79]	training's multi_logloss: 0.99089	validation's multi_logloss: 1.00383
[80]	training's multi_logloss: 0.99089	validation's multi_logloss: 1.00383
[81]	training's multi_logloss: 0.99089	validation's multi_logloss: 1.00383
[82]	training's multi_logloss: 0.99089	validation's multi_logloss: 1.00383
[83]	training's multi_logloss: 0.99089	validation's multi_logloss: 1.00383
[84]	training's multi_logloss: 0.99089	validation's multi_logloss: 1.00383
[85]	training's multi_logloss: 0.99089	validation's multi_logloss: 1.00383
[86]	training's multi_logloss: 0.99089	validation's multi_logloss: 1.00383
[87]	training's multi_logloss: 0.99089	validation's multi_logloss: 1.00383
[88]	training's multi_logloss: 0.99089	validation's multi_logloss: 1.00383
[89]	training's multi_logloss: 0.990671	validation's multi_logloss: 1.00383
[90]	training's multi_logloss: 0.990671	validation's multi_logloss: 1.00383
[91]	training's multi_logloss: 0.990671	validation's multi_logloss: 1.00383
[92]	training's multi_logloss: 0.990671	validation's multi_logloss: 1.00383
[93]	training's multi_logloss: 0.990671	validation's multi_logloss: 1.00383
[94]	training's multi_logloss: 0.990671	validation's multi_logloss: 1.00383
[95]	training's multi_logloss: 0.990671	validation's multi_logloss: 1.00383
[96]	training's multi_logloss: 0.990671	validation's multi_logloss: 1.00383
[97]	training's multi_logloss: 0.990671	validation's multi_logloss: 1.00383
[98]	training's multi_logloss: 0.990671	validation's multi_logloss: 1.00383
[99]	training's multi_logloss: 0.990671	validation's multi_logloss: 1.00383
Early stopping, best iteration is:
[79]	training's multi_logloss: 0.99089	validation's multi_logloss: 1.00383
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900
[LightGBM] [Warning] min_gain_to_split is set=7.14225713214365, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.14225713214365
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04743	validation's multi_logloss: 1.04695
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03781	validation's multi_logloss: 1.03718
[3]	training's multi_logloss: 1.02986	validation's multi_logloss: 1.02961
[4]	training's multi_logloss: 1.02378	validation's multi_logloss: 1.02316
[5]	training's multi_logloss: 1.01901	validation's multi_logloss: 1.01826
[6]	training's multi_logloss: 1.01431	validation's multi_logloss: 1.01395
[7]	training's multi_logloss: 1.01072	validation's multi_logloss: 1.01133
[8]	training's multi_logloss: 1.00815	validation's multi_logloss: 1.00934
[9]	training's multi_logloss: 1.00597	validation's multi_logloss: 1.00702
[10]	training's multi_logloss: 1.00419	validation's multi_logloss: 1.00513
[11]	training's multi_logloss: 1.00235	validation's multi_logloss: 1.00423
[12]	training's multi_logloss: 1.00069	validation's multi_logloss: 1.00291
[13]	training's multi_logloss: 0.999553	validation's multi_logloss: 1.00173
[14]	training's multi_logloss: 0.99844	validation's multi_logloss: 1.00067
[15]	training's multi_logloss: 0.997756	validation's multi_logloss: 1.00009
[16]	training's multi_logloss: 0.997128	validation's multi_logloss: 0.999618
[17]	training's multi_logloss: 0.996464	validation's multi_logloss: 0.998955
[18]	training's multi_logloss: 0.995906	validation's multi_logloss: 0.99824
[19]	training's multi_logloss: 0.995693	validation's multi_logloss: 0.998155
[20]	training's multi_logloss: 0.995233	validation's multi_logloss: 0.997697
[21]	training's multi_logloss: 0.99505	validation's multi_logloss: 0.997516
[22]	training's multi_logloss: 0.994613	validation's multi_logloss: 0.997089
[23]	training's multi_logloss: 0.994464	validation's multi_logloss: 0.997057
[24]	training's multi_logloss: 0.994464	validation's multi_logloss: 0.997057
[25]	training's multi_logloss: 0.994142	validation's multi_logloss: 0.996746
[26]	training's multi_logloss: 0.993883	validation's multi_logloss: 0.99671
[27]	training's multi_logloss: 0.993669	validation's multi_logloss: 0.996594
[28]	training's multi_logloss: 0.993445	validation's multi_logloss: 0.996594
[29]	training's multi_logloss: 0.993445	validation's multi_logloss: 0.996594
[30]	training's multi_logloss: 0.993445	validation's multi_logloss: 0.996594
[31]	training's multi_logloss: 0.993445	validation's multi_logloss: 0.996594
[32]	training's multi_logloss: 0.993061	validation's multi_logloss: 0.996319
[33]	training's multi_logloss: 0.992893	validation's multi_logloss: 0.995926
[34]	training's multi_logloss: 0.992893	validation's multi_logloss: 0.995926
[35]	training's multi_logloss: 0.992893	validation's multi_logloss: 0.995926
[36]	training's multi_logloss: 0.992893	validation's multi_logloss: 0.995926
[37]	training's multi_logloss: 0.992893	validation's multi_logloss: 0.995926
[38]	training's multi_logloss: 0.992893	validation's multi_logloss: 0.995926
[39]	training's multi_logloss: 0.992893	validation's multi_logloss: 0.995926
[40]	training's multi_logloss: 0.992893	validation's multi_logloss: 0.995926
[41]	training's multi_logloss: 0.992893	validation's multi_logloss: 0.995926
[42]	training's multi_logloss: 0.992893	validation's multi_logloss: 0.995926
[43]	training's multi_logloss: 0.992893	validation's multi_logloss: 0.995926
[44]	training's multi_logloss: 0.992893	validation's multi_logloss: 0.995926
[45]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995447
[46]	training's multi_logloss: 0.992531	validation's multi_logloss: 0.995447
[47]	training's multi_logloss: 0.992164	validation's multi_logloss: 0.995117
[48]	training's multi_logloss: 0.992164	validation's multi_logloss: 0.995117
[49]	training's multi_logloss: 0.992164	validation's multi_logloss: 0.995117
[50]	training's multi_logloss: 0.992164	validation's multi_logloss: 0.995117
[51]	training's multi_logloss: 0.992164	validation's multi_logloss: 0.995117
[52]	training's multi_logloss: 0.991966	validation's multi_logloss: 0.994985
[53]	training's multi_logloss: 0.991966	validation's multi_logloss: 0.994985
[54]	training's multi_logloss: 0.991966	validation's multi_logloss: 0.994985
[55]	training's multi_logloss: 0.991966	validation's multi_logloss: 0.994985
[56]	training's multi_logloss: 0.991966	validation's multi_logloss: 0.994985
[57]	training's multi_logloss: 0.991966	validation's multi_logloss: 0.994985
[58]	training's multi_logloss: 0.991966	validation's multi_logloss: 0.994985
[59]	training's multi_logloss: 0.991803	validation's multi_logloss: 0.994959
[60]	training's multi_logloss: 0.991803	validation's multi_logloss: 0.994959
[61]	training's multi_logloss: 0.991803	validation's multi_logloss: 0.994959
[62]	training's multi_logloss: 0.991803	validation's multi_logloss: 0.994959
[63]	training's multi_logloss: 0.991803	validation's multi_logloss: 0.994959
[64]	training's multi_logloss: 0.991803	validation's multi_logloss: 0.994959
[65]	training's multi_logloss: 0.991663	validation's multi_logloss: 0.99504
[66]	training's multi_logloss: 0.991663	validation's multi_logloss: 0.99504
[67]	training's multi_logloss: 0.991663	validation's multi_logloss: 0.99504
[68]	training's multi_logloss: 0.991663	validation's multi_logloss: 0.99504
[69]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[70]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[71]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[72]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[73]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[74]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[75]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[76]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[77]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[78]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[79]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[80]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[81]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[82]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[83]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[84]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[85]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[86]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[87]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[88]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[89]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
Early stopping, best iteration is:
[69]	training's multi_logloss: 0.991475	validation's multi_logloss: 0.994805
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900
[LightGBM] [Warning] min_gain_to_split is set=7.14225713214365, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.14225713214365
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04861	validation's multi_logloss: 1.04819
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03825	validation's multi_logloss: 1.03733
[3]	training's multi_logloss: 1.0308	validation's multi_logloss: 1.03032
[4]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02424
[5]	training's multi_logloss: 1.01957	validation's multi_logloss: 1.01899
[6]	training's multi_logloss: 1.01542	validation's multi_logloss: 1.01467
[7]	training's multi_logloss: 1.01178	validation's multi_logloss: 1.01203
[8]	training's multi_logloss: 1.00938	validation's multi_logloss: 1.00987
[9]	training's multi_logloss: 1.00655	validation's multi_logloss: 1.00686
[10]	training's multi_logloss: 1.00468	validation's multi_logloss: 1.00541
[11]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00338
[12]	training's multi_logloss: 1.00092	validation's multi_logloss: 1.00202
[13]	training's multi_logloss: 1.00021	validation's multi_logloss: 1.0018
[14]	training's multi_logloss: 0.999201	validation's multi_logloss: 1.00118
[15]	training's multi_logloss: 0.998368	validation's multi_logloss: 1.00056
[16]	training's multi_logloss: 0.99782	validation's multi_logloss: 1.00001
[17]	training's multi_logloss: 0.997002	validation's multi_logloss: 0.999177
[18]	training's multi_logloss: 0.996508	validation's multi_logloss: 0.998385
[19]	training's multi_logloss: 0.995988	validation's multi_logloss: 0.998185
[20]	training's multi_logloss: 0.995716	validation's multi_logloss: 0.997986
[21]	training's multi_logloss: 0.995091	validation's multi_logloss: 0.997138
[22]	training's multi_logloss: 0.994852	validation's multi_logloss: 0.997109
[23]	training's multi_logloss: 0.994642	validation's multi_logloss: 0.997038
[24]	training's multi_logloss: 0.994421	validation's multi_logloss: 0.997078
[25]	training's multi_logloss: 0.994421	validation's multi_logloss: 0.997078
[26]	training's multi_logloss: 0.993989	validation's multi_logloss: 0.996782
[27]	training's multi_logloss: 0.993989	validation's multi_logloss: 0.996782
[28]	training's multi_logloss: 0.993989	validation's multi_logloss: 0.996782
[29]	training's multi_logloss: 0.993989	validation's multi_logloss: 0.996782
[30]	training's multi_logloss: 0.993829	validation's multi_logloss: 0.996684
[31]	training's multi_logloss: 0.993829	validation's multi_logloss: 0.996684
[32]	training's multi_logloss: 0.993829	validation's multi_logloss: 0.996684
[33]	training's multi_logloss: 0.993829	validation's multi_logloss: 0.996684
[34]	training's multi_logloss: 0.993829	validation's multi_logloss: 0.996684
[35]	training's multi_logloss: 0.993829	validation's multi_logloss: 0.996684
[36]	training's multi_logloss: 0.993829	validation's multi_logloss: 0.996684
[37]	training's multi_logloss: 0.993829	validation's multi_logloss: 0.996684
[38]	training's multi_logloss: 0.993829	validation's multi_logloss: 0.996684
[39]	training's multi_logloss: 0.993829	validation's multi_logloss: 0.996684
[40]	training's multi_logloss: 0.993829	validation's multi_logloss: 0.996684
[41]	training's multi_logloss: 0.993829	validation's multi_logloss: 0.996684
[42]	training's multi_logloss: 0.993356	validation's multi_logloss: 0.996286
[43]	training's multi_logloss: 0.993186	validation's multi_logloss: 0.996369
[44]	training's multi_logloss: 0.993186	validation's multi_logloss: 0.996369
[45]	training's multi_logloss: 0.992995	validation's multi_logloss: 0.996143
[46]	training's multi_logloss: 0.992995	validation's multi_logloss: 0.996143
[47]	training's multi_logloss: 0.992995	validation's multi_logloss: 0.996143
[48]	training's multi_logloss: 0.992995	validation's multi_logloss: 0.996143
[49]	training's multi_logloss: 0.992807	validation's multi_logloss: 0.996112
[50]	training's multi_logloss: 0.992807	validation's multi_logloss: 0.996112
[51]	training's multi_logloss: 0.992645	validation's multi_logloss: 0.995954
[52]	training's multi_logloss: 0.992645	validation's multi_logloss: 0.995954
[53]	training's multi_logloss: 0.992645	validation's multi_logloss: 0.995954
[54]	training's multi_logloss: 0.992645	validation's multi_logloss: 0.995954
[55]	training's multi_logloss: 0.992645	validation's multi_logloss: 0.995954
[56]	training's multi_logloss: 0.992645	validation's multi_logloss: 0.995954
[57]	training's multi_logloss: 0.992645	validation's multi_logloss: 0.995954
[58]	training's multi_logloss: 0.992645	validation's multi_logloss: 0.995954
[59]	training's multi_logloss: 0.992645	validation's multi_logloss: 0.995954
[60]	training's multi_logloss: 0.992297	validation's multi_logloss: 0.99549
[61]	training's multi_logloss: 0.992297	validation's multi_logloss: 0.99549
[62]	training's multi_logloss: 0.992297	validation's multi_logloss: 0.99549
[63]	training's multi_logloss: 0.992297	validation's multi_logloss: 0.99549
[64]	training's multi_logloss: 0.992297	validation's multi_logloss: 0.99549
[65]	training's multi_logloss: 0.992297	validation's multi_logloss: 0.99549
[66]	training's multi_logloss: 0.992297	validation's multi_logloss: 0.99549
[67]	training's multi_logloss: 0.992297	validation's multi_logloss: 0.99549
[68]	training's multi_logloss: 0.992297	validation's multi_logloss: 0.99549
[69]	training's multi_logloss: 0.992297	validation's multi_logloss: 0.99549
[70]	training's multi_logloss: 0.992297	validation's multi_logloss: 0.99549
[71]	training's multi_logloss: 0.992192	validation's multi_logloss: 0.995453
[72]	training's multi_logloss: 0.992192	validation's multi_logloss: 0.995453
[73]	training's multi_logloss: 0.992192	validation's multi_logloss: 0.995453
[74]	training's multi_logloss: 0.992192	validation's multi_logloss: 0.995453
[75]	training's multi_logloss: 0.992192	validation's multi_logloss: 0.995453
[76]	training's multi_logloss: 0.992062	validation's multi_logloss: 0.995477
[77]	training's multi_logloss: 0.992062	validation's multi_logloss: 0.995477
[78]	training's multi_logloss: 0.992062	validation's multi_logloss: 0.995477
[79]	training's multi_logloss: 0.99175	validation's multi_logloss: 0.995179
[80]	training's multi_logloss: 0.99175	validation's multi_logloss: 0.995179
[81]	training's multi_logloss: 0.991645	validation's multi_logloss: 0.995051
[82]	training's multi_logloss: 0.991645	validation's multi_logloss: 0.995051
[83]	training's multi_logloss: 0.991645	validation's multi_logloss: 0.995051
[84]	training's multi_logloss: 0.991645	validation's multi_logloss: 0.995051
[85]	training's multi_logloss: 0.991645	validation's multi_logloss: 0.995051
[86]	training's multi_logloss: 0.991645	validation's multi_logloss: 0.995051
[87]	training's multi_logloss: 0.991524	validation's multi_logloss: 0.995109
[88]	training's multi_logloss: 0.991524	validation's multi_logloss: 0.995109
[89]	training's multi_logloss: 0.991383	validation's multi_logloss: 0.994918
[90]	training's multi_logloss: 0.991383	validation's multi_logloss: 0.994918
[91]	training's multi_logloss: 0.99127	validation's multi_logloss: 0.994958
[92]	training's multi_logloss: 0.99127	validation's multi_logloss: 0.994958
[93]	training's multi_logloss: 0.99127	validation's multi_logloss: 0.994958
[94]	training's multi_logloss: 0.99127	validation's multi_logloss: 0.994958
[95]	training's multi_logloss: 0.99127	validation's multi_logloss: 0.994958
[96]	training's multi_logloss: 0.99127	validation's multi_logloss: 0.994958
[97]	training's multi_logloss: 0.99127	validation's multi_logloss: 0.994958
[98]	training's multi_logloss: 0.991125	validation's multi_logloss: 0.995086
[99]	training's multi_logloss: 0.991125	validation's multi_logloss: 0.995086
[100]	training's multi_logloss: 0.991125	validation's multi_logloss: 0.995086
Did not meet early stopping. Best iteration is:
[98]	training's multi_logloss: 0.991125	validation's multi_logloss: 0.995086
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900
[LightGBM] [Warning] min_gain_to_split is set=7.14225713214365, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.14225713214365
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04666	validation's multi_logloss: 1.04976
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03542	validation's multi_logloss: 1.04188
[3]	training's multi_logloss: 1.02789	validation's multi_logloss: 1.0363
[4]	training's multi_logloss: 1.02063	validation's multi_logloss: 1.03077
[5]	training's multi_logloss: 1.01517	validation's multi_logloss: 1.02661
[6]	training's multi_logloss: 1.01096	validation's multi_logloss: 1.02364
[7]	training's multi_logloss: 1.00752	validation's multi_logloss: 1.02128
[8]	training's multi_logloss: 1.00418	validation's multi_logloss: 1.01954
[9]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.01839
[10]	training's multi_logloss: 0.999485	validation's multi_logloss: 1.01692
[11]	training's multi_logloss: 0.998255	validation's multi_logloss: 1.01637
[12]	training's multi_logloss: 0.996541	validation's multi_logloss: 1.01562
[13]	training's multi_logloss: 0.994923	validation's multi_logloss: 1.01511
[14]	training's multi_logloss: 0.993831	validation's multi_logloss: 1.01464
[15]	training's multi_logloss: 0.993163	validation's multi_logloss: 1.0142
[16]	training's multi_logloss: 0.992472	validation's multi_logloss: 1.0136
[17]	training's multi_logloss: 0.991736	validation's multi_logloss: 1.01355
[18]	training's multi_logloss: 0.99095	validation's multi_logloss: 1.01337
[19]	training's multi_logloss: 0.990675	validation's multi_logloss: 1.01314
[20]	training's multi_logloss: 0.990256	validation's multi_logloss: 1.01287
[21]	training's multi_logloss: 0.989692	validation's multi_logloss: 1.01265
[22]	training's multi_logloss: 0.989446	validation's multi_logloss: 1.01244
[23]	training's multi_logloss: 0.989213	validation's multi_logloss: 1.01234
[24]	training's multi_logloss: 0.988773	validation's multi_logloss: 1.01205
[25]	training's multi_logloss: 0.988517	validation's multi_logloss: 1.01198
[26]	training's multi_logloss: 0.988271	validation's multi_logloss: 1.012
[27]	training's multi_logloss: 0.988271	validation's multi_logloss: 1.012
[28]	training's multi_logloss: 0.988064	validation's multi_logloss: 1.01186
[29]	training's multi_logloss: 0.987769	validation's multi_logloss: 1.01186
[30]	training's multi_logloss: 0.987769	validation's multi_logloss: 1.01186
[31]	training's multi_logloss: 0.987577	validation's multi_logloss: 1.01195
[32]	training's multi_logloss: 0.987577	validation's multi_logloss: 1.01195
[33]	training's multi_logloss: 0.987577	validation's multi_logloss: 1.01195
[34]	training's multi_logloss: 0.987577	validation's multi_logloss: 1.01195
[35]	training's multi_logloss: 0.987409	validation's multi_logloss: 1.01178
[36]	training's multi_logloss: 0.987409	validation's multi_logloss: 1.01178
[37]	training's multi_logloss: 0.987409	validation's multi_logloss: 1.01178
[38]	training's multi_logloss: 0.987409	validation's multi_logloss: 1.01178
[39]	training's multi_logloss: 0.987236	validation's multi_logloss: 1.01184
[40]	training's multi_logloss: 0.987236	validation's multi_logloss: 1.01184
[41]	training's multi_logloss: 0.987236	validation's multi_logloss: 1.01184
[42]	training's multi_logloss: 0.987047	validation's multi_logloss: 1.01189
[43]	training's multi_logloss: 0.987047	validation's multi_logloss: 1.01189
[44]	training's multi_logloss: 0.986843	validation's multi_logloss: 1.01166
[45]	training's multi_logloss: 0.986843	validation's multi_logloss: 1.01166
[46]	training's multi_logloss: 0.986843	validation's multi_logloss: 1.01166
[47]	training's multi_logloss: 0.986843	validation's multi_logloss: 1.01166
[48]	training's multi_logloss: 0.986843	validation's multi_logloss: 1.01166
[49]	training's multi_logloss: 0.986843	validation's multi_logloss: 1.01166
[50]	training's multi_logloss: 0.986843	validation's multi_logloss: 1.01166
[51]	training's multi_logloss: 0.986843	validation's multi_logloss: 1.01166
[52]	training's multi_logloss: 0.986681	validation's multi_logloss: 1.01174
[53]	training's multi_logloss: 0.986681	validation's multi_logloss: 1.01174
[54]	training's multi_logloss: 0.986681	validation's multi_logloss: 1.01174
[55]	training's multi_logloss: 0.986491	validation's multi_logloss: 1.01155
[56]	training's multi_logloss: 0.986491	validation's multi_logloss: 1.01155
[57]	training's multi_logloss: 0.986491	validation's multi_logloss: 1.01155
[58]	training's multi_logloss: 0.986491	validation's multi_logloss: 1.01155
[59]	training's multi_logloss: 0.986338	validation's multi_logloss: 1.01151
[60]	training's multi_logloss: 0.98618	validation's multi_logloss: 1.01147
[61]	training's multi_logloss: 0.98618	validation's multi_logloss: 1.01147
[62]	training's multi_logloss: 0.98618	validation's multi_logloss: 1.01147
[63]	training's multi_logloss: 0.98618	validation's multi_logloss: 1.01147
[64]	training's multi_logloss: 0.98618	validation's multi_logloss: 1.01147
[65]	training's multi_logloss: 0.98618	validation's multi_logloss: 1.01147
[66]	training's multi_logloss: 0.98618	validation's multi_logloss: 1.01147
[67]	training's multi_logloss: 0.98618	validation's multi_logloss: 1.01147
[68]	training's multi_logloss: 0.98618	validation's multi_logloss: 1.01147
[69]	training's multi_logloss: 0.98591	validation's multi_logloss: 1.01156
[70]	training's multi_logloss: 0.985634	validation's multi_logloss: 1.01167
[71]	training's multi_logloss: 0.985345	validation's multi_logloss: 1.01162
[72]	training's multi_logloss: 0.985345	validation's multi_logloss: 1.01162
[73]	training's multi_logloss: 0.985345	validation's multi_logloss: 1.01162
[74]	training's multi_logloss: 0.985345	validation's multi_logloss: 1.01162
[75]	training's multi_logloss: 0.985233	validation's multi_logloss: 1.01142
[76]	training's multi_logloss: 0.985233	validation's multi_logloss: 1.01142
[77]	training's multi_logloss: 0.985233	validation's multi_logloss: 1.01142
[78]	training's multi_logloss: 0.985233	validation's multi_logloss: 1.01142
[79]	training's multi_logloss: 0.985233	validation's multi_logloss: 1.01142
[80]	training's multi_logloss: 0.98512	validation's multi_logloss: 1.01128
[81]	training's multi_logloss: 0.98512	validation's multi_logloss: 1.01128
[82]	training's multi_logloss: 0.98512	validation's multi_logloss: 1.01128
[83]	training's multi_logloss: 0.98512	validation's multi_logloss: 1.01128
[84]	training's multi_logloss: 0.98512	validation's multi_logloss: 1.01128
[85]	training's multi_logloss: 0.98512	validation's multi_logloss: 1.01128
[86]	training's multi_logloss: 0.98512	validation's multi_logloss: 1.01128
[87]	training's multi_logloss: 0.98512	validation's multi_logloss: 1.01128
[88]	training's multi_logloss: 0.98512	validation's multi_logloss: 1.01128
[89]	training's multi_logloss: 0.98512	validation's multi_logloss: 1.01128
[90]	training's multi_logloss: 0.98512	validation's multi_logloss: 1.01128
[91]	training's multi_logloss: 0.98512	validation's multi_logloss: 1.01128
[92]	training's multi_logloss: 0.98512	validation's multi_logloss: 1.01128
[93]	training's multi_logloss: 0.984962	validation's multi_logloss: 1.01117
[94]	training's multi_logloss: 0.984962	validation's multi_logloss: 1.01117
[95]	training's multi_logloss: 0.984962	validation's multi_logloss: 1.01117
[96]	training's multi_logloss: 0.984962	validation's multi_logloss: 1.01117
[97]	training's multi_logloss: 0.984962	validation's multi_logloss: 1.01117
[98]	training's multi_logloss: 0.984962	validation's multi_logloss: 1.01117
[99]	training's multi_logloss: 0.984866	validation's multi_logloss: 1.01109
[100]	training's multi_logloss: 0.984866	validation's multi_logloss: 1.01109
Did not meet early stopping. Best iteration is:
[99]	training's multi_logloss: 0.984866	validation's multi_logloss: 1.01109
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900
[LightGBM] [Warning] min_gain_to_split is set=7.14225713214365, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.14225713214365
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04755	validation's multi_logloss: 1.04834
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03761	validation's multi_logloss: 1.04006
[3]	training's multi_logloss: 1.02916	validation's multi_logloss: 1.03251
[4]	training's multi_logloss: 1.02313	validation's multi_logloss: 1.02737
[5]	training's multi_logloss: 1.01798	validation's multi_logloss: 1.0233
[6]	training's multi_logloss: 1.01381	validation's multi_logloss: 1.02018
[7]	training's multi_logloss: 1.01006	validation's multi_logloss: 1.01722
[8]	training's multi_logloss: 1.00705	validation's multi_logloss: 1.01499
[9]	training's multi_logloss: 1.00438	validation's multi_logloss: 1.01266
[10]	training's multi_logloss: 1.00213	validation's multi_logloss: 1.01133
[11]	training's multi_logloss: 1.00016	validation's multi_logloss: 1.01025
[12]	training's multi_logloss: 0.998752	validation's multi_logloss: 1.00953
[13]	training's multi_logloss: 0.997318	validation's multi_logloss: 1.00834
[14]	training's multi_logloss: 0.996341	validation's multi_logloss: 1.00771
[15]	training's multi_logloss: 0.995679	validation's multi_logloss: 1.00756
[16]	training's multi_logloss: 0.995353	validation's multi_logloss: 1.00725
[17]	training's multi_logloss: 0.994497	validation's multi_logloss: 1.00677
[18]	training's multi_logloss: 0.993901	validation's multi_logloss: 1.00596
[19]	training's multi_logloss: 0.993582	validation's multi_logloss: 1.00565
[20]	training's multi_logloss: 0.993582	validation's multi_logloss: 1.00565
[21]	training's multi_logloss: 0.993049	validation's multi_logloss: 1.00559
[22]	training's multi_logloss: 0.992311	validation's multi_logloss: 1.00505
[23]	training's multi_logloss: 0.992099	validation's multi_logloss: 1.0049
[24]	training's multi_logloss: 0.992099	validation's multi_logloss: 1.0049
[25]	training's multi_logloss: 0.99185	validation's multi_logloss: 1.00475
[26]	training's multi_logloss: 0.991652	validation's multi_logloss: 1.0046
[27]	training's multi_logloss: 0.991428	validation's multi_logloss: 1.00458
[28]	training's multi_logloss: 0.991231	validation's multi_logloss: 1.00464
[29]	training's multi_logloss: 0.991231	validation's multi_logloss: 1.00464
[30]	training's multi_logloss: 0.991231	validation's multi_logloss: 1.00464
[31]	training's multi_logloss: 0.99104	validation's multi_logloss: 1.0046
[32]	training's multi_logloss: 0.99104	validation's multi_logloss: 1.0046
[33]	training's multi_logloss: 0.99104	validation's multi_logloss: 1.0046
[34]	training's multi_logloss: 0.99104	validation's multi_logloss: 1.0046
[35]	training's multi_logloss: 0.99104	validation's multi_logloss: 1.0046
[36]	training's multi_logloss: 0.99104	validation's multi_logloss: 1.0046
[37]	training's multi_logloss: 0.99104	validation's multi_logloss: 1.0046
[38]	training's multi_logloss: 0.99104	validation's multi_logloss: 1.0046
[39]	training's multi_logloss: 0.9908	validation's multi_logloss: 1.00453
[40]	training's multi_logloss: 0.990404	validation's multi_logloss: 1.00451
[41]	training's multi_logloss: 0.990404	validation's multi_logloss: 1.00451
[42]	training's multi_logloss: 0.990208	validation's multi_logloss: 1.00451
[43]	training's multi_logloss: 0.990208	validation's multi_logloss: 1.00451
[44]	training's multi_logloss: 0.990208	validation's multi_logloss: 1.00451
[45]	training's multi_logloss: 0.990028	validation's multi_logloss: 1.0044
[46]	training's multi_logloss: 0.989807	validation's multi_logloss: 1.00428
[47]	training's multi_logloss: 0.989807	validation's multi_logloss: 1.00428
[48]	training's multi_logloss: 0.989807	validation's multi_logloss: 1.00428
[49]	training's multi_logloss: 0.989807	validation's multi_logloss: 1.00428
[50]	training's multi_logloss: 0.989807	validation's multi_logloss: 1.00428
[51]	training's multi_logloss: 0.989807	validation's multi_logloss: 1.00428
[52]	training's multi_logloss: 0.989807	validation's multi_logloss: 1.00428
[53]	training's multi_logloss: 0.989807	validation's multi_logloss: 1.00428
[54]	training's multi_logloss: 0.989587	validation's multi_logloss: 1.00417
[55]	training's multi_logloss: 0.989587	validation's multi_logloss: 1.00417
[56]	training's multi_logloss: 0.989587	validation's multi_logloss: 1.00417
[57]	training's multi_logloss: 0.989587	validation's multi_logloss: 1.00417
[58]	training's multi_logloss: 0.989258	validation's multi_logloss: 1.00402
[59]	training's multi_logloss: 0.989258	validation's multi_logloss: 1.00402
[60]	training's multi_logloss: 0.989258	validation's multi_logloss: 1.00402
[61]	training's multi_logloss: 0.989258	validation's multi_logloss: 1.00402
[62]	training's multi_logloss: 0.989067	validation's multi_logloss: 1.00402
[63]	training's multi_logloss: 0.988918	validation's multi_logloss: 1.00397
[64]	training's multi_logloss: 0.988918	validation's multi_logloss: 1.00397
[65]	training's multi_logloss: 0.988918	validation's multi_logloss: 1.00397
[66]	training's multi_logloss: 0.988918	validation's multi_logloss: 1.00397
[67]	training's multi_logloss: 0.988918	validation's multi_logloss: 1.00397
[68]	training's multi_logloss: 0.988918	validation's multi_logloss: 1.00397
[69]	training's multi_logloss: 0.988918	validation's multi_logloss: 1.00397
[70]	training's multi_logloss: 0.988918	validation's multi_logloss: 1.00397
[71]	training's multi_logloss: 0.988918	validation's multi_logloss: 1.00397
[72]	training's multi_logloss: 0.988918	validation's multi_logloss: 1.00397
[73]	training's multi_logloss: 0.988918	validation's multi_logloss: 1.00397
[74]	training's multi_logloss: 0.988918	validation's multi_logloss: 1.00397
[75]	training's multi_logloss: 0.988918	validation's multi_logloss: 1.00397
[76]	training's multi_logloss: 0.988918	validation's multi_logloss: 1.00397
[77]	training's multi_logloss: 0.988918	validation's multi_logloss: 1.00397
[78]	training's multi_logloss: 0.988918	validation's multi_logloss: 1.00397
[79]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[80]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[81]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[82]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[83]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[84]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[85]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[86]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[87]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[88]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[89]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[90]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[91]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[92]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[93]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[94]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[95]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[96]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[97]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[98]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[99]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
Early stopping, best iteration is:
[79]	training's multi_logloss: 0.988758	validation's multi_logloss: 1.00374
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=7.318765212922888, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.318765212922888
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04698	validation's multi_logloss: 1.04647
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03725	validation's multi_logloss: 1.0366
[3]	training's multi_logloss: 1.02872	validation's multi_logloss: 1.02872
[4]	training's multi_logloss: 1.02249	validation's multi_logloss: 1.02213
[5]	training's multi_logloss: 1.01778	validation's multi_logloss: 1.0173
[6]	training's multi_logloss: 1.01321	validation's multi_logloss: 1.01312
[7]	training's multi_logloss: 1.00948	validation's multi_logloss: 1.01015
[8]	training's multi_logloss: 1.00703	validation's multi_logloss: 1.00829
[9]	training's multi_logloss: 1.00497	validation's multi_logloss: 1.00612
[10]	training's multi_logloss: 1.00326	validation's multi_logloss: 1.00431
[11]	training's multi_logloss: 1.00133	validation's multi_logloss: 1.00284
[12]	training's multi_logloss: 0.999722	validation's multi_logloss: 1.00158
[13]	training's multi_logloss: 0.999014	validation's multi_logloss: 1.00095
[14]	training's multi_logloss: 0.997994	validation's multi_logloss: 0.999929
[15]	training's multi_logloss: 0.997333	validation's multi_logloss: 0.999385
[16]	training's multi_logloss: 0.996713	validation's multi_logloss: 0.998937
[17]	training's multi_logloss: 0.995791	validation's multi_logloss: 0.997903
[18]	training's multi_logloss: 0.995287	validation's multi_logloss: 0.997253
[19]	training's multi_logloss: 0.99505	validation's multi_logloss: 0.997126
[20]	training's multi_logloss: 0.994595	validation's multi_logloss: 0.996699
[21]	training's multi_logloss: 0.994417	validation's multi_logloss: 0.99653
[22]	training's multi_logloss: 0.993925	validation's multi_logloss: 0.996102
[23]	training's multi_logloss: 0.993925	validation's multi_logloss: 0.996102
[24]	training's multi_logloss: 0.993925	validation's multi_logloss: 0.996102
[25]	training's multi_logloss: 0.993606	validation's multi_logloss: 0.995792
[26]	training's multi_logloss: 0.993606	validation's multi_logloss: 0.995792
[27]	training's multi_logloss: 0.993606	validation's multi_logloss: 0.995792
[28]	training's multi_logloss: 0.99334	validation's multi_logloss: 0.995771
[29]	training's multi_logloss: 0.99334	validation's multi_logloss: 0.995771
[30]	training's multi_logloss: 0.99334	validation's multi_logloss: 0.995771
[31]	training's multi_logloss: 0.99334	validation's multi_logloss: 0.995771
[32]	training's multi_logloss: 0.992932	validation's multi_logloss: 0.995489
[33]	training's multi_logloss: 0.992754	validation's multi_logloss: 0.995107
[34]	training's multi_logloss: 0.992754	validation's multi_logloss: 0.995107
[35]	training's multi_logloss: 0.992754	validation's multi_logloss: 0.995107
[36]	training's multi_logloss: 0.992754	validation's multi_logloss: 0.995107
[37]	training's multi_logloss: 0.992754	validation's multi_logloss: 0.995107
[38]	training's multi_logloss: 0.992754	validation's multi_logloss: 0.995107
[39]	training's multi_logloss: 0.992754	validation's multi_logloss: 0.995107
[40]	training's multi_logloss: 0.992754	validation's multi_logloss: 0.995107
[41]	training's multi_logloss: 0.992754	validation's multi_logloss: 0.995107
[42]	training's multi_logloss: 0.992754	validation's multi_logloss: 0.995107
[43]	training's multi_logloss: 0.992567	validation's multi_logloss: 0.995039
[44]	training's multi_logloss: 0.992567	validation's multi_logloss: 0.995039
[45]	training's multi_logloss: 0.992222	validation's multi_logloss: 0.994644
[46]	training's multi_logloss: 0.992222	validation's multi_logloss: 0.994644
[47]	training's multi_logloss: 0.992047	validation's multi_logloss: 0.994562
[48]	training's multi_logloss: 0.992047	validation's multi_logloss: 0.994562
[49]	training's multi_logloss: 0.992047	validation's multi_logloss: 0.994562
[50]	training's multi_logloss: 0.992047	validation's multi_logloss: 0.994562
[51]	training's multi_logloss: 0.992047	validation's multi_logloss: 0.994562
[52]	training's multi_logloss: 0.991677	validation's multi_logloss: 0.994281
[53]	training's multi_logloss: 0.991677	validation's multi_logloss: 0.994281
[54]	training's multi_logloss: 0.991677	validation's multi_logloss: 0.994281
[55]	training's multi_logloss: 0.991677	validation's multi_logloss: 0.994281
[56]	training's multi_logloss: 0.991527	validation's multi_logloss: 0.994105
[57]	training's multi_logloss: 0.991527	validation's multi_logloss: 0.994105
[58]	training's multi_logloss: 0.991527	validation's multi_logloss: 0.994105
[59]	training's multi_logloss: 0.991527	validation's multi_logloss: 0.994105
[60]	training's multi_logloss: 0.991527	validation's multi_logloss: 0.994105
[61]	training's multi_logloss: 0.991527	validation's multi_logloss: 0.994105
[62]	training's multi_logloss: 0.991527	validation's multi_logloss: 0.994105
[63]	training's multi_logloss: 0.991527	validation's multi_logloss: 0.994105
[64]	training's multi_logloss: 0.991527	validation's multi_logloss: 0.994105
[65]	training's multi_logloss: 0.99139	validation's multi_logloss: 0.99419
[66]	training's multi_logloss: 0.99139	validation's multi_logloss: 0.99419
[67]	training's multi_logloss: 0.99139	validation's multi_logloss: 0.99419
[68]	training's multi_logloss: 0.99139	validation's multi_logloss: 0.99419
[69]	training's multi_logloss: 0.99117	validation's multi_logloss: 0.993918
[70]	training's multi_logloss: 0.99117	validation's multi_logloss: 0.993918
[71]	training's multi_logloss: 0.99117	validation's multi_logloss: 0.993918
[72]	training's multi_logloss: 0.99117	validation's multi_logloss: 0.993918
[73]	training's multi_logloss: 0.99117	validation's multi_logloss: 0.993918
[74]	training's multi_logloss: 0.99117	validation's multi_logloss: 0.993918
[75]	training's multi_logloss: 0.99117	validation's multi_logloss: 0.993918
[76]	training's multi_logloss: 0.99117	validation's multi_logloss: 0.993918
[77]	training's multi_logloss: 0.99117	validation's multi_logloss: 0.993918
[78]	training's multi_logloss: 0.99117	validation's multi_logloss: 0.993918
[79]	training's multi_logloss: 0.99117	validation's multi_logloss: 0.993918
[80]	training's multi_logloss: 0.99117	validation's multi_logloss: 0.993918
[81]	training's multi_logloss: 0.99117	validation's multi_logloss: 0.993918
[82]	training's multi_logloss: 0.99117	validation's multi_logloss: 0.993918
[83]	training's multi_logloss: 0.99117	validation's multi_logloss: 0.993918
[84]	training's multi_logloss: 0.99117	validation's multi_logloss: 0.993918
[85]	training's multi_logloss: 0.990981	validation's multi_logloss: 0.99383
[86]	training's multi_logloss: 0.990981	validation's multi_logloss: 0.99383
[87]	training's multi_logloss: 0.990981	validation's multi_logloss: 0.99383
[88]	training's multi_logloss: 0.990981	validation's multi_logloss: 0.99383
[89]	training's multi_logloss: 0.990981	validation's multi_logloss: 0.99383
[90]	training's multi_logloss: 0.990981	validation's multi_logloss: 0.99383
[91]	training's multi_logloss: 0.990981	validation's multi_logloss: 0.99383
[92]	training's multi_logloss: 0.990981	validation's multi_logloss: 0.99383
[93]	training's multi_logloss: 0.990981	validation's multi_logloss: 0.99383
[94]	training's multi_logloss: 0.990981	validation's multi_logloss: 0.99383
[95]	training's multi_logloss: 0.990981	validation's multi_logloss: 0.99383
[96]	training's multi_logloss: 0.990981	validation's multi_logloss: 0.99383
[97]	training's multi_logloss: 0.990981	validation's multi_logloss: 0.99383
[98]	training's multi_logloss: 0.990981	validation's multi_logloss: 0.99383
[99]	training's multi_logloss: 0.990981	validation's multi_logloss: 0.99383
[100]	training's multi_logloss: 0.990981	validation's multi_logloss: 0.99383
Did not meet early stopping. Best iteration is:
[85]	training's multi_logloss: 0.990981	validation's multi_logloss: 0.99383
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=7.318765212922888, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.318765212922888
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04839	validation's multi_logloss: 1.04796
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03787	validation's multi_logloss: 1.03703
[3]	training's multi_logloss: 1.02931	validation's multi_logloss: 1.02942
[4]	training's multi_logloss: 1.02274	validation's multi_logloss: 1.02283
[5]	training's multi_logloss: 1.01782	validation's multi_logloss: 1.01765
[6]	training's multi_logloss: 1.01382	validation's multi_logloss: 1.01345
[7]	training's multi_logloss: 1.01042	validation's multi_logloss: 1.01099
[8]	training's multi_logloss: 1.00787	validation's multi_logloss: 1.00856
[9]	training's multi_logloss: 1.00519	validation's multi_logloss: 1.00572
[10]	training's multi_logloss: 1.00349	validation's multi_logloss: 1.00465
[11]	training's multi_logloss: 1.00139	validation's multi_logloss: 1.00274
[12]	training's multi_logloss: 0.99978	validation's multi_logloss: 1.00148
[13]	training's multi_logloss: 0.999118	validation's multi_logloss: 1.00129
[14]	training's multi_logloss: 0.998131	validation's multi_logloss: 1.00093
[15]	training's multi_logloss: 0.996973	validation's multi_logloss: 0.999943
[16]	training's multi_logloss: 0.996539	validation's multi_logloss: 0.999573
[17]	training's multi_logloss: 0.995735	validation's multi_logloss: 0.998767
[18]	training's multi_logloss: 0.995059	validation's multi_logloss: 0.997931
[19]	training's multi_logloss: 0.994563	validation's multi_logloss: 0.997769
[20]	training's multi_logloss: 0.994298	validation's multi_logloss: 0.997381
[21]	training's multi_logloss: 0.993787	validation's multi_logloss: 0.996513
[22]	training's multi_logloss: 0.993554	validation's multi_logloss: 0.996486
[23]	training's multi_logloss: 0.993324	validation's multi_logloss: 0.996406
[24]	training's multi_logloss: 0.993116	validation's multi_logloss: 0.996454
[25]	training's multi_logloss: 0.993116	validation's multi_logloss: 0.996454
[26]	training's multi_logloss: 0.992702	validation's multi_logloss: 0.996177
[27]	training's multi_logloss: 0.992702	validation's multi_logloss: 0.996177
[28]	training's multi_logloss: 0.992702	validation's multi_logloss: 0.996177
[29]	training's multi_logloss: 0.992702	validation's multi_logloss: 0.996177
[30]	training's multi_logloss: 0.992548	validation's multi_logloss: 0.996091
[31]	training's multi_logloss: 0.992548	validation's multi_logloss: 0.996091
[32]	training's multi_logloss: 0.992548	validation's multi_logloss: 0.996091
[33]	training's multi_logloss: 0.992548	validation's multi_logloss: 0.996091
[34]	training's multi_logloss: 0.992548	validation's multi_logloss: 0.996091
[35]	training's multi_logloss: 0.992548	validation's multi_logloss: 0.996091
[36]	training's multi_logloss: 0.992548	validation's multi_logloss: 0.996091
[37]	training's multi_logloss: 0.992548	validation's multi_logloss: 0.996091
[38]	training's multi_logloss: 0.992548	validation's multi_logloss: 0.996091
[39]	training's multi_logloss: 0.992548	validation's multi_logloss: 0.996091
[40]	training's multi_logloss: 0.992548	validation's multi_logloss: 0.996091
[41]	training's multi_logloss: 0.992548	validation's multi_logloss: 0.996091
[42]	training's multi_logloss: 0.992548	validation's multi_logloss: 0.996091
[43]	training's multi_logloss: 0.992397	validation's multi_logloss: 0.996183
[44]	training's multi_logloss: 0.992397	validation's multi_logloss: 0.996183
[45]	training's multi_logloss: 0.99218	validation's multi_logloss: 0.995919
[46]	training's multi_logloss: 0.99218	validation's multi_logloss: 0.995919
[47]	training's multi_logloss: 0.99218	validation's multi_logloss: 0.995919
[48]	training's multi_logloss: 0.99218	validation's multi_logloss: 0.995919
[49]	training's multi_logloss: 0.991996	validation's multi_logloss: 0.995894
[50]	training's multi_logloss: 0.991996	validation's multi_logloss: 0.995894
[51]	training's multi_logloss: 0.991807	validation's multi_logloss: 0.995704
[52]	training's multi_logloss: 0.991807	validation's multi_logloss: 0.995704
[53]	training's multi_logloss: 0.991807	validation's multi_logloss: 0.995704
[54]	training's multi_logloss: 0.991807	validation's multi_logloss: 0.995704
[55]	training's multi_logloss: 0.991807	validation's multi_logloss: 0.995704
[56]	training's multi_logloss: 0.991807	validation's multi_logloss: 0.995704
[57]	training's multi_logloss: 0.991807	validation's multi_logloss: 0.995704
[58]	training's multi_logloss: 0.991807	validation's multi_logloss: 0.995704
[59]	training's multi_logloss: 0.991807	validation's multi_logloss: 0.995704
[60]	training's multi_logloss: 0.991636	validation's multi_logloss: 0.995368
[61]	training's multi_logloss: 0.991636	validation's multi_logloss: 0.995368
[62]	training's multi_logloss: 0.991636	validation's multi_logloss: 0.995368
[63]	training's multi_logloss: 0.991636	validation's multi_logloss: 0.995368
[64]	training's multi_logloss: 0.991636	validation's multi_logloss: 0.995368
[65]	training's multi_logloss: 0.991636	validation's multi_logloss: 0.995368
[66]	training's multi_logloss: 0.991636	validation's multi_logloss: 0.995368
[67]	training's multi_logloss: 0.991636	validation's multi_logloss: 0.995368
[68]	training's multi_logloss: 0.991636	validation's multi_logloss: 0.995368
[69]	training's multi_logloss: 0.991636	validation's multi_logloss: 0.995368
[70]	training's multi_logloss: 0.991636	validation's multi_logloss: 0.995368
[71]	training's multi_logloss: 0.991542	validation's multi_logloss: 0.995343
[72]	training's multi_logloss: 0.991542	validation's multi_logloss: 0.995343
[73]	training's multi_logloss: 0.991542	validation's multi_logloss: 0.995343
[74]	training's multi_logloss: 0.991542	validation's multi_logloss: 0.995343
[75]	training's multi_logloss: 0.991542	validation's multi_logloss: 0.995343
[76]	training's multi_logloss: 0.991409	validation's multi_logloss: 0.995363
[77]	training's multi_logloss: 0.991409	validation's multi_logloss: 0.995363
[78]	training's multi_logloss: 0.991409	validation's multi_logloss: 0.995363
[79]	training's multi_logloss: 0.991029	validation's multi_logloss: 0.995
[80]	training's multi_logloss: 0.991029	validation's multi_logloss: 0.995
[81]	training's multi_logloss: 0.991029	validation's multi_logloss: 0.995
[82]	training's multi_logloss: 0.991029	validation's multi_logloss: 0.995
[83]	training's multi_logloss: 0.991029	validation's multi_logloss: 0.995
[84]	training's multi_logloss: 0.991029	validation's multi_logloss: 0.995
[85]	training's multi_logloss: 0.991029	validation's multi_logloss: 0.995
[86]	training's multi_logloss: 0.990874	validation's multi_logloss: 0.995049
[87]	training's multi_logloss: 0.990772	validation's multi_logloss: 0.99512
[88]	training's multi_logloss: 0.990772	validation's multi_logloss: 0.99512
[89]	training's multi_logloss: 0.990608	validation's multi_logloss: 0.994905
[90]	training's multi_logloss: 0.990608	validation's multi_logloss: 0.994905
[91]	training's multi_logloss: 0.990511	validation's multi_logloss: 0.994958
[92]	training's multi_logloss: 0.990511	validation's multi_logloss: 0.994958
[93]	training's multi_logloss: 0.990511	validation's multi_logloss: 0.994958
[94]	training's multi_logloss: 0.990511	validation's multi_logloss: 0.994958
[95]	training's multi_logloss: 0.990511	validation's multi_logloss: 0.994958
[96]	training's multi_logloss: 0.990511	validation's multi_logloss: 0.994958
[97]	training's multi_logloss: 0.990511	validation's multi_logloss: 0.994958
[98]	training's multi_logloss: 0.99038	validation's multi_logloss: 0.9951
[99]	training's multi_logloss: 0.99038	validation's multi_logloss: 0.9951
[100]	training's multi_logloss: 0.99038	validation's multi_logloss: 0.9951
Did not meet early stopping. Best iteration is:
[98]	training's multi_logloss: 0.99038	validation's multi_logloss: 0.9951
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=7.318765212922888, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.318765212922888
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04638	validation's multi_logloss: 1.04956
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03474	validation's multi_logloss: 1.04098
[3]	training's multi_logloss: 1.02714	validation's multi_logloss: 1.0354
[4]	training's multi_logloss: 1.01992	validation's multi_logloss: 1.02993
[5]	training's multi_logloss: 1.01415	validation's multi_logloss: 1.02583
[6]	training's multi_logloss: 1.01001	validation's multi_logloss: 1.02276
[7]	training's multi_logloss: 1.00633	validation's multi_logloss: 1.02044
[8]	training's multi_logloss: 1.00319	validation's multi_logloss: 1.01779
[9]	training's multi_logloss: 1.00092	validation's multi_logloss: 1.01678
[10]	training's multi_logloss: 0.998568	validation's multi_logloss: 1.01528
[11]	training's multi_logloss: 0.997196	validation's multi_logloss: 1.01424
[12]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.01393
[13]	training's multi_logloss: 0.994498	validation's multi_logloss: 1.01336
[14]	training's multi_logloss: 0.993328	validation's multi_logloss: 1.01279
[15]	training's multi_logloss: 0.992591	validation's multi_logloss: 1.01252
[16]	training's multi_logloss: 0.991601	validation's multi_logloss: 1.01202
[17]	training's multi_logloss: 0.99083	validation's multi_logloss: 1.01183
[18]	training's multi_logloss: 0.989878	validation's multi_logloss: 1.01156
[19]	training's multi_logloss: 0.989646	validation's multi_logloss: 1.01137
[20]	training's multi_logloss: 0.989227	validation's multi_logloss: 1.01119
[21]	training's multi_logloss: 0.988676	validation's multi_logloss: 1.01099
[22]	training's multi_logloss: 0.988453	validation's multi_logloss: 1.01079
[23]	training's multi_logloss: 0.98813	validation's multi_logloss: 1.01072
[24]	training's multi_logloss: 0.987639	validation's multi_logloss: 1.01048
[25]	training's multi_logloss: 0.987639	validation's multi_logloss: 1.01048
[26]	training's multi_logloss: 0.987358	validation's multi_logloss: 1.01048
[27]	training's multi_logloss: 0.987358	validation's multi_logloss: 1.01048
[28]	training's multi_logloss: 0.987161	validation's multi_logloss: 1.01035
[29]	training's multi_logloss: 0.986787	validation's multi_logloss: 1.01049
[30]	training's multi_logloss: 0.986787	validation's multi_logloss: 1.01049
[31]	training's multi_logloss: 0.986605	validation's multi_logloss: 1.01059
[32]	training's multi_logloss: 0.986605	validation's multi_logloss: 1.01059
[33]	training's multi_logloss: 0.986605	validation's multi_logloss: 1.01059
[34]	training's multi_logloss: 0.986605	validation's multi_logloss: 1.01059
[35]	training's multi_logloss: 0.986422	validation's multi_logloss: 1.01041
[36]	training's multi_logloss: 0.986422	validation's multi_logloss: 1.01041
[37]	training's multi_logloss: 0.986422	validation's multi_logloss: 1.01041
[38]	training's multi_logloss: 0.986422	validation's multi_logloss: 1.01041
[39]	training's multi_logloss: 0.986239	validation's multi_logloss: 1.01047
[40]	training's multi_logloss: 0.986239	validation's multi_logloss: 1.01047
[41]	training's multi_logloss: 0.986239	validation's multi_logloss: 1.01047
[42]	training's multi_logloss: 0.986023	validation's multi_logloss: 1.01051
[43]	training's multi_logloss: 0.986023	validation's multi_logloss: 1.01051
[44]	training's multi_logloss: 0.986023	validation's multi_logloss: 1.01051
[45]	training's multi_logloss: 0.986023	validation's multi_logloss: 1.01051
[46]	training's multi_logloss: 0.986023	validation's multi_logloss: 1.01051
[47]	training's multi_logloss: 0.986023	validation's multi_logloss: 1.01051
[48]	training's multi_logloss: 0.986023	validation's multi_logloss: 1.01051
Early stopping, best iteration is:
[28]	training's multi_logloss: 0.987161	validation's multi_logloss: 1.01035
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=7.318765212922888, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.318765212922888
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04656	validation's multi_logloss: 1.04782
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03685	validation's multi_logloss: 1.03971
[3]	training's multi_logloss: 1.02746	validation's multi_logloss: 1.03224
[4]	training's multi_logloss: 1.02115	validation's multi_logloss: 1.02614
[5]	training's multi_logloss: 1.01574	validation's multi_logloss: 1.02179
[6]	training's multi_logloss: 1.01108	validation's multi_logloss: 1.0181
[7]	training's multi_logloss: 1.00754	validation's multi_logloss: 1.01532
[8]	training's multi_logloss: 1.00422	validation's multi_logloss: 1.01294
[9]	training's multi_logloss: 1.00185	validation's multi_logloss: 1.01085
[10]	training's multi_logloss: 0.999951	validation's multi_logloss: 1.0098
[11]	training's multi_logloss: 0.997784	validation's multi_logloss: 1.00843
[12]	training's multi_logloss: 0.996412	validation's multi_logloss: 1.00776
[13]	training's multi_logloss: 0.995338	validation's multi_logloss: 1.0072
[14]	training's multi_logloss: 0.99473	validation's multi_logloss: 1.00679
[15]	training's multi_logloss: 0.993979	validation's multi_logloss: 1.00664
[16]	training's multi_logloss: 0.993431	validation's multi_logloss: 1.0061
[17]	training's multi_logloss: 0.992932	validation's multi_logloss: 1.00568
[18]	training's multi_logloss: 0.99237	validation's multi_logloss: 1.00512
[19]	training's multi_logloss: 0.992038	validation's multi_logloss: 1.00479
[20]	training's multi_logloss: 0.992038	validation's multi_logloss: 1.00479
[21]	training's multi_logloss: 0.99153	validation's multi_logloss: 1.00478
[22]	training's multi_logloss: 0.99086	validation's multi_logloss: 1.00438
[23]	training's multi_logloss: 0.990633	validation's multi_logloss: 1.00422
[24]	training's multi_logloss: 0.990633	validation's multi_logloss: 1.00422
[25]	training's multi_logloss: 0.990633	validation's multi_logloss: 1.00422
[26]	training's multi_logloss: 0.990451	validation's multi_logloss: 1.00409
[27]	training's multi_logloss: 0.990451	validation's multi_logloss: 1.00409
[28]	training's multi_logloss: 0.990451	validation's multi_logloss: 1.00409
[29]	training's multi_logloss: 0.990451	validation's multi_logloss: 1.00409
[30]	training's multi_logloss: 0.990451	validation's multi_logloss: 1.00409
[31]	training's multi_logloss: 0.990255	validation's multi_logloss: 1.00405
[32]	training's multi_logloss: 0.990255	validation's multi_logloss: 1.00405
[33]	training's multi_logloss: 0.990026	validation's multi_logloss: 1.0039
[34]	training's multi_logloss: 0.990026	validation's multi_logloss: 1.0039
[35]	training's multi_logloss: 0.990026	validation's multi_logloss: 1.0039
[36]	training's multi_logloss: 0.990026	validation's multi_logloss: 1.0039
[37]	training's multi_logloss: 0.990026	validation's multi_logloss: 1.0039
[38]	training's multi_logloss: 0.990026	validation's multi_logloss: 1.0039
[39]	training's multi_logloss: 0.989583	validation's multi_logloss: 1.00353
[40]	training's multi_logloss: 0.989369	validation's multi_logloss: 1.00353
[41]	training's multi_logloss: 0.989369	validation's multi_logloss: 1.00353
[42]	training's multi_logloss: 0.989369	validation's multi_logloss: 1.00353
[43]	training's multi_logloss: 0.989369	validation's multi_logloss: 1.00353
[44]	training's multi_logloss: 0.989369	validation's multi_logloss: 1.00353
[45]	training's multi_logloss: 0.989197	validation's multi_logloss: 1.00343
[46]	training's multi_logloss: 0.988967	validation's multi_logloss: 1.00334
[47]	training's multi_logloss: 0.988967	validation's multi_logloss: 1.00334
[48]	training's multi_logloss: 0.988803	validation's multi_logloss: 1.0034
[49]	training's multi_logloss: 0.988803	validation's multi_logloss: 1.0034
[50]	training's multi_logloss: 0.988803	validation's multi_logloss: 1.0034
[51]	training's multi_logloss: 0.988803	validation's multi_logloss: 1.0034
[52]	training's multi_logloss: 0.988803	validation's multi_logloss: 1.0034
[53]	training's multi_logloss: 0.988803	validation's multi_logloss: 1.0034
[54]	training's multi_logloss: 0.988669	validation's multi_logloss: 1.00337
[55]	training's multi_logloss: 0.988669	validation's multi_logloss: 1.00337
[56]	training's multi_logloss: 0.988669	validation's multi_logloss: 1.00337
[57]	training's multi_logloss: 0.988669	validation's multi_logloss: 1.00337
[58]	training's multi_logloss: 0.988669	validation's multi_logloss: 1.00337
[59]	training's multi_logloss: 0.988669	validation's multi_logloss: 1.00337
[60]	training's multi_logloss: 0.988669	validation's multi_logloss: 1.00337
[61]	training's multi_logloss: 0.988669	validation's multi_logloss: 1.00337
[62]	training's multi_logloss: 0.988669	validation's multi_logloss: 1.00337
[63]	training's multi_logloss: 0.988669	validation's multi_logloss: 1.00337
[64]	training's multi_logloss: 0.988669	validation's multi_logloss: 1.00337
[65]	training's multi_logloss: 0.988669	validation's multi_logloss: 1.00337
[66]	training's multi_logloss: 0.988669	validation's multi_logloss: 1.00337
Early stopping, best iteration is:
[46]	training's multi_logloss: 0.988967	validation's multi_logloss: 1.00334
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=7.581004042647009, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.581004042647009
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04816	validation's multi_logloss: 1.0474
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.0393	validation's multi_logloss: 1.03873
[3]	training's multi_logloss: 1.0325	validation's multi_logloss: 1.03193
[4]	training's multi_logloss: 1.0261	validation's multi_logloss: 1.02522
[5]	training's multi_logloss: 1.02159	validation's multi_logloss: 1.02068
[6]	training's multi_logloss: 1.01792	validation's multi_logloss: 1.01666
[7]	training's multi_logloss: 1.01559	validation's multi_logloss: 1.01402
[8]	training's multi_logloss: 1.01258	validation's multi_logloss: 1.01133
[9]	training's multi_logloss: 1.01085	validation's multi_logloss: 1.00959
[10]	training's multi_logloss: 1.00945	validation's multi_logloss: 1.00799
[11]	training's multi_logloss: 1.00837	validation's multi_logloss: 1.00705
[12]	training's multi_logloss: 1.00727	validation's multi_logloss: 1.00609
[13]	training's multi_logloss: 1.00638	validation's multi_logloss: 1.00531
[14]	training's multi_logloss: 1.00478	validation's multi_logloss: 1.00422
[15]	training's multi_logloss: 1.0038	validation's multi_logloss: 1.00331
[16]	training's multi_logloss: 1.00286	validation's multi_logloss: 1.00212
[17]	training's multi_logloss: 1.00195	validation's multi_logloss: 1.00138
[18]	training's multi_logloss: 1.00114	validation's multi_logloss: 1.00081
[19]	training's multi_logloss: 1.0005	validation's multi_logloss: 0.999772
[20]	training's multi_logloss: 1.00022	validation's multi_logloss: 0.999388
[21]	training's multi_logloss: 0.999975	validation's multi_logloss: 0.998918
[1]	training's multi_logloss: 1.04589	validation's multi_logloss: 1.04551
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03581	validation's multi_logloss: 1.03544
[3]	training's multi_logloss: 1.0267	validation's multi_logloss: 1.02688
[4]	training's multi_logloss: 1.02049	validation's multi_logloss: 1.02017
[5]	training's multi_logloss: 1.01575	validation's multi_logloss: 1.01529
[6]	training's multi_logloss: 1.01136	validation's multi_logloss: 1.01078
[7]	training's multi_logloss: 1.00741	validation's multi_logloss: 1.00754
[8]	training's multi_logloss: 1.00451	validation's multi_logloss: 1.00551
[9]	training's multi_logloss: 1.00254	validation's multi_logloss: 1.00362
[10]	training's multi_logloss: 1.00065	validation's multi_logloss: 1.00187
[11]	training's multi_logloss: 0.998829	validation's multi_logloss: 1.00052
[12]	training's multi_logloss: 0.997303	validation's multi_logloss: 0.999456
[13]	training's multi_logloss: 0.996325	validation's multi_logloss: 0.998359
[14]	training's multi_logloss: 0.995286	validation's multi_logloss: 0.997405
[15]	training's multi_logloss: 0.99447	validation's multi_logloss: 0.996883
[16]	training's multi_logloss: 0.993968	validation's multi_logloss: 0.996462
[17]	training's multi_logloss: 0.993256	validation's multi_logloss: 0.995688
[18]	training's multi_logloss: 0.992867	validation's multi_logloss: 0.995241
[19]	training's multi_logloss: 0.992867	validation's multi_logloss: 0.995241
[20]	training's multi_logloss: 0.992557	validation's multi_logloss: 0.994772
[21]	training's multi_logloss: 0.9924	validation's multi_logloss: 0.994622
[22]	training's multi_logloss: 0.991931	validation's multi_logloss: 0.994155
[23]	training's multi_logloss: 0.991931	validation's multi_logloss: 0.994155
[24]	training's multi_logloss: 0.991738	validation's multi_logloss: 0.994087
[25]	training's multi_logloss: 0.991334	validation's multi_logloss: 0.993898
[26]	training's multi_logloss: 0.991146	validation's multi_logloss: 0.993728
[27]	training's multi_logloss: 0.991146	validation's multi_logloss: 0.993728
[28]	training's multi_logloss: 0.991146	validation's multi_logloss: 0.993728
[29]	training's multi_logloss: 0.990957	validation's multi_logloss: 0.993679
[30]	training's multi_logloss: 0.990957	validation's multi_logloss: 0.993679
[31]	training's multi_logloss: 0.990957	validation's multi_logloss: 0.993679
[32]	training's multi_logloss: 0.990541	validation's multi_logloss: 0.993399
[33]	training's multi_logloss: 0.990376	validation's multi_logloss: 0.993016
[34]	training's multi_logloss: 0.990241	validation's multi_logloss: 0.993031
[35]	training's multi_logloss: 0.990241	validation's multi_logloss: 0.993031
[36]	training's multi_logloss: 0.990241	validation's multi_logloss: 0.993031
[37]	training's multi_logloss: 0.990241	validation's multi_logloss: 0.993031
[38]	training's multi_logloss: 0.990241	validation's multi_logloss: 0.993031
[39]	training's multi_logloss: 0.990241	validation's multi_logloss: 0.993031
[40]	training's multi_logloss: 0.990241	validation's multi_logloss: 0.993031
[41]	training's multi_logloss: 0.990241	validation's multi_logloss: 0.993031
[42]	training's multi_logloss: 0.990241	validation's multi_logloss: 0.993031
[43]	training's multi_logloss: 0.990241	validation's multi_logloss: 0.993031
[44]	training's multi_logloss: 0.990241	validation's multi_logloss: 0.993031
[45]	training's multi_logloss: 0.990061	validation's multi_logloss: 0.992936
[46]	training's multi_logloss: 0.990061	validation's multi_logloss: 0.992936
[47]	training's multi_logloss: 0.990061	validation's multi_logloss: 0.992936
[48]	training's multi_logloss: 0.990061	validation's multi_logloss: 0.992936
[49]	training's multi_logloss: 0.990061	validation's multi_logloss: 0.992936
[50]	training's multi_logloss: 0.990061	validation's multi_logloss: 0.992936
[51]	training's multi_logloss: 0.989891	validation's multi_logloss: 0.993006
[52]	training's multi_logloss: 0.989548	validation's multi_logloss: 0.992748
[53]	training's multi_logloss: 0.989548	validation's multi_logloss: 0.992748
[54]	training's multi_logloss: 0.989548	validation's multi_logloss: 0.992748
[55]	training's multi_logloss: 0.989548	validation's multi_logloss: 0.992748
[56]	training's multi_logloss: 0.989548	validation's multi_logloss: 0.992748
[57]	training's multi_logloss: 0.989548	validation's multi_logloss: 0.992748
[58]	training's multi_logloss: 0.989548	validation's multi_logloss: 0.992748
[59]	training's multi_logloss: 0.989548	validation's multi_logloss: 0.992748
[60]	training's multi_logloss: 0.989548	validation's multi_logloss: 0.992748
[61]	training's multi_logloss: 0.989548	validation's multi_logloss: 0.992748
[62]	training's multi_logloss: 0.989548	validation's multi_logloss: 0.992748
[63]	training's multi_logloss: 0.989548	validation's multi_logloss: 0.992748
[64]	training's multi_logloss: 0.989548	validation's multi_logloss: 0.992748
[65]	training's multi_logloss: 0.989426	validation's multi_logloss: 0.992864
[66]	training's multi_logloss: 0.989426	validation's multi_logloss: 0.992864
[67]	training's multi_logloss: 0.989426	validation's multi_logloss: 0.992864
[68]	training's multi_logloss: 0.989426	validation's multi_logloss: 0.992864
[69]	training's multi_logloss: 0.989203	validation's multi_logloss: 0.992485
[70]	training's multi_logloss: 0.989203	validation's multi_logloss: 0.992485
[71]	training's multi_logloss: 0.98908	validation's multi_logloss: 0.992317
[72]	training's multi_logloss: 0.98908	validation's multi_logloss: 0.992317
[73]	training's multi_logloss: 0.98908	validation's multi_logloss: 0.992317
[74]	training's multi_logloss: 0.98908	validation's multi_logloss: 0.992317
[75]	training's multi_logloss: 0.98908	validation's multi_logloss: 0.992317
[76]	training's multi_logloss: 0.98908	validation's multi_logloss: 0.992317
[77]	training's multi_logloss: 0.98908	validation's multi_logloss: 0.992317
[78]	training's multi_logloss: 0.98908	validation's multi_logloss: 0.992317
[79]	training's multi_logloss: 0.98908	validation's multi_logloss: 0.992317
[80]	training's multi_logloss: 0.98908	validation's multi_logloss: 0.992317
[81]	training's multi_logloss: 0.98908	validation's multi_logloss: 0.992317
[82]	training's multi_logloss: 0.98908	validation's multi_logloss: 0.992317
[83]	training's multi_logloss: 0.98908	validation's multi_logloss: 0.992317
[84]	training's multi_logloss: 0.98908	validation's multi_logloss: 0.992317
[85]	training's multi_logloss: 0.988908	validation's multi_logloss: 0.992252
[86]	training's multi_logloss: 0.988908	validation's multi_logloss: 0.992252
[87]	training's multi_logloss: 0.988908	validation's multi_logloss: 0.992252
[88]	training's multi_logloss: 0.988908	validation's multi_logloss: 0.992252
[89]	training's multi_logloss: 0.988908	validation's multi_logloss: 0.992252
[90]	training's multi_logloss: 0.988908	validation's multi_logloss: 0.992252
[91]	training's multi_logloss: 0.988762	validation's multi_logloss: 0.992085
[92]	training's multi_logloss: 0.988762	validation's multi_logloss: 0.992085
[93]	training's multi_logloss: 0.988762	validation's multi_logloss: 0.992085
[94]	training's multi_logloss: 0.988762	validation's multi_logloss: 0.992085
[95]	training's multi_logloss: 0.988762	validation's multi_logloss: 0.992085
[96]	training's multi_logloss: 0.988762	validation's multi_logloss: 0.992085
[97]	training's multi_logloss: 0.988762	validation's multi_logloss: 0.992085
[98]	training's multi_logloss: 0.988762	validation's multi_logloss: 0.992085
[99]	training's multi_logloss: 0.988762	validation's multi_logloss: 0.992085
[100]	training's multi_logloss: 0.988762	validation's multi_logloss: 0.992085
Did not meet early stopping. Best iteration is:
[91]	training's multi_logloss: 0.988762	validation's multi_logloss: 0.992085
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=7.244454343177231, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.244454343177231
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04725	validation's multi_logloss: 1.04769
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03586	validation's multi_logloss: 1.03639
[3]	training's multi_logloss: 1.02702	validation's multi_logloss: 1.02853
[4]	training's multi_logloss: 1.0201	validation's multi_logloss: 1.02164
[5]	training's multi_logloss: 1.01504	validation's multi_logloss: 1.0163
[6]	training's multi_logloss: 1.01094	validation's multi_logloss: 1.0124
[7]	training's multi_logloss: 1.00772	validation's multi_logloss: 1.00968
[8]	training's multi_logloss: 1.00495	validation's multi_logloss: 1.00652
[9]	training's multi_logloss: 1.00269	validation's multi_logloss: 1.00382
[10]	training's multi_logloss: 1.00066	validation's multi_logloss: 1.0023
[11]	training's multi_logloss: 0.998776	validation's multi_logloss: 1.00063
[12]	training's multi_logloss: 0.997534	validation's multi_logloss: 0.999226
[13]	training's multi_logloss: 0.996967	validation's multi_logloss: 0.999126
[14]	training's multi_logloss: 0.99603	validation's multi_logloss: 0.998824
[15]	training's multi_logloss: 0.994897	validation's multi_logloss: 0.997826
[16]	training's multi_logloss: 0.994415	validation's multi_logloss: 0.99752
[17]	training's multi_logloss: 0.993712	validation's multi_logloss: 0.99681
[18]	training's multi_logloss: 0.993126	validation's multi_logloss: 0.996121
[19]	training's multi_logloss: 0.99272	validation's multi_logloss: 0.99604
[20]	training's multi_logloss: 0.99249	validation's multi_logloss: 0.995684
[21]	training's multi_logloss: 0.991856	validation's multi_logloss: 0.994864
[22]	training's multi_logloss: 0.991633	validation's multi_logloss: 0.994862
[23]	training's multi_logloss: 0.991418	validation's multi_logloss: 0.994801
[24]	training's multi_logloss: 0.991233	validation's multi_logloss: 0.994888
[25]	training's multi_logloss: 0.991076	validation's multi_logloss: 0.994801
[26]	training's multi_logloss: 0.990735	validation's multi_logloss: 0.994587
[27]	training's multi_logloss: 0.990735	validation's multi_logloss: 0.994587
[28]	training's multi_logloss: 0.990735	validation's multi_logloss: 0.994587
[29]	training's multi_logloss: 0.990631	validation's multi_logloss: 0.994464
[30]	training's multi_logloss: 0.990631	validation's multi_logloss: 0.994464
[31]	training's multi_logloss: 0.990631	validation's multi_logloss: 0.994464
[32]	training's multi_logloss: 0.990631	validation's multi_logloss: 0.994464
[33]	training's multi_logloss: 0.990631	validation's multi_logloss: 0.994464
[34]	training's multi_logloss: 0.990631	validation's multi_logloss: 0.994464
[35]	training's multi_logloss: 0.990631	validation's multi_logloss: 0.994464
[36]	training's multi_logloss: 0.990631	validation's multi_logloss: 0.994464
[37]	training's multi_logloss: 0.990631	validation's multi_logloss: 0.994464
[38]	training's multi_logloss: 0.990631	validation's multi_logloss: 0.994464
[39]	training's multi_logloss: 0.990459	validation's multi_logloss: 0.994537
[40]	training's multi_logloss: 0.990459	validation's multi_logloss: 0.994537
[41]	training's multi_logloss: 0.990459	validation's multi_logloss: 0.994537
[42]	training's multi_logloss: 0.990459	validation's multi_logloss: 0.994537
[43]	training's multi_logloss: 0.990329	validation's multi_logloss: 0.994664
[44]	training's multi_logloss: 0.990329	validation's multi_logloss: 0.994664
[45]	training's multi_logloss: 0.990174	validation's multi_logloss: 0.994463
[46]	training's multi_logloss: 0.990174	validation's multi_logloss: 0.994463
[47]	training's multi_logloss: 0.990174	validation's multi_logloss: 0.994463
[48]	training's multi_logloss: 0.990174	validation's multi_logloss: 0.994463
[49]	training's multi_logloss: 0.99001	validation's multi_logloss: 0.994471
[50]	training's multi_logloss: 0.99001	validation's multi_logloss: 0.994471
[51]	training's multi_logloss: 0.99001	validation's multi_logloss: 0.994471
[52]	training's multi_logloss: 0.99001	validation's multi_logloss: 0.994471
[53]	training's multi_logloss: 0.99001	validation's multi_logloss: 0.994471
[54]	training's multi_logloss: 0.99001	validation's multi_logloss: 0.994471
[55]	training's multi_logloss: 0.99001	validation's multi_logloss: 0.994471
[56]	training's multi_logloss: 0.99001	validation's multi_logloss: 0.994471
[57]	training's multi_logloss: 0.99001	validation's multi_logloss: 0.994471
[58]	training's multi_logloss: 0.99001	validation's multi_logloss: 0.994471
[59]	training's multi_logloss: 0.98989	validation's multi_logloss: 0.994458
[60]	training's multi_logloss: 0.989764	validation's multi_logloss: 0.994161
[61]	training's multi_logloss: 0.989764	validation's multi_logloss: 0.994161
[62]	training's multi_logloss: 0.989764	validation's multi_logloss: 0.994161
[63]	training's multi_logloss: 0.989764	validation's multi_logloss: 0.994161
[64]	training's multi_logloss: 0.98964	validation's multi_logloss: 0.993966
[65]	training's multi_logloss: 0.98964	validation's multi_logloss: 0.993966
[66]	training's multi_logloss: 0.98964	validation's multi_logloss: 0.993966
[67]	training's multi_logloss: 0.98964	validation's multi_logloss: 0.993966
[68]	training's multi_logloss: 0.98964	validation's multi_logloss: 0.993966
[69]	training's multi_logloss: 0.98964	validation's multi_logloss: 0.993966
[70]	training's multi_logloss: 0.98964	validation's multi_logloss: 0.993966
[71]	training's multi_logloss: 0.98955	validation's multi_logloss: 0.994008
[72]	training's multi_logloss: 0.98955	validation's multi_logloss: 0.994008
[73]	training's multi_logloss: 0.98955	validation's multi_logloss: 0.994008
[74]	training's multi_logloss: 0.989365	validation's multi_logloss: 0.993865
[75]	training's multi_logloss: 0.989365	validation's multi_logloss: 0.993865
[76]	training's multi_logloss: 0.989365	validation's multi_logloss: 0.993865
[77]	training's multi_logloss: 0.989365	validation's multi_logloss: 0.993865
[78]	training's multi_logloss: 0.989365	validation's multi_logloss: 0.993865
[79]	training's multi_logloss: 0.98921	validation's multi_logloss: 0.993761
[80]	training's multi_logloss: 0.98921	validation's multi_logloss: 0.993761
[81]	training's multi_logloss: 0.98921	validation's multi_logloss: 0.993761
[82]	training's multi_logloss: 0.98921	validation's multi_logloss: 0.993761
[83]	training's multi_logloss: 0.98921	validation's multi_logloss: 0.993761
[84]	training's multi_logloss: 0.989129	validation's multi_logloss: 0.993658
[85]	training's multi_logloss: 0.988994	validation's multi_logloss: 0.993505
[86]	training's multi_logloss: 0.988994	validation's multi_logloss: 0.993505
[87]	training's multi_logloss: 0.988994	validation's multi_logloss: 0.993505
[88]	training's multi_logloss: 0.988994	validation's multi_logloss: 0.993505
[89]	training's multi_logloss: 0.988901	validation's multi_logloss: 0.993366
[90]	training's multi_logloss: 0.988901	validation's multi_logloss: 0.993366
[91]	training's multi_logloss: 0.988831	validation's multi_logloss: 0.993448
[92]	training's multi_logloss: 0.988831	validation's multi_logloss: 0.993448
[93]	training's multi_logloss: 0.988831	validation's multi_logloss: 0.993448
[94]	training's multi_logloss: 0.988831	validation's multi_logloss: 0.993448
[95]	training's multi_logloss: 0.988705	validation's multi_logloss: 0.993433
[96]	training's multi_logloss: 0.988705	validation's multi_logloss: 0.993433
[97]	training's multi_logloss: 0.988705	validation's multi_logloss: 0.993433
[98]	training's multi_logloss: 0.988705	validation's multi_logloss: 0.993433
[99]	training's multi_logloss: 0.988705	validation's multi_logloss: 0.993433
[100]	training's multi_logloss: 0.988705	validation's multi_logloss: 0.993433
Did not meet early stopping. Best iteration is:
[95]	training's multi_logloss: 0.988705	validation's multi_logloss: 0.993433
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=7.244454343177231, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.244454343177231
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04549	validation's multi_logloss: 1.0488
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03326	validation's multi_logloss: 1.0403
[3]	training's multi_logloss: 1.02529	validation's multi_logloss: 1.03427
[4]	training's multi_logloss: 1.01761	validation's multi_logloss: 1.02812
[5]	training's multi_logloss: 1.01134	validation's multi_logloss: 1.02337
[6]	training's multi_logloss: 1.00698	validation's multi_logloss: 1.02091
[7]	training's multi_logloss: 1.00274	validation's multi_logloss: 1.01853
[8]	training's multi_logloss: 0.999453	validation's multi_logloss: 1.01613
[9]	training's multi_logloss: 0.996868	validation's multi_logloss: 1.01498
[10]	training's multi_logloss: 0.994765	validation's multi_logloss: 1.01354
[11]	training's multi_logloss: 0.993277	validation's multi_logloss: 1.01284
[12]	training's multi_logloss: 0.99177	validation's multi_logloss: 1.01248
[13]	training's multi_logloss: 0.99043	validation's multi_logloss: 1.01218
[14]	training's multi_logloss: 0.989739	validation's multi_logloss: 1.0119
[15]	training's multi_logloss: 0.98917	validation's multi_logloss: 1.0117
[16]	training's multi_logloss: 0.98802	validation's multi_logloss: 1.01112
[17]	training's multi_logloss: 0.98738	validation's multi_logloss: 1.01107
[18]	training's multi_logloss: 0.986586	validation's multi_logloss: 1.01071
[19]	training's multi_logloss: 0.986156	validation's multi_logloss: 1.01044
[20]	training's multi_logloss: 0.986156	validation's multi_logloss: 1.01044
[21]	training's multi_logloss: 0.985661	validation's multi_logloss: 1.0103
[22]	training's multi_logloss: 0.985545	validation's multi_logloss: 1.01057
[23]	training's multi_logloss: 0.985344	validation's multi_logloss: 1.01058
[24]	training's multi_logloss: 0.985052	validation's multi_logloss: 1.01041
[25]	training's multi_logloss: 0.984852	validation's multi_logloss: 1.01039
[26]	training's multi_logloss: 0.984512	validation's multi_logloss: 1.01042
[27]	training's multi_logloss: 0.984512	validation's multi_logloss: 1.01042
[28]	training's multi_logloss: 0.984512	validation's multi_logloss: 1.01042
[29]	training's multi_logloss: 0.984127	validation's multi_logloss: 1.01058
[30]	training's multi_logloss: 0.984127	validation's multi_logloss: 1.01058
[31]	training's multi_logloss: 0.983967	validation's multi_logloss: 1.01071
[32]	training's multi_logloss: 0.983967	validation's multi_logloss: 1.01071
[33]	training's multi_logloss: 0.983967	validation's multi_logloss: 1.01071
[34]	training's multi_logloss: 0.983967	validation's multi_logloss: 1.01071
[35]	training's multi_logloss: 0.98384	validation's multi_logloss: 1.01073
[36]	training's multi_logloss: 0.98384	validation's multi_logloss: 1.01073
[37]	training's multi_logloss: 0.98384	validation's multi_logloss: 1.01073
[38]	training's multi_logloss: 0.983689	validation's multi_logloss: 1.01072
[39]	training's multi_logloss: 0.983292	validation's multi_logloss: 1.01092
[40]	training's multi_logloss: 0.983292	validation's multi_logloss: 1.01092
[41]	training's multi_logloss: 0.983292	validation's multi_logloss: 1.01092
Early stopping, best iteration is:
[21]	training's multi_logloss: 0.985661	validation's multi_logloss: 1.0103
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=7.244454343177231, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.244454343177231
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04548	validation's multi_logloss: 1.04697
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03457	validation's multi_logloss: 1.03797
[3]	training's multi_logloss: 1.02472	validation's multi_logloss: 1.03038
[4]	training's multi_logloss: 1.01855	validation's multi_logloss: 1.02438
[5]	training's multi_logloss: 1.01284	validation's multi_logloss: 1.01981
[6]	training's multi_logloss: 1.0085	validation's multi_logloss: 1.01638
[7]	training's multi_logloss: 1.00458	validation's multi_logloss: 1.01369
[8]	training's multi_logloss: 1.00182	validation's multi_logloss: 1.01138
[9]	training's multi_logloss: 0.999458	validation's multi_logloss: 1.00943
[10]	training's multi_logloss: 0.997411	validation's multi_logloss: 1.00783
[11]	training's multi_logloss: 0.995455	validation's multi_logloss: 1.00645
[12]	training's multi_logloss: 0.99407	validation's multi_logloss: 1.00569
[13]	training's multi_logloss: 0.992947	validation's multi_logloss: 1.00496
[14]	training's multi_logloss: 0.992411	validation's multi_logloss: 1.00482
[15]	training's multi_logloss: 0.991931	validation's multi_logloss: 1.00484
[16]	training's multi_logloss: 0.991341	validation's multi_logloss: 1.00441
[17]	training's multi_logloss: 0.991146	validation's multi_logloss: 1.00425
[18]	training's multi_logloss: 0.99063	validation's multi_logloss: 1.00355
[19]	training's multi_logloss: 0.990318	validation's multi_logloss: 1.00325
[20]	training's multi_logloss: 0.990318	validation's multi_logloss: 1.00325
[21]	training's multi_logloss: 0.989939	validation's multi_logloss: 1.00344
[22]	training's multi_logloss: 0.989452	validation's multi_logloss: 1.00301
[23]	training's multi_logloss: 0.989033	validation's multi_logloss: 1.00288
[24]	training's multi_logloss: 0.989033	validation's multi_logloss: 1.00288
[25]	training's multi_logloss: 0.989033	validation's multi_logloss: 1.00288
[26]	training's multi_logloss: 0.988841	validation's multi_logloss: 1.00275
[27]	training's multi_logloss: 0.988668	validation's multi_logloss: 1.00276
[28]	training's multi_logloss: 0.988668	validation's multi_logloss: 1.00276
[29]	training's multi_logloss: 0.988668	validation's multi_logloss: 1.00276
[30]	training's multi_logloss: 0.988668	validation's multi_logloss: 1.00276
[31]	training's multi_logloss: 0.988476	validation's multi_logloss: 1.00274
[32]	training's multi_logloss: 0.987749	validation's multi_logloss: 1.0029
[33]	training's multi_logloss: 0.987749	validation's multi_logloss: 1.0029
[34]	training's multi_logloss: 0.987749	validation's multi_logloss: 1.0029
[35]	training's multi_logloss: 0.987749	validation's multi_logloss: 1.0029
[36]	training's multi_logloss: 0.987543	validation's multi_logloss: 1.00311
[37]	training's multi_logloss: 0.987415	validation's multi_logloss: 1.0033
[38]	training's multi_logloss: 0.987415	validation's multi_logloss: 1.0033
[39]	training's multi_logloss: 0.987268	validation's multi_logloss: 1.00331
[40]	training's multi_logloss: 0.986959	validation's multi_logloss: 1.00334
[41]	training's multi_logloss: 0.986788	validation's multi_logloss: 1.0034
[42]	training's multi_logloss: 0.986788	validation's multi_logloss: 1.0034
[43]	training's multi_logloss: 0.986788	validation's multi_logloss: 1.0034
[44]	training's multi_logloss: 0.986788	validation's multi_logloss: 1.0034
[45]	training's multi_logloss: 0.986621	validation's multi_logloss: 1.0033
[46]	training's multi_logloss: 0.986446	validation's multi_logloss: 1.00321
[47]	training's multi_logloss: 0.986446	validation's multi_logloss: 1.00321
[48]	training's multi_logloss: 0.986446	validation's multi_logloss: 1.00321
[49]	training's multi_logloss: 0.986446	validation's multi_logloss: 1.00321
[50]	training's multi_logloss: 0.986446	validation's multi_logloss: 1.00321
[51]	training's multi_logloss: 0.986446	validation's multi_logloss: 1.00321
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.988476	validation's multi_logloss: 1.00274
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900
[LightGBM] [Warning] min_gain_to_split is set=7.249868421596516, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.249868421596516
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.0471	validation's multi_logloss: 1.04663
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03741	validation's multi_logloss: 1.03679
[3]	training's multi_logloss: 1.02922	validation's multi_logloss: 1.02904
[4]	training's multi_logloss: 1.02312	validation's multi_logloss: 1.02259
[5]	training's multi_logloss: 1.01778	validation's multi_logloss: 1.01718
[6]	training's multi_logloss: 1.01337	validation's multi_logloss: 1.01303
[7]	training's multi_logloss: 1.00994	validation's multi_logloss: 1.00972
[8]	training's multi_logloss: 1.00751	validation's multi_logloss: 1.00735
[9]	training's multi_logloss: 1.00532	validation's multi_logloss: 1.00518
[10]	training's multi_logloss: 1.00338	validation's multi_logloss: 1.00334
[11]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00185
[12]	training's multi_logloss: 0.999536	validation's multi_logloss: 1.00074
[13]	training's multi_logloss: 0.998628	validation's multi_logloss: 1.00008
[14]	training's multi_logloss: 0.997773	validation's multi_logloss: 0.99919
[15]	training's multi_logloss: 0.996914	validation's multi_logloss: 0.998518
[16]	training's multi_logloss: 0.996438	validation's multi_logloss: 0.998297
[17]	training's multi_logloss: 0.995562	validation's multi_logloss: 0.997344
[18]	training's multi_logloss: 0.995061	validation's multi_logloss: 0.996769
[19]	training's multi_logloss: 0.994646	validation's multi_logloss: 0.996622
[20]	training's multi_logloss: 0.994242	validation's multi_logloss: 0.99615
[21]	training's multi_logloss: 0.993884	validation's multi_logloss: 0.995773
[22]	training's multi_logloss: 0.993524	validation's multi_logloss: 0.995414
[23]	training's multi_logloss: 0.99341	validation's multi_logloss: 0.995423
[24]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995352
[25]	training's multi_logloss: 0.992803	validation's multi_logloss: 0.995154
[26]	training's multi_logloss: 0.992467	validation's multi_logloss: 0.99493
[27]	training's multi_logloss: 0.992467	validation's multi_logloss: 0.99493
[28]	training's multi_logloss: 0.992266	validation's multi_logloss: 0.994833
[29]	training's multi_logloss: 0.992105	validation's multi_logloss: 0.994805
[30]	training's multi_logloss: 0.992105	validation's multi_logloss: 0.994805
[31]	training's multi_logloss: 0.992105	validation's multi_logloss: 0.994805
[32]	training's multi_logloss: 0.991694	validation's multi_logloss: 0.994525
[33]	training's multi_logloss: 0.991559	validation's multi_logloss: 0.994157
[34]	training's multi_logloss: 0.991559	validation's multi_logloss: 0.994157
[35]	training's multi_logloss: 0.991559	validation's multi_logloss: 0.994157
[36]	training's multi_logloss: 0.991559	validation's multi_logloss: 0.994157
[37]	training's multi_logloss: 0.991559	validation's multi_logloss: 0.994157
[38]	training's multi_logloss: 0.991559	validation's multi_logloss: 0.994157
[39]	training's multi_logloss: 0.991559	validation's multi_logloss: 0.994157
[40]	training's multi_logloss: 0.991559	validation's multi_logloss: 0.994157
[41]	training's multi_logloss: 0.991559	validation's multi_logloss: 0.994157
[42]	training's multi_logloss: 0.991409	validation's multi_logloss: 0.993933
[43]	training's multi_logloss: 0.991409	validation's multi_logloss: 0.993933
[44]	training's multi_logloss: 0.991409	validation's multi_logloss: 0.993933
[45]	training's multi_logloss: 0.991409	validation's multi_logloss: 0.993933
[46]	training's multi_logloss: 0.991409	validation's multi_logloss: 0.993933
[47]	training's multi_logloss: 0.991264	validation's multi_logloss: 0.993882
[48]	training's multi_logloss: 0.991264	validation's multi_logloss: 0.993882
[49]	training's multi_logloss: 0.991264	validation's multi_logloss: 0.993882
[50]	training's multi_logloss: 0.991264	validation's multi_logloss: 0.993882
[51]	training's multi_logloss: 0.991264	validation's multi_logloss: 0.993882
[52]	training's multi_logloss: 0.990933	validation's multi_logloss: 0.993631
[53]	training's multi_logloss: 0.990933	validation's multi_logloss: 0.993631
[54]	training's multi_logloss: 0.990933	validation's multi_logloss: 0.993631
[55]	training's multi_logloss: 0.990933	validation's multi_logloss: 0.993631
[56]	training's multi_logloss: 0.990933	validation's multi_logloss: 0.993631
[57]	training's multi_logloss: 0.990933	validation's multi_logloss: 0.993631
[58]	training's multi_logloss: 0.990933	validation's multi_logloss: 0.993631
[59]	training's multi_logloss: 0.990933	validation's multi_logloss: 0.993631
[60]	training's multi_logloss: 0.990933	validation's multi_logloss: 0.993631
[61]	training's multi_logloss: 0.990842	validation's multi_logloss: 0.993493
[62]	training's multi_logloss: 0.990842	validation's multi_logloss: 0.993493
[63]	training's multi_logloss: 0.990842	validation's multi_logloss: 0.993493
[64]	training's multi_logloss: 0.990842	validation's multi_logloss: 0.993493
[65]	training's multi_logloss: 0.990712	validation's multi_logloss: 0.993634
[66]	training's multi_logloss: 0.990712	validation's multi_logloss: 0.993634
[67]	training's multi_logloss: 0.990712	validation's multi_logloss: 0.993634
[68]	training's multi_logloss: 0.990712	validation's multi_logloss: 0.993634
[69]	training's multi_logloss: 0.990474	validation's multi_logloss: 0.993247
[70]	training's multi_logloss: 0.990474	validation's multi_logloss: 0.993247
[71]	training's multi_logloss: 0.990474	validation's multi_logloss: 0.993247
[72]	training's multi_logloss: 0.990474	validation's multi_logloss: 0.993247
[73]	training's multi_logloss: 0.990474	validation's multi_logloss: 0.993247
[74]	training's multi_logloss: 0.990474	validation's multi_logloss: 0.993247
[75]	training's multi_logloss: 0.990474	validation's multi_logloss: 0.993247
[76]	training's multi_logloss: 0.990474	validation's multi_logloss: 0.993247
[77]	training's multi_logloss: 0.990474	validation's multi_logloss: 0.993247
[78]	training's multi_logloss: 0.990474	validation's multi_logloss: 0.993247
[79]	training's multi_logloss: 0.990474	validation's multi_logloss: 0.993247
[80]	training's multi_logloss: 0.990474	validation's multi_logloss: 0.993247
[81]	training's multi_logloss: 0.990474	validation's multi_logloss: 0.993247
[82]	training's multi_logloss: 0.990474	validation's multi_logloss: 0.993247
[83]	training's multi_logloss: 0.990474	validation's multi_logloss: 0.993247
[84]	training's multi_logloss: 0.990474	validation's multi_logloss: 0.993247
[85]	training's multi_logloss: 0.990474	validation's multi_logloss: 0.993247
[86]	training's multi_logloss: 0.990474	validation's multi_logloss: 0.993247
[87]	training's multi_logloss: 0.990474	validation's multi_logloss: 0.993247
[88]	training's multi_logloss: 0.990313	validation's multi_logloss: 0.993358
[89]	training's multi_logloss: 0.990313	validation's multi_logloss: 0.993358
Early stopping, best iteration is:
[69]	training's multi_logloss: 0.990474	validation's multi_logloss: 0.993247
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900
[LightGBM] [Warning] min_gain_to_split is set=7.249868421596516, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.249868421596516
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04934	validation's multi_logloss: 1.0491
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03789	validation's multi_logloss: 1.03772
[3]	training's multi_logloss: 1.02947	validation's multi_logloss: 1.03045
[4]	training's multi_logloss: 1.02314	validation's multi_logloss: 1.02432
[5]	training's multi_logloss: 1.01802	validation's multi_logloss: 1.01913
[6]	training's multi_logloss: 1.01353	validation's multi_logloss: 1.01484
[7]	training's multi_logloss: 1.01011	validation's multi_logloss: 1.01205
[8]	training's multi_logloss: 1.00778	validation's multi_logloss: 1.01001
[9]	training's multi_logloss: 1.00508	validation's multi_logloss: 1.00672
[10]	training's multi_logloss: 1.00281	validation's multi_logloss: 1.00469
[11]	training's multi_logloss: 1.00067	validation's multi_logloss: 1.00296
[12]	training's multi_logloss: 0.999279	validation's multi_logloss: 1.00161
[13]	training's multi_logloss: 0.998624	validation's multi_logloss: 1.00146
[14]	training's multi_logloss: 0.997572	validation's multi_logloss: 1.00106
[15]	training's multi_logloss: 0.996362	validation's multi_logloss: 0.999806
[16]	training's multi_logloss: 0.995855	validation's multi_logloss: 0.999325
[17]	training's multi_logloss: 0.995084	validation's multi_logloss: 0.998429
[18]	training's multi_logloss: 0.994535	validation's multi_logloss: 0.997982
[19]	training's multi_logloss: 0.994307	validation's multi_logloss: 0.998076
[20]	training's multi_logloss: 0.994061	validation's multi_logloss: 0.997681
[21]	training's multi_logloss: 0.993582	validation's multi_logloss: 0.996721
[22]	training's multi_logloss: 0.99339	validation's multi_logloss: 0.996734
[23]	training's multi_logloss: 0.993203	validation's multi_logloss: 0.996688
[24]	training's multi_logloss: 0.992989	validation's multi_logloss: 0.996759
[25]	training's multi_logloss: 0.992808	validation's multi_logloss: 0.99665
[26]	training's multi_logloss: 0.992444	validation's multi_logloss: 0.996413
[27]	training's multi_logloss: 0.992444	validation's multi_logloss: 0.996413
[28]	training's multi_logloss: 0.99229	validation's multi_logloss: 0.996544
[29]	training's multi_logloss: 0.99229	validation's multi_logloss: 0.996544
[30]	training's multi_logloss: 0.992123	validation's multi_logloss: 0.996445
[31]	training's multi_logloss: 0.992123	validation's multi_logloss: 0.996445
[32]	training's multi_logloss: 0.992123	validation's multi_logloss: 0.996445
[33]	training's multi_logloss: 0.992123	validation's multi_logloss: 0.996445
[34]	training's multi_logloss: 0.992123	validation's multi_logloss: 0.996445
[35]	training's multi_logloss: 0.992123	validation's multi_logloss: 0.996445
[36]	training's multi_logloss: 0.992123	validation's multi_logloss: 0.996445
[37]	training's multi_logloss: 0.992123	validation's multi_logloss: 0.996445
[38]	training's multi_logloss: 0.992123	validation's multi_logloss: 0.996445
[39]	training's multi_logloss: 0.991962	validation's multi_logloss: 0.996517
[40]	training's multi_logloss: 0.991962	validation's multi_logloss: 0.996517
[41]	training's multi_logloss: 0.991962	validation's multi_logloss: 0.996517
[42]	training's multi_logloss: 0.991962	validation's multi_logloss: 0.996517
[43]	training's multi_logloss: 0.991962	validation's multi_logloss: 0.996517
[44]	training's multi_logloss: 0.991962	validation's multi_logloss: 0.996517
[45]	training's multi_logloss: 0.991786	validation's multi_logloss: 0.996292
[46]	training's multi_logloss: 0.991786	validation's multi_logloss: 0.996292
[47]	training's multi_logloss: 0.991786	validation's multi_logloss: 0.996292
[48]	training's multi_logloss: 0.991786	validation's multi_logloss: 0.996292
[49]	training's multi_logloss: 0.991368	validation's multi_logloss: 0.995997
[50]	training's multi_logloss: 0.991368	validation's multi_logloss: 0.995997
[51]	training's multi_logloss: 0.991229	validation's multi_logloss: 0.995755
[52]	training's multi_logloss: 0.991229	validation's multi_logloss: 0.995755
[53]	training's multi_logloss: 0.991229	validation's multi_logloss: 0.995755
[54]	training's multi_logloss: 0.991229	validation's multi_logloss: 0.995755
[55]	training's multi_logloss: 0.991229	validation's multi_logloss: 0.995755
[56]	training's multi_logloss: 0.991229	validation's multi_logloss: 0.995755
[57]	training's multi_logloss: 0.991229	validation's multi_logloss: 0.995755
[58]	training's multi_logloss: 0.991229	validation's multi_logloss: 0.995755
[59]	training's multi_logloss: 0.991099	validation's multi_logloss: 0.995731
[60]	training's multi_logloss: 0.990987	validation's multi_logloss: 0.995565
[61]	training's multi_logloss: 0.990987	validation's multi_logloss: 0.995565
[62]	training's multi_logloss: 0.990987	validation's multi_logloss: 0.995565
[63]	training's multi_logloss: 0.990836	validation's multi_logloss: 0.995536
[64]	training's multi_logloss: 0.990711	validation's multi_logloss: 0.995333
[65]	training's multi_logloss: 0.990711	validation's multi_logloss: 0.995333
[66]	training's multi_logloss: 0.990711	validation's multi_logloss: 0.995333
[67]	training's multi_logloss: 0.990711	validation's multi_logloss: 0.995333
[68]	training's multi_logloss: 0.990711	validation's multi_logloss: 0.995333
[69]	training's multi_logloss: 0.990711	validation's multi_logloss: 0.995333
[70]	training's multi_logloss: 0.990711	validation's multi_logloss: 0.995333
[71]	training's multi_logloss: 0.990617	validation's multi_logloss: 0.995313
[72]	training's multi_logloss: 0.990617	validation's multi_logloss: 0.995313
[73]	training's multi_logloss: 0.990617	validation's multi_logloss: 0.995313
[74]	training's multi_logloss: 0.990617	validation's multi_logloss: 0.995313
[75]	training's multi_logloss: 0.990617	validation's multi_logloss: 0.995313
[76]	training's multi_logloss: 0.990517	validation's multi_logloss: 0.995363
[77]	training's multi_logloss: 0.990517	validation's multi_logloss: 0.995363
[78]	training's multi_logloss: 0.990517	validation's multi_logloss: 0.995363
[79]	training's multi_logloss: 0.990339	validation's multi_logloss: 0.995314
[80]	training's multi_logloss: 0.990339	validation's multi_logloss: 0.995314
[81]	training's multi_logloss: 0.990339	validation's multi_logloss: 0.995314
[82]	training's multi_logloss: 0.990339	validation's multi_logloss: 0.995314
[83]	training's multi_logloss: 0.990339	validation's multi_logloss: 0.995314
[84]	training's multi_logloss: 0.990249	validation's multi_logloss: 0.995196
[85]	training's multi_logloss: 0.990093	validation's multi_logloss: 0.995014
[86]	training's multi_logloss: 0.990093	validation's multi_logloss: 0.995014
[87]	training's multi_logloss: 0.990093	validation's multi_logloss: 0.995014
[88]	training's multi_logloss: 0.990093	validation's multi_logloss: 0.995014
[89]	training's multi_logloss: 0.989994	validation's multi_logloss: 0.994863
[90]	training's multi_logloss: 0.989994	validation's multi_logloss: 0.994863
[91]	training's multi_logloss: 0.989932	validation's multi_logloss: 0.99495
[92]	training's multi_logloss: 0.989932	validation's multi_logloss: 0.99495
[93]	training's multi_logloss: 0.989932	validation's multi_logloss: 0.99495
[94]	training's multi_logloss: 0.989932	validation's multi_logloss: 0.99495
[95]	training's multi_logloss: 0.989817	validation's multi_logloss: 0.994941
[96]	training's multi_logloss: 0.989817	validation's multi_logloss: 0.994941
[97]	training's multi_logloss: 0.989817	validation's multi_logloss: 0.994941
[98]	training's multi_logloss: 0.989817	validation's multi_logloss: 0.994941
[99]	training's multi_logloss: 0.989817	validation's multi_logloss: 0.994941
[100]	training's multi_logloss: 0.989817	validation's multi_logloss: 0.994941
Did not meet early stopping. Best iteration is:
[95]	training's multi_logloss: 0.989817	validation's multi_logloss: 0.994941
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900
[LightGBM] [Warning] min_gain_to_split is set=7.249868421596516, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.249868421596516
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04578	validation's multi_logloss: 1.04902
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03423	validation's multi_logloss: 1.04105
[3]	training's multi_logloss: 1.02627	validation's multi_logloss: 1.035
[4]	training's multi_logloss: 1.01885	validation's multi_logloss: 1.02925
[5]	training's multi_logloss: 1.01254	validation's multi_logloss: 1.02451
[6]	training's multi_logloss: 1.00844	validation's multi_logloss: 1.02158
[7]	training's multi_logloss: 1.0046	validation's multi_logloss: 1.0193
[8]	training's multi_logloss: 1.00123	validation's multi_logloss: 1.01678
[9]	training's multi_logloss: 0.998987	validation's multi_logloss: 1.01534
[10]	training's multi_logloss: 0.996697	validation's multi_logloss: 1.01373
[11]	training's multi_logloss: 0.995289	validation's multi_logloss: 1.01266
[12]	training's multi_logloss: 0.993645	validation's multi_logloss: 1.01225
[13]	training's multi_logloss: 0.99219	validation's multi_logloss: 1.01186
[14]	training's multi_logloss: 0.991256	validation's multi_logloss: 1.01152
[15]	training's multi_logloss: 0.990419	validation's multi_logloss: 1.01103
[16]	training's multi_logloss: 0.989906	validation's multi_logloss: 1.01063
[17]	training's multi_logloss: 0.989261	validation's multi_logloss: 1.01057
[18]	training's multi_logloss: 0.988617	validation's multi_logloss: 1.01061
[19]	training's multi_logloss: 0.988131	validation's multi_logloss: 1.0103
[20]	training's multi_logloss: 0.987643	validation's multi_logloss: 1.01002
[21]	training's multi_logloss: 0.987153	validation's multi_logloss: 1.00987
[22]	training's multi_logloss: 0.987047	validation's multi_logloss: 1.01014
[23]	training's multi_logloss: 0.987047	validation's multi_logloss: 1.01014
[24]	training's multi_logloss: 0.986709	validation's multi_logloss: 1.00991
[25]	training's multi_logloss: 0.986475	validation's multi_logloss: 1.00987
[26]	training's multi_logloss: 0.986111	validation's multi_logloss: 1.00988
[27]	training's multi_logloss: 0.985967	validation's multi_logloss: 1.00988
[28]	training's multi_logloss: 0.985782	validation's multi_logloss: 1.00977
[29]	training's multi_logloss: 0.985505	validation's multi_logloss: 1.00981
[30]	training's multi_logloss: 0.985505	validation's multi_logloss: 1.00981
[31]	training's multi_logloss: 0.985292	validation's multi_logloss: 1.00991
[32]	training's multi_logloss: 0.985292	validation's multi_logloss: 1.00991
[33]	training's multi_logloss: 0.985292	validation's multi_logloss: 1.00991
[34]	training's multi_logloss: 0.985292	validation's multi_logloss: 1.00991
[35]	training's multi_logloss: 0.985162	validation's multi_logloss: 1.00977
[36]	training's multi_logloss: 0.985162	validation's multi_logloss: 1.00977
[37]	training's multi_logloss: 0.985162	validation's multi_logloss: 1.00977
[38]	training's multi_logloss: 0.985021	validation's multi_logloss: 1.00976
[39]	training's multi_logloss: 0.984619	validation's multi_logloss: 1.00997
[40]	training's multi_logloss: 0.984619	validation's multi_logloss: 1.00997
[41]	training's multi_logloss: 0.984619	validation's multi_logloss: 1.00997
[42]	training's multi_logloss: 0.984474	validation's multi_logloss: 1.01006
[43]	training's multi_logloss: 0.984474	validation's multi_logloss: 1.01006
[44]	training's multi_logloss: 0.984474	validation's multi_logloss: 1.01006
[45]	training's multi_logloss: 0.984474	validation's multi_logloss: 1.01006
[46]	training's multi_logloss: 0.984474	validation's multi_logloss: 1.01006
[47]	training's multi_logloss: 0.984474	validation's multi_logloss: 1.01006
[48]	training's multi_logloss: 0.984474	validation's multi_logloss: 1.01006
[49]	training's multi_logloss: 0.984474	validation's multi_logloss: 1.01006
[50]	training's multi_logloss: 0.984474	validation's multi_logloss: 1.01006
[51]	training's multi_logloss: 0.984474	validation's multi_logloss: 1.01006
[52]	training's multi_logloss: 0.984474	validation's multi_logloss: 1.01006
[53]	training's multi_logloss: 0.984474	validation's multi_logloss: 1.01006
[54]	training's multi_logloss: 0.984474	validation's multi_logloss: 1.01006
[55]	training's multi_logloss: 0.984474	validation's multi_logloss: 1.01006
[56]	training's multi_logloss: 0.984474	validation's multi_logloss: 1.01006
[57]	training's multi_logloss: 0.984474	validation's multi_logloss: 1.01006
[58]	training's multi_logloss: 0.984474	validation's multi_logloss: 1.01006
Early stopping, best iteration is:
[38]	training's multi_logloss: 0.985021	validation's multi_logloss: 1.00976
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900
[LightGBM] [Warning] min_gain_to_split is set=7.249868421596516, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.249868421596516
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.0466	validation's multi_logloss: 1.04775
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03641	validation's multi_logloss: 1.03942
[3]	training's multi_logloss: 1.02757	validation's multi_logloss: 1.03195
[4]	training's multi_logloss: 1.02139	validation's multi_logloss: 1.02588
[5]	training's multi_logloss: 1.01548	validation's multi_logloss: 1.02114
[6]	training's multi_logloss: 1.01078	validation's multi_logloss: 1.01767
[7]	training's multi_logloss: 1.00703	validation's multi_logloss: 1.01498
[8]	training's multi_logloss: 1.00457	validation's multi_logloss: 1.01319
[9]	training's multi_logloss: 1.0023	validation's multi_logloss: 1.01135
[10]	training's multi_logloss: 1.00022	validation's multi_logloss: 1.01005
[11]	training's multi_logloss: 0.998165	validation's multi_logloss: 1.00895
[12]	training's multi_logloss: 0.996607	validation's multi_logloss: 1.00798
[13]	training's multi_logloss: 0.995597	validation's multi_logloss: 1.0074
[14]	training's multi_logloss: 0.99473	validation's multi_logloss: 1.00683
[15]	training's multi_logloss: 0.993364	validation's multi_logloss: 1.00605
[16]	training's multi_logloss: 0.99258	validation's multi_logloss: 1.00541
[17]	training's multi_logloss: 0.991962	validation's multi_logloss: 1.00512
[18]	training's multi_logloss: 0.991465	validation's multi_logloss: 1.00442
[19]	training's multi_logloss: 0.991191	validation's multi_logloss: 1.00414
[20]	training's multi_logloss: 0.991191	validation's multi_logloss: 1.00414
[21]	training's multi_logloss: 0.990821	validation's multi_logloss: 1.00442
[22]	training's multi_logloss: 0.990174	validation's multi_logloss: 1.00418
[23]	training's multi_logloss: 0.989991	validation's multi_logloss: 1.00407
[24]	training's multi_logloss: 0.989991	validation's multi_logloss: 1.00407
[25]	training's multi_logloss: 0.989991	validation's multi_logloss: 1.00407
[26]	training's multi_logloss: 0.989753	validation's multi_logloss: 1.0039
[27]	training's multi_logloss: 0.989575	validation's multi_logloss: 1.00391
[28]	training's multi_logloss: 0.989575	validation's multi_logloss: 1.00391
[29]	training's multi_logloss: 0.989575	validation's multi_logloss: 1.00391
[30]	training's multi_logloss: 0.989575	validation's multi_logloss: 1.00391
[31]	training's multi_logloss: 0.989397	validation's multi_logloss: 1.00389
[32]	training's multi_logloss: 0.989259	validation's multi_logloss: 1.00393
[33]	training's multi_logloss: 0.989259	validation's multi_logloss: 1.00393
[34]	training's multi_logloss: 0.989259	validation's multi_logloss: 1.00393
[35]	training's multi_logloss: 0.989259	validation's multi_logloss: 1.00393
[36]	training's multi_logloss: 0.989045	validation's multi_logloss: 1.00412
[37]	training's multi_logloss: 0.988913	validation's multi_logloss: 1.0043
[38]	training's multi_logloss: 0.988913	validation's multi_logloss: 1.0043
[39]	training's multi_logloss: 0.988729	validation's multi_logloss: 1.00428
[40]	training's multi_logloss: 0.988611	validation's multi_logloss: 1.00427
[41]	training's multi_logloss: 0.988202	validation's multi_logloss: 1.00427
[42]	training's multi_logloss: 0.988202	validation's multi_logloss: 1.00427
[43]	training's multi_logloss: 0.988202	validation's multi_logloss: 1.00427
[44]	training's multi_logloss: 0.988202	validation's multi_logloss: 1.00427
[45]	training's multi_logloss: 0.988012	validation's multi_logloss: 1.00415
[46]	training's multi_logloss: 0.988012	validation's multi_logloss: 1.00415
[47]	training's multi_logloss: 0.988012	validation's multi_logloss: 1.00415
[48]	training's multi_logloss: 0.988012	validation's multi_logloss: 1.00415
[49]	training's multi_logloss: 0.988012	validation's multi_logloss: 1.00415
[50]	training's multi_logloss: 0.987846	validation's multi_logloss: 1.0042
[51]	training's multi_logloss: 0.987846	validation's multi_logloss: 1.0042
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.989397	validation's multi_logloss: 1.00389
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=6.932605245654812, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.932605245654812
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04816	validation's multi_logloss: 1.0477
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03885	validation's multi_logloss: 1.03835
[3]	training's multi_logloss: 1.03043	validation's multi_logloss: 1.03002
[4]	training's multi_logloss: 1.02402	validation's multi_logloss: 1.02321
[5]	training's multi_logloss: 1.01876	validation's multi_logloss: 1.01818
[6]	training's multi_logloss: 1.01451	validation's multi_logloss: 1.01394
[7]	training's multi_logloss: 1.01054	validation's multi_logloss: 1.00999
[8]	training's multi_logloss: 1.00776	validation's multi_logloss: 1.00742
[9]	training's multi_logloss: 1.006	validation's multi_logloss: 1.00555
[10]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.0038
[11]	training's multi_logloss: 1.00257	validation's multi_logloss: 1.00244
[12]	training's multi_logloss: 1.00119	validation's multi_logloss: 1.00142
[13]	training's multi_logloss: 0.999436	validation's multi_logloss: 0.999084
[14]	training's multi_logloss: 0.9983	validation's multi_logloss: 0.997824
[15]	training's multi_logloss: 0.997555	validation's multi_logloss: 0.997253
[16]	training's multi_logloss: 0.996976	validation's multi_logloss: 0.996699
[17]	training's multi_logloss: 0.996161	validation's multi_logloss: 0.995901
[18]	training's multi_logloss: 0.995167	validation's multi_logloss: 0.995496
[19]	training's multi_logloss: 0.994768	validation's multi_logloss: 0.995462
[20]	training's multi_logloss: 0.994105	validation's multi_logloss: 0.995148
[21]	training's multi_logloss: 0.993719	validation's multi_logloss: 0.994592
[22]	training's multi_logloss: 0.993443	validation's multi_logloss: 0.994421
[23]	training's multi_logloss: 0.993443	validation's multi_logloss: 0.994421
[24]	training's multi_logloss: 0.993245	validation's multi_logloss: 0.994365
[25]	training's multi_logloss: 0.992725	validation's multi_logloss: 0.994093
[26]	training's multi_logloss: 0.992499	validation's multi_logloss: 0.994117
[27]	training's multi_logloss: 0.992499	validation's multi_logloss: 0.994117
[28]	training's multi_logloss: 0.992299	validation's multi_logloss: 0.993946
[29]	training's multi_logloss: 0.991959	validation's multi_logloss: 0.99371
[30]	training's multi_logloss: 0.991831	validation's multi_logloss: 0.993709
[31]	training's multi_logloss: 0.991605	validation's multi_logloss: 0.993494
[32]	training's multi_logloss: 0.991442	validation's multi_logloss: 0.993354
[33]	training's multi_logloss: 0.991442	validation's multi_logloss: 0.993354
[34]	training's multi_logloss: 0.991442	validation's multi_logloss: 0.993354
[35]	training's multi_logloss: 0.991442	validation's multi_logloss: 0.993354
[36]	training's multi_logloss: 0.991442	validation's multi_logloss: 0.993354
[37]	training's multi_logloss: 0.991442	validation's multi_logloss: 0.993354
[38]	training's multi_logloss: 0.991442	validation's multi_logloss: 0.993354
[39]	training's multi_logloss: 0.99125	validation's multi_logloss: 0.993445
[40]	training's multi_logloss: 0.99125	validation's multi_logloss: 0.993445
[41]	training's multi_logloss: 0.99125	validation's multi_logloss: 0.993445
[42]	training's multi_logloss: 0.99125	validation's multi_logloss: 0.993445
[43]	training's multi_logloss: 0.991066	validation's multi_logloss: 0.993438
[44]	training's multi_logloss: 0.991066	validation's multi_logloss: 0.993438
[45]	training's multi_logloss: 0.991066	validation's multi_logloss: 0.993438
[46]	training's multi_logloss: 0.991066	validation's multi_logloss: 0.993438
[47]	training's multi_logloss: 0.991066	validation's multi_logloss: 0.993438
[48]	training's multi_logloss: 0.991066	validation's multi_logloss: 0.993438
[49]	training's multi_logloss: 0.991066	validation's multi_logloss: 0.993438
[50]	training's multi_logloss: 0.991066	validation's multi_logloss: 0.993438
[51]	training's multi_logloss: 0.990925	validation's multi_logloss: 0.993553
[52]	training's multi_logloss: 0.990736	validation's multi_logloss: 0.993372
Early stopping, best iteration is:
[32]	training's multi_logloss: 0.991442	validation's multi_logloss: 0.993354
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=6.932605245654812, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.932605245654812
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.0492	validation's multi_logloss: 1.04917
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03861	validation's multi_logloss: 1.03869
[3]	training's multi_logloss: 1.03051	validation's multi_logloss: 1.03061
[4]	training's multi_logloss: 1.02417	validation's multi_logloss: 1.02452
[5]	training's multi_logloss: 1.01995	validation's multi_logloss: 1.01997
[6]	training's multi_logloss: 1.01545	validation's multi_logloss: 1.01625
[7]	training's multi_logloss: 1.01249	validation's multi_logloss: 1.01339
[8]	training's multi_logloss: 1.00964	validation's multi_logloss: 1.01113
[9]	training's multi_logloss: 1.00662	validation's multi_logloss: 1.00786
[10]	training's multi_logloss: 1.00398	validation's multi_logloss: 1.0056
[11]	training's multi_logloss: 1.00206	validation's multi_logloss: 1.00382
[12]	training's multi_logloss: 1.00088	validation's multi_logloss: 1.00267
[13]	training's multi_logloss: 0.9995	validation's multi_logloss: 1.00175
[14]	training's multi_logloss: 0.998222	validation's multi_logloss: 1.00061
[15]	training's multi_logloss: 0.996811	validation's multi_logloss: 0.99941
[16]	training's multi_logloss: 0.996392	validation's multi_logloss: 0.999404
[17]	training's multi_logloss: 0.995464	validation's multi_logloss: 0.998515
[18]	training's multi_logloss: 0.994917	validation's multi_logloss: 0.998063
[19]	training's multi_logloss: 0.994431	validation's multi_logloss: 0.997888
[20]	training's multi_logloss: 0.994234	validation's multi_logloss: 0.997561
[21]	training's multi_logloss: 0.99399	validation's multi_logloss: 0.997485
[22]	training's multi_logloss: 0.993721	validation's multi_logloss: 0.997463
[23]	training's multi_logloss: 0.993361	validation's multi_logloss: 0.997414
[24]	training's multi_logloss: 0.993167	validation's multi_logloss: 0.997275
[25]	training's multi_logloss: 0.992929	validation's multi_logloss: 0.997345
[26]	training's multi_logloss: 0.9927	validation's multi_logloss: 0.997329
[27]	training's multi_logloss: 0.9927	validation's multi_logloss: 0.997329
[28]	training's multi_logloss: 0.9927	validation's multi_logloss: 0.997329
[29]	training's multi_logloss: 0.9927	validation's multi_logloss: 0.997329
[30]	training's multi_logloss: 0.9927	validation's multi_logloss: 0.997329
[31]	training's multi_logloss: 0.992352	validation's multi_logloss: 0.996915
[32]	training's multi_logloss: 0.992352	validation's multi_logloss: 0.996915
[33]	training's multi_logloss: 0.992352	validation's multi_logloss: 0.996915
[34]	training's multi_logloss: 0.992352	validation's multi_logloss: 0.996915
[35]	training's multi_logloss: 0.992352	validation's multi_logloss: 0.996915
[36]	training's multi_logloss: 0.992223	validation's multi_logloss: 0.996831
[37]	training's multi_logloss: 0.992223	validation's multi_logloss: 0.996831
[38]	training's multi_logloss: 0.992223	validation's multi_logloss: 0.996831
[39]	training's multi_logloss: 0.99203	validation's multi_logloss: 0.996905
[40]	training's multi_logloss: 0.991964	validation's multi_logloss: 0.996852
[41]	training's multi_logloss: 0.991964	validation's multi_logloss: 0.996852
[42]	training's multi_logloss: 0.991964	validation's multi_logloss: 0.996852
[43]	training's multi_logloss: 0.991964	validation's multi_logloss: 0.996852
[44]	training's multi_logloss: 0.991964	validation's multi_logloss: 0.996852
[45]	training's multi_logloss: 0.99179	validation's multi_logloss: 0.996713
[46]	training's multi_logloss: 0.99179	validation's multi_logloss: 0.996713
[47]	training's multi_logloss: 0.99179	validation's multi_logloss: 0.996713
[48]	training's multi_logloss: 0.991581	validation's multi_logloss: 0.996572
[49]	training's multi_logloss: 0.99128	validation's multi_logloss: 0.996473
[50]	training's multi_logloss: 0.99128	validation's multi_logloss: 0.996473
[51]	training's multi_logloss: 0.99128	validation's multi_logloss: 0.996473
[52]	training's multi_logloss: 0.99128	validation's multi_logloss: 0.996473
[53]	training's multi_logloss: 0.99128	validation's multi_logloss: 0.996473
[54]	training's multi_logloss: 0.991211	validation's multi_logloss: 0.996273
[55]	training's multi_logloss: 0.991211	validation's multi_logloss: 0.996273
[56]	training's multi_logloss: 0.991211	validation's multi_logloss: 0.996273
[57]	training's multi_logloss: 0.991211	validation's multi_logloss: 0.996273
[58]	training's multi_logloss: 0.991211	validation's multi_logloss: 0.996273
[59]	training's multi_logloss: 0.991211	validation's multi_logloss: 0.996273
[60]	training's multi_logloss: 0.991084	validation's multi_logloss: 0.996017
[61]	training's multi_logloss: 0.991084	validation's multi_logloss: 0.996017
[62]	training's multi_logloss: 0.991084	validation's multi_logloss: 0.996017
[63]	training's multi_logloss: 0.990909	validation's multi_logloss: 0.995647
[64]	training's multi_logloss: 0.990838	validation's multi_logloss: 0.995633
[65]	training's multi_logloss: 0.990838	validation's multi_logloss: 0.995633
[66]	training's multi_logloss: 0.990686	validation's multi_logloss: 0.995645
[67]	training's multi_logloss: 0.990686	validation's multi_logloss: 0.995645
[68]	training's multi_logloss: 0.990686	validation's multi_logloss: 0.995645
[69]	training's multi_logloss: 0.990686	validation's multi_logloss: 0.995645
[70]	training's multi_logloss: 0.990686	validation's multi_logloss: 0.995645
[71]	training's multi_logloss: 0.990592	validation's multi_logloss: 0.995621
[72]	training's multi_logloss: 0.990592	validation's multi_logloss: 0.995621
[73]	training's multi_logloss: 0.990592	validation's multi_logloss: 0.995621
[74]	training's multi_logloss: 0.990592	validation's multi_logloss: 0.995621
[75]	training's multi_logloss: 0.99048	validation's multi_logloss: 0.995698
[76]	training's multi_logloss: 0.99048	validation's multi_logloss: 0.995698
[77]	training's multi_logloss: 0.99048	validation's multi_logloss: 0.995698
[78]	training's multi_logloss: 0.99048	validation's multi_logloss: 0.995698
[79]	training's multi_logloss: 0.990302	validation's multi_logloss: 0.995636
[80]	training's multi_logloss: 0.990302	validation's multi_logloss: 0.995636
[81]	training's multi_logloss: 0.990191	validation's multi_logloss: 0.995586
[82]	training's multi_logloss: 0.990191	validation's multi_logloss: 0.995586
[83]	training's multi_logloss: 0.990191	validation's multi_logloss: 0.995586
[84]	training's multi_logloss: 0.990053	validation's multi_logloss: 0.995315
[85]	training's multi_logloss: 0.990053	validation's multi_logloss: 0.995315
[86]	training's multi_logloss: 0.990053	validation's multi_logloss: 0.995315
[87]	training's multi_logloss: 0.990053	validation's multi_logloss: 0.995315
[88]	training's multi_logloss: 0.990053	validation's multi_logloss: 0.995315
[89]	training's multi_logloss: 0.989947	validation's multi_logloss: 0.995479
[90]	training's multi_logloss: 0.989947	validation's multi_logloss: 0.995479
[91]	training's multi_logloss: 0.989816	validation's multi_logloss: 0.995586
[92]	training's multi_logloss: 0.989816	validation's multi_logloss: 0.995586
[93]	training's multi_logloss: 0.989816	validation's multi_logloss: 0.995586
[94]	training's multi_logloss: 0.989821	validation's multi_logloss: 0.995505
[95]	training's multi_logloss: 0.989821	validation's multi_logloss: 0.995505
[96]	training's multi_logloss: 0.989821	validation's multi_logloss: 0.995505
[97]	training's multi_logloss: 0.989821	validation's multi_logloss: 0.995505
[98]	training's multi_logloss: 0.989821	validation's multi_logloss: 0.995505
[99]	training's multi_logloss: 0.989821	validation's multi_logloss: 0.995505
[100]	training's multi_logloss: 0.989821	validation's multi_logloss: 0.995505
Did not meet early stopping. Best iteration is:
[91]	training's multi_logloss: 0.989816	validation's multi_logloss: 0.995586
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=6.932605245654812, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.932605245654812
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04602	validation's multi_logloss: 1.04934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03552	validation's multi_logloss: 1.04131
[3]	training's multi_logloss: 1.02739	validation's multi_logloss: 1.03532
[4]	training's multi_logloss: 1.02056	validation's multi_logloss: 1.02989
[5]	training's multi_logloss: 1.01464	validation's multi_logloss: 1.02508
[6]	training's multi_logloss: 1.0105	validation's multi_logloss: 1.02259
[7]	training's multi_logloss: 1.00758	validation's multi_logloss: 1.02047
[8]	training's multi_logloss: 1.00413	validation's multi_logloss: 1.01817
[9]	training's multi_logloss: 1.00215	validation's multi_logloss: 1.01686
[10]	training's multi_logloss: 0.999519	validation's multi_logloss: 1.01511
[11]	training's multi_logloss: 0.997986	validation's multi_logloss: 1.01387
[12]	training's multi_logloss: 0.996445	validation's multi_logloss: 1.01331
[13]	training's multi_logloss: 0.994634	validation's multi_logloss: 1.01251
[14]	training's multi_logloss: 0.993781	validation's multi_logloss: 1.01164
[15]	training's multi_logloss: 0.993084	validation's multi_logloss: 1.01148
[16]	training's multi_logloss: 0.992272	validation's multi_logloss: 1.01114
[17]	training's multi_logloss: 0.991446	validation's multi_logloss: 1.01083
[18]	training's multi_logloss: 0.99049	validation's multi_logloss: 1.01083
[19]	training's multi_logloss: 0.989951	validation's multi_logloss: 1.01052
[20]	training's multi_logloss: 0.98912	validation's multi_logloss: 1.0102
[21]	training's multi_logloss: 0.988835	validation's multi_logloss: 1.01006
[22]	training's multi_logloss: 0.988437	validation's multi_logloss: 1.00992
[23]	training's multi_logloss: 0.988225	validation's multi_logloss: 1.00961
[24]	training's multi_logloss: 0.987768	validation's multi_logloss: 1.00974
[25]	training's multi_logloss: 0.987246	validation's multi_logloss: 1.00965
[26]	training's multi_logloss: 0.987073	validation's multi_logloss: 1.00954
[27]	training's multi_logloss: 0.986963	validation's multi_logloss: 1.0097
[28]	training's multi_logloss: 0.986717	validation's multi_logloss: 1.00962
[29]	training's multi_logloss: 0.986368	validation's multi_logloss: 1.0098
[30]	training's multi_logloss: 0.986368	validation's multi_logloss: 1.0098
[31]	training's multi_logloss: 0.986368	validation's multi_logloss: 1.0098
[32]	training's multi_logloss: 0.986368	validation's multi_logloss: 1.0098
[33]	training's multi_logloss: 0.986244	validation's multi_logloss: 1.00979
[34]	training's multi_logloss: 0.986244	validation's multi_logloss: 1.00979
[35]	training's multi_logloss: 0.986107	validation's multi_logloss: 1.00981
[36]	training's multi_logloss: 0.986107	validation's multi_logloss: 1.00981
[37]	training's multi_logloss: 0.985885	validation's multi_logloss: 1.0098
[38]	training's multi_logloss: 0.985551	validation's multi_logloss: 1.00996
[39]	training's multi_logloss: 0.98514	validation's multi_logloss: 1.01023
[40]	training's multi_logloss: 0.984949	validation's multi_logloss: 1.01028
[41]	training's multi_logloss: 0.984949	validation's multi_logloss: 1.01028
[42]	training's multi_logloss: 0.9848	validation's multi_logloss: 1.01033
[43]	training's multi_logloss: 0.9848	validation's multi_logloss: 1.01033
[44]	training's multi_logloss: 0.984688	validation's multi_logloss: 1.01021
[45]	training's multi_logloss: 0.984688	validation's multi_logloss: 1.01021
[46]	training's multi_logloss: 0.984688	validation's multi_logloss: 1.01021
Early stopping, best iteration is:
[26]	training's multi_logloss: 0.987073	validation's multi_logloss: 1.00954
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=6.932605245654812, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.932605245654812
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.0469	validation's multi_logloss: 1.04782
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03792	validation's multi_logloss: 1.04118
[3]	training's multi_logloss: 1.02943	validation's multi_logloss: 1.03385
[4]	training's multi_logloss: 1.02298	validation's multi_logloss: 1.02808
[5]	training's multi_logloss: 1.01722	validation's multi_logloss: 1.02323
[6]	training's multi_logloss: 1.013	validation's multi_logloss: 1.01956
[7]	training's multi_logloss: 1.00858	validation's multi_logloss: 1.01624
[8]	training's multi_logloss: 1.00589	validation's multi_logloss: 1.014
[9]	training's multi_logloss: 1.00325	validation's multi_logloss: 1.0117
[10]	training's multi_logloss: 1.00067	validation's multi_logloss: 1.00983
[11]	training's multi_logloss: 0.998764	validation's multi_logloss: 1.00847
[12]	training's multi_logloss: 0.997102	validation's multi_logloss: 1.00721
[13]	training's multi_logloss: 0.996161	validation's multi_logloss: 1.00664
[14]	training's multi_logloss: 0.995079	validation's multi_logloss: 1.00627
[15]	training's multi_logloss: 0.994209	validation's multi_logloss: 1.00612
[16]	training's multi_logloss: 0.993459	validation's multi_logloss: 1.00573
[17]	training's multi_logloss: 0.992837	validation's multi_logloss: 1.00542
[18]	training's multi_logloss: 0.992112	validation's multi_logloss: 1.00458
[19]	training's multi_logloss: 0.991575	validation's multi_logloss: 1.00408
[20]	training's multi_logloss: 0.991429	validation's multi_logloss: 1.00407
[21]	training's multi_logloss: 0.990897	validation's multi_logloss: 1.00388
[22]	training's multi_logloss: 0.990474	validation's multi_logloss: 1.00376
[23]	training's multi_logloss: 0.990273	validation's multi_logloss: 1.00364
[24]	training's multi_logloss: 0.990273	validation's multi_logloss: 1.00364
[25]	training's multi_logloss: 0.990034	validation's multi_logloss: 1.00343
[26]	training's multi_logloss: 0.989859	validation's multi_logloss: 1.00325
[27]	training's multi_logloss: 0.989521	validation's multi_logloss: 1.00295
[28]	training's multi_logloss: 0.989521	validation's multi_logloss: 1.00295
[29]	training's multi_logloss: 0.989521	validation's multi_logloss: 1.00295
[30]	training's multi_logloss: 0.989218	validation's multi_logloss: 1.00269
[31]	training's multi_logloss: 0.989035	validation's multi_logloss: 1.00271
[32]	training's multi_logloss: 0.988903	validation's multi_logloss: 1.00276
[33]	training's multi_logloss: 0.988903	validation's multi_logloss: 1.00276
[34]	training's multi_logloss: 0.988903	validation's multi_logloss: 1.00276
[35]	training's multi_logloss: 0.988739	validation's multi_logloss: 1.00274
[36]	training's multi_logloss: 0.988482	validation's multi_logloss: 1.00295
[37]	training's multi_logloss: 0.988482	validation's multi_logloss: 1.00295
[38]	training's multi_logloss: 0.988482	validation's multi_logloss: 1.00295
[39]	training's multi_logloss: 0.988244	validation's multi_logloss: 1.0029
[40]	training's multi_logloss: 0.988067	validation's multi_logloss: 1.00289
[41]	training's multi_logloss: 0.987953	validation's multi_logloss: 1.0031
[42]	training's multi_logloss: 0.987953	validation's multi_logloss: 1.0031
[43]	training's multi_logloss: 0.987953	validation's multi_logloss: 1.0031
[44]	training's multi_logloss: 0.987953	validation's multi_logloss: 1.0031
[45]	training's multi_logloss: 0.987953	validation's multi_logloss: 1.0031
[46]	training's multi_logloss: 0.987804	validation's multi_logloss: 1.00305
[47]	training's multi_logloss: 0.987804	validation's multi_logloss: 1.00305
[48]	training's multi_logloss: 0.987804	validation's multi_logloss: 1.00305
[49]	training's multi_logloss: 0.987804	validation's multi_logloss: 1.00305
[50]	training's multi_logloss: 0.987726	validation's multi_logloss: 1.00314
Early stopping, best iteration is:
[30]	training's multi_logloss: 0.989218	validation's multi_logloss: 1.00269
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=2200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2200
[LightGBM] [Warning] min_gain_to_split is set=8.59475402860501, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.59475402860501
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=2200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2200
[LightGBM] [Warning] min_gain_to_split is set=8.59475402860501, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.59475402860501
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=2200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2200
[LightGBM] [Warning] min_gain_to_split is set=8.59475402860501, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.59475402860501
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=2200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2200
[LightGBM] [Warning] min_gain_to_split is set=8.59475402860501, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.59475402860501
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300
[LightGBM] [Warning] min_gain_to_split is set=6.743412912344107, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.743412912344107
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300
[LightGBM] [Warning] min_gain_to_split is set=6.743412912344107, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.743412912344107
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300
[LightGBM] [Warning] min_gain_to_split is set=6.743412912344107, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.743412912344107
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300
[LightGBM] [Warning] min_gain_to_split is set=6.743412912344107, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.743412912344107
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600
[LightGBM] [Warning] min_gain_to_split is set=7.198330743003687, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.198330743003687
[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04732	validation's multi_logloss: 1.04681
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03743	validation's multi_logloss: 1.03582
[3]	training's multi_logloss: 1.02904	validation's multi_logloss: 1.0281
[4]	training's multi_logloss: 1.02282	validation's multi_logloss: 1.02131
[5]	training's multi_logloss: 1.01797	validation's multi_logloss: 1.01663
[6]	training's multi_logloss: 1.01358	validation's multi_logloss: 1.01181
[7]	training's multi_logloss: 1.01053	validation's multi_logloss: 1.00935
[8]	training's multi_logloss: 1.00783	validation's multi_logloss: 1.00695
[9]	training's multi_logloss: 1.00599	validation's multi_logloss: 1.00509
[10]	training's multi_logloss: 1.00378	validation's multi_logloss: 1.00304
[11]	training's multi_logloss: 1.00277	validation's multi_logloss: 1.00241
[12]	training's multi_logloss: 1.00136	validation's multi_logloss: 1.00126
[13]	training's multi_logloss: 0.999821	validation's multi_logloss: 0.999627
[14]	training's multi_logloss: 0.99867	validation's multi_logloss: 0.998367
[15]	training's multi_logloss: 0.997989	validation's multi_logloss: 0.997826
[16]	training's multi_logloss: 0.997294	validation's multi_logloss: 0.997094
[17]	training's multi_logloss: 0.996655	validation's multi_logloss: 0.996489
[18]	training's multi_logloss: 0.99614	validation's multi_logloss: 0.996105
[19]	training's multi_logloss: 0.99614	validation's multi_logloss: 0.996105
[20]	training's multi_logloss: 0.995634	validation's multi_logloss: 0.995636
[21]	training's multi_logloss: 0.995437	validation's multi_logloss: 0.995452
[22]	training's multi_logloss: 0.995116	validation's multi_logloss: 0.99507
[23]	training's multi_logloss: 0.995116	validation's multi_logloss: 0.99507
[24]	training's multi_logloss: 0.995116	validation's multi_logloss: 0.99507
[25]	training's multi_logloss: 0.994522	validation's multi_logloss: 0.994713
[26]	training's multi_logloss: 0.994522	validation's multi_logloss: 0.994713
[27]	training's multi_logloss: 0.994522	validation's multi_logloss: 0.994713
[28]	training's multi_logloss: 0.994522	validation's multi_logloss: 0.994713
[29]	training's multi_logloss: 0.994522	validation's multi_logloss: 0.994713
[30]	training's multi_logloss: 0.994286	validation's multi_logloss: 0.994577
[31]	training's multi_logloss: 0.994286	validation's multi_logloss: 0.994577
[32]	training's multi_logloss: 0.994001	validation's multi_logloss: 0.994566
[33]	training's multi_logloss: 0.994001	validation's multi_logloss: 0.994566
[34]	training's multi_logloss: 0.994001	validation's multi_logloss: 0.994566
[35]	training's multi_logloss: 0.994001	validation's multi_logloss: 0.994566
[36]	training's multi_logloss: 0.994001	validation's multi_logloss: 0.994566
[37]	training's multi_logloss: 0.994001	validation's multi_logloss: 0.994566
[38]	training's multi_logloss: 0.994001	validation's multi_logloss: 0.994566
[39]	training's multi_logloss: 0.994001	validation's multi_logloss: 0.994566
[40]	training's multi_logloss: 0.994001	validation's multi_logloss: 0.994566
[41]	training's multi_logloss: 0.994001	validation's multi_logloss: 0.994566
[42]	training's multi_logloss: 0.994001	validation's multi_logloss: 0.994566
[43]	training's multi_logloss: 0.993794	validation's multi_logloss: 0.994509
[44]	training's multi_logloss: 0.993794	validation's multi_logloss: 0.994509
[45]	training's multi_logloss: 0.993794	validation's multi_logloss: 0.994509
[46]	training's multi_logloss: 0.993794	validation's multi_logloss: 0.994509
[47]	training's multi_logloss: 0.993794	validation's multi_logloss: 0.994509
[48]	training's multi_logloss: 0.993794	validation's multi_logloss: 0.994509
[49]	training's multi_logloss: 0.993794	validation's multi_logloss: 0.994509
[50]	training's multi_logloss: 0.993794	validation's multi_logloss: 0.994509
[51]	training's multi_logloss: 0.993794	validation's multi_logloss: 0.994509
[52]	training's multi_logloss: 0.993542	validation's multi_logloss: 0.994265
[53]	training's multi_logloss: 0.993542	validation's multi_logloss: 0.994265
[54]	training's multi_logloss: 0.993542	validation's multi_logloss: 0.994265
[55]	training's multi_logloss: 0.993542	validation's multi_logloss: 0.994265
[56]	training's multi_logloss: 0.993542	validation's multi_logloss: 0.994265
[57]	training's multi_logloss: 0.993542	validation's multi_logloss: 0.994265
[58]	training's multi_logloss: 0.993542	validation's multi_logloss: 0.994265
[59]	training's multi_logloss: 0.993542	validation's multi_logloss: 0.994265
[60]	training's multi_logloss: 0.993542	validation's multi_logloss: 0.994265
[61]	training's multi_logloss: 0.993542	validation's multi_logloss: 0.994265
[62]	training's multi_logloss: 0.993542	validation's multi_logloss: 0.994265
[63]	training's multi_logloss: 0.993542	validation's multi_logloss: 0.994265
[64]	training's multi_logloss: 0.993542	validation's multi_logloss: 0.994265
[65]	training's multi_logloss: 0.993542	validation's multi_logloss: 0.994265
[66]	training's multi_logloss: 0.993542	validation's multi_logloss: 0.994265
[67]	training's multi_logloss: 0.993542	validation's multi_logloss: 0.994265
[68]	training's multi_logloss: 0.993542	validation's multi_logloss: 0.994265
[69]	training's multi_logloss: 0.993333	validation's multi_logloss: 0.993925
[70]	training's multi_logloss: 0.993082	validation's multi_logloss: 0.993815
[71]	training's multi_logloss: 0.993082	validation's multi_logloss: 0.993815
[72]	training's multi_logloss: 0.993082	validation's multi_logloss: 0.993815
[73]	training's multi_logloss: 0.993082	validation's multi_logloss: 0.993815
[74]	training's multi_logloss: 0.992888	validation's multi_logloss: 0.993789
[75]	training's multi_logloss: 0.992888	validation's multi_logloss: 0.993789
[76]	training's multi_logloss: 0.992888	validation's multi_logloss: 0.993789
[77]	training's multi_logloss: 0.992888	validation's multi_logloss: 0.993789
[78]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[79]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[80]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[81]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[82]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[83]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[84]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[85]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[86]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[87]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[88]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[89]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[90]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[91]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[92]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[93]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[94]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[95]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[96]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[97]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[98]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
Early stopping, best iteration is:
[78]	training's multi_logloss: 0.992695	validation's multi_logloss: 0.993588
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600
[LightGBM] [Warning] min_gain_to_split is set=7.198330743003687, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.198330743003687
[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18546	validation's multi_logloss: 1.1862
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.16873	validation's multi_logloss: 1.17002
[3]	training's multi_logloss: 1.15504	validation's multi_logloss: 1.15607
[4]	training's multi_logloss: 1.14228	validation's multi_logloss: 1.14316
[5]	training's multi_logloss: 1.13204	validation's multi_logloss: 1.13271
[6]	training's multi_logloss: 1.12261	validation's multi_logloss: 1.12275
[7]	training's multi_logloss: 1.11364	validation's multi_logloss: 1.11364
[8]	training's multi_logloss: 1.1052	validation's multi_logloss: 1.10504
[9]	training's multi_logloss: 1.09706	validation's multi_logloss: 1.0969
[10]	training's multi_logloss: 1.08958	validation's multi_logloss: 1.0898
[11]	training's multi_logloss: 1.086	validation's multi_logloss: 1.08552
[12]	training's multi_logloss: 1.07988	validation's multi_logloss: 1.07919
[13]	training's multi_logloss: 1.07433	validation's multi_logloss: 1.07423
[14]	training's multi_logloss: 1.06867	validation's multi_logloss: 1.06809
[15]	training's multi_logloss: 1.06333	validation's multi_logloss: 1.06289
[16]	training's multi_logloss: 1.06333	validation's multi_logloss: 1.06289
[17]	training's multi_logloss: 1.05857	validation's multi_logloss: 1.05806
[18]	training's multi_logloss: 1.05399	validation's multi_logloss: 1.05336
[19]	training's multi_logloss: 1.05221	validation's multi_logloss: 1.05136
[20]	training's multi_logloss: 1.04974	validation's multi_logloss: 1.04889
[21]	training's multi_logloss: 1.04974	validation's multi_logloss: 1.04889
[22]	training's multi_logloss: 1.04786	validation's multi_logloss: 1.04717
[23]	training's multi_logloss: 1.04569	validation's multi_logloss: 1.04511
[24]	training's multi_logloss: 1.04377	validation's multi_logloss: 1.04303
[25]	training's multi_logloss: 1.04145	validation's multi_logloss: 1.04131
[26]	training's multi_logloss: 1.03802	validation's multi_logloss: 1.0382
[27]	training's multi_logloss: 1.03459	validation's multi_logloss: 1.03496
[28]	training's multi_logloss: 1.03459	validation's multi_logloss: 1.03496
[29]	training's multi_logloss: 1.03459	validation's multi_logloss: 1.03496
[30]	training's multi_logloss: 1.03459	validation's multi_logloss: 1.03496
[31]	training's multi_logloss: 1.03278	validation's multi_logloss: 1.03327
[32]	training's multi_logloss: 1.03278	validation's multi_logloss: 1.03327
[33]	training's multi_logloss: 1.03278	validation's multi_logloss: 1.03327
[34]	training's multi_logloss: 1.03093	validation's multi_logloss: 1.03155
[35]	training's multi_logloss: 1.03093	validation's multi_logloss: 1.03155
[36]	training's multi_logloss: 1.03093	validation's multi_logloss: 1.03155
[37]	training's multi_logloss: 1.03093	validation's multi_logloss: 1.03155
[38]	training's multi_logloss: 1.03093	validation's multi_logloss: 1.03155
[39]	training's multi_logloss: 1.0297	validation's multi_logloss: 1.03053
[40]	training's multi_logloss: 1.0297	validation's multi_logloss: 1.03053
[41]	training's multi_logloss: 1.0297	validation's multi_logloss: 1.03053
[42]	training's multi_logloss: 1.0297	validation's multi_logloss: 1.03053
[43]	training's multi_logloss: 1.0297	validation's multi_logloss: 1.03053
[44]	training's multi_logloss: 1.02836	validation's multi_logloss: 1.02908
[45]	training's multi_logloss: 1.02836	validation's multi_logloss: 1.02908
[46]	training's multi_logloss: 1.02836	validation's multi_logloss: 1.02908
[47]	training's multi_logloss: 1.02836	validation's multi_logloss: 1.02908
[48]	training's multi_logloss: 1.02836	validation's multi_logloss: 1.02908
[49]	training's multi_logloss: 1.02753	validation's multi_logloss: 1.02837
[50]	training's multi_logloss: 1.02753	validation's multi_logloss: 1.02837
[51]	training's multi_logloss: 1.02753	validation's multi_logloss: 1.02837
[52]	training's multi_logloss: 1.02753	validation's multi_logloss: 1.02837
[53]	training's multi_logloss: 1.02753	validation's multi_logloss: 1.02837
[54]	training's multi_logloss: 1.02753	validation's multi_logloss: 1.02837
[55]	training's multi_logloss: 1.02753	validation's multi_logloss: 1.02837
[56]	training's multi_logloss: 1.02753	validation's multi_logloss: 1.02837
[57]	training's multi_logloss: 1.02546	validation's multi_logloss: 1.02627
[58]	training's multi_logloss: 1.02546	validation's multi_logloss: 1.02627
[59]	training's multi_logloss: 1.02546	validation's multi_logloss: 1.02627
[60]	training's multi_logloss: 1.02344	validation's multi_logloss: 1.02426
[61]	training's multi_logloss: 1.02344	validation's multi_logloss: 1.02426
[62]	training's multi_logloss: 1.02344	validation's multi_logloss: 1.02426
[63]	training's multi_logloss: 1.02216	validation's multi_logloss: 1.02291
[64]	training's multi_logloss: 1.02216	validation's multi_logloss: 1.02291
[65]	training's multi_logloss: 1.02087	validation's multi_logloss: 1.02173
[66]	training's multi_logloss: 1.02087	validation's multi_logloss: 1.02173
[67]	training's multi_logloss: 1.02087	validation's multi_logloss: 1.02173
[68]	training's multi_logloss: 1.02087	validation's multi_logloss: 1.02173
[69]	training's multi_logloss: 1.02087	validation's multi_logloss: 1.02173
[70]	training's multi_logloss: 1.02087	validation's multi_logloss: 1.02173
[71]	training's multi_logloss: 1.01488	validation's multi_logloss: 1.01597
[72]	training's multi_logloss: 1.01488	validation's multi_logloss: 1.01597
[73]	training's multi_logloss: 1.01488	validation's multi_logloss: 1.01597
[74]	training's multi_logloss: 1.01488	validation's multi_logloss: 1.01597
[75]	training's multi_logloss: 1.01488	validation's multi_logloss: 1.01597
[76]	training's multi_logloss: 1.01488	validation's multi_logloss: 1.01597
[77]	training's multi_logloss: 1.01488	validation's multi_logloss: 1.01597
[78]	training's multi_logloss: 1.01488	validation's multi_logloss: 1.01597
[79]	training's multi_logloss: 1.01488	validation's multi_logloss: 1.01597
[80]	training's multi_logloss: 1.01488	validation's multi_logloss: 1.01597
[81]	training's multi_logloss: 1.01488	validation's multi_logloss: 1.01597
[82]	training's multi_logloss: 1.01488	validation's multi_logloss: 1.01597
[83]	training's multi_logloss: 1.01488	validation's multi_logloss: 1.01597
[84]	training's multi_logloss: 1.01402	validation's multi_logloss: 1.01523
[85]	training's multi_logloss: 1.01402	validation's multi_logloss: 1.01523
[86]	training's multi_logloss: 1.01402	validation's multi_logloss: 1.01523
[87]	training's multi_logloss: 1.01402	validation's multi_logloss: 1.01523
[88]	training's multi_logloss: 1.01402	validation's multi_logloss: 1.01523
[89]	training's multi_logloss: 1.01308	validation's multi_logloss: 1.01469
[90]	training's multi_logloss: 1.01308	validation's multi_logloss: 1.01469
[91]	training's multi_logloss: 1.01308	validation's multi_logloss: 1.01469
[92]	training's multi_logloss: 1.01308	validation's multi_logloss: 1.01469
[93]	training's multi_logloss: 1.01308	validation's multi_logloss: 1.01469
[94]	training's multi_logloss: 1.01215	validation's multi_logloss: 1.01375
[95]	training's multi_logloss: 1.01134	validation's multi_logloss: 1.01317
[96]	training's multi_logloss: 1.01134	validation's multi_logloss: 1.01317
[97]	training's multi_logloss: 1.01134	validation's multi_logloss: 1.01317
[98]	training's multi_logloss: 1.01134	validation's multi_logloss: 1.01317
[99]	training's multi_logloss: 1.01134	validation's multi_logloss: 1.01317
[100]	training's multi_logloss: 1.01059	validation's multi_logloss: 1.0124
Did not meet early stopping. Best iteration is:
[100]	training's multi_logloss: 1.01059	validation's multi_logloss: 1.0124
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600
[LightGBM] [Warning] min_gain_to_split is set=7.198330743003687, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.198330743003687
[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04665	validation's multi_logloss: 1.05004
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03523	validation's multi_logloss: 1.04127
[3]	training's multi_logloss: 1.02727	validation's multi_logloss: 1.03452
[4]	training's multi_logloss: 1.02107	validation's multi_logloss: 1.02946
[5]	training's multi_logloss: 1.01545	validation's multi_logloss: 1.02534
[6]	training's multi_logloss: 1.0114	validation's multi_logloss: 1.02199
[7]	training's multi_logloss: 1.00819	validation's multi_logloss: 1.02025
[8]	training's multi_logloss: 1.00498	validation's multi_logloss: 1.01794
[9]	training's multi_logloss: 1.00298	validation's multi_logloss: 1.01692
[10]	training's multi_logloss: 1.00036	validation's multi_logloss: 1.01527
[11]	training's multi_logloss: 0.998908	validation's multi_logloss: 1.01409
[12]	training's multi_logloss: 0.997518	validation's multi_logloss: 1.01339
[13]	training's multi_logloss: 0.996528	validation's multi_logloss: 1.01281
[14]	training's multi_logloss: 0.995555	validation's multi_logloss: 1.01182
[15]	training's multi_logloss: 0.995161	validation's multi_logloss: 1.01169
[16]	training's multi_logloss: 0.994335	validation's multi_logloss: 1.01127
[17]	training's multi_logloss: 0.993558	validation's multi_logloss: 1.01096
[18]	training's multi_logloss: 0.992737	validation's multi_logloss: 1.01091
[19]	training's multi_logloss: 0.992737	validation's multi_logloss: 1.01091
[20]	training's multi_logloss: 0.992048	validation's multi_logloss: 1.01074
[21]	training's multi_logloss: 0.991403	validation's multi_logloss: 1.01042
[22]	training's multi_logloss: 0.99106	validation's multi_logloss: 1.0102
[23]	training's multi_logloss: 0.990684	validation's multi_logloss: 1.01007
[24]	training's multi_logloss: 0.990171	validation's multi_logloss: 1.00976
[25]	training's multi_logloss: 0.989882	validation's multi_logloss: 1.00968
[26]	training's multi_logloss: 0.989882	validation's multi_logloss: 1.00968
[27]	training's multi_logloss: 0.989882	validation's multi_logloss: 1.00968
[28]	training's multi_logloss: 0.989687	validation's multi_logloss: 1.00948
[29]	training's multi_logloss: 0.989425	validation's multi_logloss: 1.00945
[30]	training's multi_logloss: 0.989425	validation's multi_logloss: 1.00945
[31]	training's multi_logloss: 0.989151	validation's multi_logloss: 1.00944
[32]	training's multi_logloss: 0.989151	validation's multi_logloss: 1.00944
[33]	training's multi_logloss: 0.988715	validation's multi_logloss: 1.00908
[34]	training's multi_logloss: 0.988715	validation's multi_logloss: 1.00908
[35]	training's multi_logloss: 0.988715	validation's multi_logloss: 1.00908
[36]	training's multi_logloss: 0.988715	validation's multi_logloss: 1.00908
[37]	training's multi_logloss: 0.9884	validation's multi_logloss: 1.00862
[38]	training's multi_logloss: 0.9884	validation's multi_logloss: 1.00862
[39]	training's multi_logloss: 0.988038	validation's multi_logloss: 1.00867
[40]	training's multi_logloss: 0.988038	validation's multi_logloss: 1.00867
[41]	training's multi_logloss: 0.988038	validation's multi_logloss: 1.00867
[42]	training's multi_logloss: 0.987803	validation's multi_logloss: 1.00868
[43]	training's multi_logloss: 0.987803	validation's multi_logloss: 1.00868
[44]	training's multi_logloss: 0.987803	validation's multi_logloss: 1.00868
[45]	training's multi_logloss: 0.987803	validation's multi_logloss: 1.00868
[46]	training's multi_logloss: 0.987803	validation's multi_logloss: 1.00868
[47]	training's multi_logloss: 0.987803	validation's multi_logloss: 1.00868
[48]	training's multi_logloss: 0.987803	validation's multi_logloss: 1.00868
[49]	training's multi_logloss: 0.987803	validation's multi_logloss: 1.00868
[50]	training's multi_logloss: 0.987803	validation's multi_logloss: 1.00868
[51]	training's multi_logloss: 0.987803	validation's multi_logloss: 1.00868
[52]	training's multi_logloss: 0.987803	validation's multi_logloss: 1.00868
[53]	training's multi_logloss: 0.987803	validation's multi_logloss: 1.00868
[54]	training's multi_logloss: 0.987803	validation's multi_logloss: 1.00868
[55]	training's multi_logloss: 0.987618	validation's multi_logloss: 1.00845
[56]	training's multi_logloss: 0.987618	validation's multi_logloss: 1.00845
[57]	training's multi_logloss: 0.987618	validation's multi_logloss: 1.00845
[58]	training's multi_logloss: 0.987618	validation's multi_logloss: 1.00845
[59]	training's multi_logloss: 0.987618	validation's multi_logloss: 1.00845
[60]	training's multi_logloss: 0.987618	validation's multi_logloss: 1.00845
[61]	training's multi_logloss: 0.987618	validation's multi_logloss: 1.00845
[62]	training's multi_logloss: 0.987618	validation's multi_logloss: 1.00845
[63]	training's multi_logloss: 0.987618	validation's multi_logloss: 1.00845
[64]	training's multi_logloss: 0.987618	validation's multi_logloss: 1.00845
[65]	training's multi_logloss: 0.987618	validation's multi_logloss: 1.00845
[66]	training's multi_logloss: 0.987618	validation's multi_logloss: 1.00845
[67]	training's multi_logloss: 0.987618	validation's multi_logloss: 1.00845
[68]	training's multi_logloss: 0.987618	validation's multi_logloss: 1.00845
[69]	training's multi_logloss: 0.987618	validation's multi_logloss: 1.00845
[70]	training's multi_logloss: 0.987399	validation's multi_logloss: 1.00845
[71]	training's multi_logloss: 0.987399	validation's multi_logloss: 1.00845
[72]	training's multi_logloss: 0.987399	validation's multi_logloss: 1.00845
[73]	training's multi_logloss: 0.987399	validation's multi_logloss: 1.00845
[74]	training's multi_logloss: 0.987399	validation's multi_logloss: 1.00845
[75]	training's multi_logloss: 0.987235	validation's multi_logloss: 1.00846
[76]	training's multi_logloss: 0.987235	validation's multi_logloss: 1.00846
[77]	training's multi_logloss: 0.987235	validation's multi_logloss: 1.00846
[78]	training's multi_logloss: 0.987235	validation's multi_logloss: 1.00846
[79]	training's multi_logloss: 0.987235	validation's multi_logloss: 1.00846
[80]	training's multi_logloss: 0.987235	validation's multi_logloss: 1.00846
[81]	training's multi_logloss: 0.987235	validation's multi_logloss: 1.00846
[82]	training's multi_logloss: 0.987235	validation's multi_logloss: 1.00846
[83]	training's multi_logloss: 0.987235	validation's multi_logloss: 1.00846
[84]	training's multi_logloss: 0.987235	validation's multi_logloss: 1.00846
[85]	training's multi_logloss: 0.987235	validation's multi_logloss: 1.00846
[86]	training's multi_logloss: 0.987235	validation's multi_logloss: 1.00846
[87]	training's multi_logloss: 0.987235	validation's multi_logloss: 1.00846
[88]	training's multi_logloss: 0.987235	validation's multi_logloss: 1.00846
[89]	training's multi_logloss: 0.987235	validation's multi_logloss: 1.00846
[90]	training's multi_logloss: 0.987235	validation's multi_logloss: 1.00846
Early stopping, best iteration is:
[70]	training's multi_logloss: 0.987399	validation's multi_logloss: 1.00845
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600
[LightGBM] [Warning] min_gain_to_split is set=7.198330743003687, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.198330743003687
[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04649	validation's multi_logloss: 1.04723
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03635	validation's multi_logloss: 1.03911
[3]	training's multi_logloss: 1.0281	validation's multi_logloss: 1.03253
[4]	training's multi_logloss: 1.02237	validation's multi_logloss: 1.02769
[5]	training's multi_logloss: 1.01681	validation's multi_logloss: 1.02312
[6]	training's multi_logloss: 1.01223	validation's multi_logloss: 1.01933
[7]	training's multi_logloss: 1.00868	validation's multi_logloss: 1.01654
[8]	training's multi_logloss: 1.00626	validation's multi_logloss: 1.01417
[9]	training's multi_logloss: 1.0039	validation's multi_logloss: 1.01186
[10]	training's multi_logloss: 1.0015	validation's multi_logloss: 1.01043
[11]	training's multi_logloss: 1.00046	validation's multi_logloss: 1.00953
[12]	training's multi_logloss: 0.999065	validation's multi_logloss: 1.00867
[13]	training's multi_logloss: 0.998182	validation's multi_logloss: 1.00827
[14]	training's multi_logloss: 0.997304	validation's multi_logloss: 1.00781
[15]	training's multi_logloss: 0.996625	validation's multi_logloss: 1.00736
[16]	training's multi_logloss: 0.995958	validation's multi_logloss: 1.00673
[17]	training's multi_logloss: 0.995252	validation's multi_logloss: 1.00656
[18]	training's multi_logloss: 0.994594	validation's multi_logloss: 1.00581
[19]	training's multi_logloss: 0.993935	validation's multi_logloss: 1.00525
[20]	training's multi_logloss: 0.993935	validation's multi_logloss: 1.00525
[21]	training's multi_logloss: 0.993264	validation's multi_logloss: 1.00486
[22]	training's multi_logloss: 0.992795	validation's multi_logloss: 1.00485
[23]	training's multi_logloss: 0.99253	validation's multi_logloss: 1.00465
[24]	training's multi_logloss: 0.99253	validation's multi_logloss: 1.00465
[25]	training's multi_logloss: 0.99253	validation's multi_logloss: 1.00465
[26]	training's multi_logloss: 0.99253	validation's multi_logloss: 1.00465
[27]	training's multi_logloss: 0.99253	validation's multi_logloss: 1.00465
[28]	training's multi_logloss: 0.99253	validation's multi_logloss: 1.00465
[29]	training's multi_logloss: 0.99253	validation's multi_logloss: 1.00465
[30]	training's multi_logloss: 0.992288	validation's multi_logloss: 1.00453
[31]	training's multi_logloss: 0.992288	validation's multi_logloss: 1.00453
[32]	training's multi_logloss: 0.992288	validation's multi_logloss: 1.00453
[33]	training's multi_logloss: 0.992288	validation's multi_logloss: 1.00453
[34]	training's multi_logloss: 0.992288	validation's multi_logloss: 1.00453
[35]	training's multi_logloss: 0.992288	validation's multi_logloss: 1.00453
[36]	training's multi_logloss: 0.992033	validation's multi_logloss: 1.00472
[37]	training's multi_logloss: 0.992033	validation's multi_logloss: 1.00472
[38]	training's multi_logloss: 0.992033	validation's multi_logloss: 1.00472
[39]	training's multi_logloss: 0.991805	validation's multi_logloss: 1.00465
[40]	training's multi_logloss: 0.991615	validation's multi_logloss: 1.00464
[41]	training's multi_logloss: 0.991453	validation's multi_logloss: 1.0046
[42]	training's multi_logloss: 0.991201	validation's multi_logloss: 1.0042
[43]	training's multi_logloss: 0.991201	validation's multi_logloss: 1.0042
[44]	training's multi_logloss: 0.991201	validation's multi_logloss: 1.0042
[45]	training's multi_logloss: 0.991201	validation's multi_logloss: 1.0042
[46]	training's multi_logloss: 0.990925	validation's multi_logloss: 1.00401
[47]	training's multi_logloss: 0.990925	validation's multi_logloss: 1.00401
[48]	training's multi_logloss: 0.990925	validation's multi_logloss: 1.00401
[49]	training's multi_logloss: 0.990925	validation's multi_logloss: 1.00401
[50]	training's multi_logloss: 0.99078	validation's multi_logloss: 1.00398
[51]	training's multi_logloss: 0.99078	validation's multi_logloss: 1.00398
[52]	training's multi_logloss: 0.99078	validation's multi_logloss: 1.00398
[53]	training's multi_logloss: 0.99078	validation's multi_logloss: 1.00398
[54]	training's multi_logloss: 0.99053	validation's multi_logloss: 1.00368
[55]	training's multi_logloss: 0.99053	validation's multi_logloss: 1.00368
[56]	training's multi_logloss: 0.99053	validation's multi_logloss: 1.00368
[57]	training's multi_logloss: 0.99053	validation's multi_logloss: 1.00368
[58]	training's multi_logloss: 0.99053	validation's multi_logloss: 1.00368
[59]	training's multi_logloss: 0.990261	validation's multi_logloss: 1.00351
[60]	training's multi_logloss: 0.990261	validation's multi_logloss: 1.00351
[61]	training's multi_logloss: 0.990261	validation's multi_logloss: 1.00351
[62]	training's multi_logloss: 0.990261	validation's multi_logloss: 1.00351
[63]	training's multi_logloss: 0.990261	validation's multi_logloss: 1.00351
[64]	training's multi_logloss: 0.990261	validation's multi_logloss: 1.00351
[65]	training's multi_logloss: 0.990261	validation's multi_logloss: 1.00351
[66]	training's multi_logloss: 0.990261	validation's multi_logloss: 1.00351
[67]	training's multi_logloss: 0.990261	validation's multi_logloss: 1.00351
[68]	training's multi_logloss: 0.990261	validation's multi_logloss: 1.00351
[69]	training's multi_logloss: 0.990261	validation's multi_logloss: 1.00351
[70]	training's multi_logloss: 0.990261	validation's multi_logloss: 1.00351
[71]	training's multi_logloss: 0.990261	validation's multi_logloss: 1.00351
[72]	training's multi_logloss: 0.990261	validation's multi_logloss: 1.00351
[73]	training's multi_logloss: 0.990261	validation's multi_logloss: 1.00351
[74]	training's multi_logloss: 0.990261	validation's multi_logloss: 1.00351
[75]	training's multi_logloss: 0.990261	validation's multi_logloss: 1.00351
[76]	training's multi_logloss: 0.990261	validation's multi_logloss: 1.00351
[77]	training's multi_logloss: 0.990261	validation's multi_logloss: 1.00351
[78]	training's multi_logloss: 0.9898	validation's multi_logloss: 1.00317
[79]	training's multi_logloss: 0.989602	validation's multi_logloss: 1.00291
[80]	training's multi_logloss: 0.989602	validation's multi_logloss: 1.00291
[81]	training's multi_logloss: 0.989406	validation's multi_logloss: 1.00292
[82]	training's multi_logloss: 0.989406	validation's multi_logloss: 1.00292
[83]	training's multi_logloss: 0.989406	validation's multi_logloss: 1.00292
[84]	training's multi_logloss: 0.989406	validation's multi_logloss: 1.00292
[85]	training's multi_logloss: 0.989406	validation's multi_logloss: 1.00292
[86]	training's multi_logloss: 0.989406	validation's multi_logloss: 1.00292
[87]	training's multi_logloss: 0.989406	validation's multi_logloss: 1.00292
[88]	training's multi_logloss: 0.989406	validation's multi_logloss: 1.00292
[89]	training's multi_logloss: 0.989406	validation's multi_logloss: 1.00292
[90]	training's multi_logloss: 0.989406	validation's multi_logloss: 1.00292
[91]	training's multi_logloss: 0.989406	validation's multi_logloss: 1.00292
[92]	training's multi_logloss: 0.989406	validation's multi_logloss: 1.00292
[93]	training's multi_logloss: 0.989406	validation's multi_logloss: 1.00292
[94]	training's multi_logloss: 0.989406	validation's multi_logloss: 1.00292
[95]	training's multi_logloss: 0.989406	validation's multi_logloss: 1.00292
[96]	training's multi_logloss: 0.989406	validation's multi_logloss: 1.00292
[97]	training's multi_logloss: 0.989406	validation's multi_logloss: 1.00292
[98]	training's multi_logloss: 0.989406	validation's multi_logloss: 1.00292
[99]	training's multi_logloss: 0.989406	validation's multi_logloss: 1.00292
Early stopping, best iteration is:
[79]	training's multi_logloss: 0.989602	validation's multi_logloss: 1.00291
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300
[LightGBM] [Warning] min_gain_to_split is set=8.953287284134271, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.953287284134271
[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05022	validation's multi_logloss: 1.04992
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.04146	validation's multi_logloss: 1.04052
[3]	training's multi_logloss: 1.03465	validation's multi_logloss: 1.0334
[4]	training's multi_logloss: 1.02883	validation's multi_logloss: 1.02729
[5]	training's multi_logloss: 1.02456	validation's multi_logloss: 1.02277
[6]	training's multi_logloss: 1.0204	validation's multi_logloss: 1.01892
[7]	training's multi_logloss: 1.01811	validation's multi_logloss: 1.01721
[8]	training's multi_logloss: 1.01547	validation's multi_logloss: 1.01502
[9]	training's multi_logloss: 1.01348	validation's multi_logloss: 1.01304
[10]	training's multi_logloss: 1.01115	validation's multi_logloss: 1.01062
[11]	training's multi_logloss: 1.00942	validation's multi_logloss: 1.00897
[12]	training's multi_logloss: 1.00837	validation's multi_logloss: 1.00787
[13]	training's multi_logloss: 1.00746	validation's multi_logloss: 1.00665
[14]	training's multi_logloss: 1.00634	validation's multi_logloss: 1.00539
[15]	training's multi_logloss: 1.00507	validation's multi_logloss: 1.00429
[16]	training's multi_logloss: 1.00428	validation's multi_logloss: 1.00349
[17]	training's multi_logloss: 1.00334	validation's multi_logloss: 1.00251
[18]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00161
[19]	training's multi_logloss: 1.00225	validation's multi_logloss: 1.00126
[20]	training's multi_logloss: 1.00161	validation's multi_logloss: 1.00028
[21]	training's multi_logloss: 1.00131	validation's multi_logloss: 1.00015
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=2600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2600
[LightGBM] [Warning] min_gain_to_split is set=6.405876403582206, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.405876403582206
[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=2600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2600
[LightGBM] [Warning] min_gain_to_split is set=6.405876403582206, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.405876403582206
[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=2600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2600
[LightGBM] [Warning] min_gain_to_split is set=6.405876403582206, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.405876403582206
[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000
[LightGBM] [Warning] min_gain_to_split is set=7.951830555128571, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.951830555128571
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000
[LightGBM] [Warning] min_gain_to_split is set=7.951830555128571, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.951830555128571
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000
[LightGBM] [Warning] min_gain_to_split is set=7.951830555128571, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.951830555128571
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=2000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2000
[LightGBM] [Warning] min_gain_to_split is set=7.951830555128571, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.951830555128571
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[12]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[13]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[14]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[15]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[16]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[17]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[18]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[19]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[20]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[21]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04603	validation's multi_logloss: 1.04545
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.0358	validation's multi_logloss: 1.0352
[3]	training's multi_logloss: 1.02741	validation's multi_logloss: 1.02762
[4]	training's multi_logloss: 1.02073	validation's multi_logloss: 1.02063
[5]	training's multi_logloss: 1.01539	validation's multi_logloss: 1.01531
[6]	training's multi_logloss: 1.01113	validation's multi_logloss: 1.01131
[7]	training's multi_logloss: 1.00709	validation's multi_logloss: 1.00769
[8]	training's multi_logloss: 1.00426	validation's multi_logloss: 1.00586
[9]	training's multi_logloss: 1.00212	validation's multi_logloss: 1.00383
[10]	training's multi_logloss: 1.00012	validation's multi_logloss: 1.00213
[11]	training's multi_logloss: 0.997976	validation's multi_logloss: 1.00067
[12]	training's multi_logloss: 0.996471	validation's multi_logloss: 0.999743
[13]	training's multi_logloss: 0.995041	validation's multi_logloss: 0.998151
[14]	training's multi_logloss: 0.993937	validation's multi_logloss: 0.997043
[15]	training's multi_logloss: 0.99292	validation's multi_logloss: 0.996185
[16]	training's multi_logloss: 0.992283	validation's multi_logloss: 0.995646
[17]	training's multi_logloss: 0.991633	validation's multi_logloss: 0.995054
[18]	training's multi_logloss: 0.991244	validation's multi_logloss: 0.994524
[19]	training's multi_logloss: 0.991059	validation's multi_logloss: 0.994438
[20]	training's multi_logloss: 0.990797	validation's multi_logloss: 0.99407
[21]	training's multi_logloss: 0.990384	validation's multi_logloss: 0.993598
[22]	training's multi_logloss: 0.990057	validation's multi_logloss: 0.993256
[23]	training's multi_logloss: 0.989952	validation's multi_logloss: 0.993262
[24]	training's multi_logloss: 0.989604	validation's multi_logloss: 0.993141
[25]	training's multi_logloss: 0.989229	validation's multi_logloss: 0.993003
[26]	training's multi_logloss: 0.988965	validation's multi_logloss: 0.992839
[27]	training's multi_logloss: 0.988751	validation's multi_logloss: 0.992858
[28]	training's multi_logloss: 0.988594	validation's multi_logloss: 0.992778
[29]	training's multi_logloss: 0.988353	validation's multi_logloss: 0.992591
[30]	training's multi_logloss: 0.988353	validation's multi_logloss: 0.992591
[31]	training's multi_logloss: 0.988353	validation's multi_logloss: 0.992591
[32]	training's multi_logloss: 0.988035	validation's multi_logloss: 0.992373
[33]	training's multi_logloss: 0.987919	validation's multi_logloss: 0.992076
[34]	training's multi_logloss: 0.987801	validation's multi_logloss: 0.992095
[35]	training's multi_logloss: 0.987643	validation's multi_logloss: 0.9921
[36]	training's multi_logloss: 0.987643	validation's multi_logloss: 0.9921
[37]	training's multi_logloss: 0.987489	validation's multi_logloss: 0.992172
[38]	training's multi_logloss: 0.987365	validation's multi_logloss: 0.992031
[39]	training's multi_logloss: 0.987365	validation's multi_logloss: 0.992031
[40]	training's multi_logloss: 0.987365	validation's multi_logloss: 0.992031
[41]	training's multi_logloss: 0.987365	validation's multi_logloss: 0.992031
[42]	training's multi_logloss: 0.987365	validation's multi_logloss: 0.992031
[43]	training's multi_logloss: 0.987317	validation's multi_logloss: 0.992124
[44]	training's multi_logloss: 0.987317	validation's multi_logloss: 0.992124
[45]	training's multi_logloss: 0.987194	validation's multi_logloss: 0.992071
[46]	training's multi_logloss: 0.987125	validation's multi_logloss: 0.992205
[47]	training's multi_logloss: 0.986966	validation's multi_logloss: 0.991989
[48]	training's multi_logloss: 0.986966	validation's multi_logloss: 0.991989
[49]	training's multi_logloss: 0.986966	validation's multi_logloss: 0.991989
[50]	training's multi_logloss: 0.986966	validation's multi_logloss: 0.991989
[51]	training's multi_logloss: 0.986821	validation's multi_logloss: 0.992068
[52]	training's multi_logloss: 0.986697	validation's multi_logloss: 0.992001
[53]	training's multi_logloss: 0.986697	validation's multi_logloss: 0.992001
[54]	training's multi_logloss: 0.986697	validation's multi_logloss: 0.992001
[55]	training's multi_logloss: 0.986697	validation's multi_logloss: 0.992001
[56]	training's multi_logloss: 0.986601	validation's multi_logloss: 0.991876
[57]	training's multi_logloss: 0.986601	validation's multi_logloss: 0.991876
[58]	training's multi_logloss: 0.986601	validation's multi_logloss: 0.991876
[59]	training's multi_logloss: 0.986601	validation's multi_logloss: 0.991876
[60]	training's multi_logloss: 0.986601	validation's multi_logloss: 0.991876
[61]	training's multi_logloss: 0.986601	validation's multi_logloss: 0.991876
[62]	training's multi_logloss: 0.986601	validation's multi_logloss: 0.991876
[63]	training's multi_logloss: 0.986601	validation's multi_logloss: 0.991876
[64]	training's multi_logloss: 0.986601	validation's multi_logloss: 0.991876
[65]	training's multi_logloss: 0.986516	validation's multi_logloss: 0.992002
[66]	training's multi_logloss: 0.986516	validation's multi_logloss: 0.992002
[67]	training's multi_logloss: 0.986516	validation's multi_logloss: 0.992002
[68]	training's multi_logloss: 0.986516	validation's multi_logloss: 0.992002
[69]	training's multi_logloss: 0.986353	validation's multi_logloss: 0.991794
[70]	training's multi_logloss: 0.986353	validation's multi_logloss: 0.991794
[71]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.991662
[72]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.991662
[73]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.991662
[74]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.991662
[75]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.991662
[76]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.991662
[77]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.991662
[78]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.991662
[79]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.991662
[80]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.991662
[81]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.991662
[82]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.991662
[83]	training's multi_logloss: 0.986132	validation's multi_logloss: 0.991823
[84]	training's multi_logloss: 0.986132	validation's multi_logloss: 0.991823
[85]	training's multi_logloss: 0.986042	validation's multi_logloss: 0.991823
[86]	training's multi_logloss: 0.986042	validation's multi_logloss: 0.991823
[87]	training's multi_logloss: 0.986042	validation's multi_logloss: 0.991823
[88]	training's multi_logloss: 0.985937	validation's multi_logloss: 0.991952
[89]	training's multi_logloss: 0.985937	validation's multi_logloss: 0.991952
[90]	training's multi_logloss: 0.985937	validation's multi_logloss: 0.991952
[91]	training's multi_logloss: 0.98585	validation's multi_logloss: 0.991849
Early stopping, best iteration is:
[71]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.991662
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.0486	validation's multi_logloss: 1.04823
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03716	validation's multi_logloss: 1.0365
[3]	training's multi_logloss: 1.02853	validation's multi_logloss: 1.02861
[4]	training's multi_logloss: 1.02226	validation's multi_logloss: 1.02226
[5]	training's multi_logloss: 1.01705	validation's multi_logloss: 1.01721
[6]	training's multi_logloss: 1.01264	validation's multi_logloss: 1.01288
[7]	training's multi_logloss: 1.00955	validation's multi_logloss: 1.01004
[8]	training's multi_logloss: 1.00632	validation's multi_logloss: 1.00676
[9]	training's multi_logloss: 1.00371	validation's multi_logloss: 1.00382
[10]	training's multi_logloss: 1.00135	validation's multi_logloss: 1.00146
[11]	training's multi_logloss: 0.99942	validation's multi_logloss: 0.999913
[12]	training's multi_logloss: 0.998162	validation's multi_logloss: 0.9989
[13]	training's multi_logloss: 0.997071	validation's multi_logloss: 0.998143
[14]	training's multi_logloss: 0.995941	validation's multi_logloss: 0.997326
[15]	training's multi_logloss: 0.994692	validation's multi_logloss: 0.996618
[16]	training's multi_logloss: 0.993932	validation's multi_logloss: 0.995817
[17]	training's multi_logloss: 0.993058	validation's multi_logloss: 0.995009
[18]	training's multi_logloss: 0.992384	validation's multi_logloss: 0.994405
[19]	training's multi_logloss: 0.992025	validation's multi_logloss: 0.994452
[20]	training's multi_logloss: 0.991814	validation's multi_logloss: 0.994087
[21]	training's multi_logloss: 0.991236	validation's multi_logloss: 0.993191
[22]	training's multi_logloss: 0.991055	validation's multi_logloss: 0.993193
[23]	training's multi_logloss: 0.990891	validation's multi_logloss: 0.993158
[24]	training's multi_logloss: 0.990689	validation's multi_logloss: 0.993223
[25]	training's multi_logloss: 0.99058	validation's multi_logloss: 0.993249
[26]	training's multi_logloss: 0.990285	validation's multi_logloss: 0.993095
[27]	training's multi_logloss: 0.990135	validation's multi_logloss: 0.992904
[28]	training's multi_logloss: 0.989995	validation's multi_logloss: 0.993024
[29]	training's multi_logloss: 0.989908	validation's multi_logloss: 0.992918
[30]	training's multi_logloss: 0.989787	validation's multi_logloss: 0.992856
[31]	training's multi_logloss: 0.989787	validation's multi_logloss: 0.992856
[32]	training's multi_logloss: 0.989664	validation's multi_logloss: 0.993016
[33]	training's multi_logloss: 0.989664	validation's multi_logloss: 0.993016
[34]	training's multi_logloss: 0.98933	validation's multi_logloss: 0.99267
[35]	training's multi_logloss: 0.98933	validation's multi_logloss: 0.99267
[36]	training's multi_logloss: 0.98933	validation's multi_logloss: 0.99267
[37]	training's multi_logloss: 0.989183	validation's multi_logloss: 0.992636
[38]	training's multi_logloss: 0.989183	validation's multi_logloss: 0.992636
[39]	training's multi_logloss: 0.98905	validation's multi_logloss: 0.992701
[40]	training's multi_logloss: 0.988992	validation's multi_logloss: 0.992572
[41]	training's multi_logloss: 0.988992	validation's multi_logloss: 0.992572
[42]	training's multi_logloss: 0.988992	validation's multi_logloss: 0.992572
[43]	training's multi_logloss: 0.988862	validation's multi_logloss: 0.992362
[44]	training's multi_logloss: 0.988862	validation's multi_logloss: 0.992362
[45]	training's multi_logloss: 0.988707	validation's multi_logloss: 0.992225
[46]	training's multi_logloss: 0.988707	validation's multi_logloss: 0.992225
[47]	training's multi_logloss: 0.988707	validation's multi_logloss: 0.992225
[48]	training's multi_logloss: 0.988707	validation's multi_logloss: 0.992225
[49]	training's multi_logloss: 0.988362	validation's multi_logloss: 0.992022
[50]	training's multi_logloss: 0.988362	validation's multi_logloss: 0.992022
[51]	training's multi_logloss: 0.988232	validation's multi_logloss: 0.992024
[52]	training's multi_logloss: 0.988232	validation's multi_logloss: 0.992024
[53]	training's multi_logloss: 0.988232	validation's multi_logloss: 0.992024
[54]	training's multi_logloss: 0.988232	validation's multi_logloss: 0.992024
[55]	training's multi_logloss: 0.988232	validation's multi_logloss: 0.992024
[56]	training's multi_logloss: 0.988232	validation's multi_logloss: 0.992024
[57]	training's multi_logloss: 0.988232	validation's multi_logloss: 0.992024
[58]	training's multi_logloss: 0.988232	validation's multi_logloss: 0.992024
[59]	training's multi_logloss: 0.988054	validation's multi_logloss: 0.992159
[60]	training's multi_logloss: 0.987975	validation's multi_logloss: 0.991948
[61]	training's multi_logloss: 0.987882	validation's multi_logloss: 0.992069
[62]	training's multi_logloss: 0.987882	validation's multi_logloss: 0.992069
[63]	training's multi_logloss: 0.987882	validation's multi_logloss: 0.992069
[64]	training's multi_logloss: 0.987803	validation's multi_logloss: 0.991929
[65]	training's multi_logloss: 0.987803	validation's multi_logloss: 0.991929
[66]	training's multi_logloss: 0.987803	validation's multi_logloss: 0.991929
[67]	training's multi_logloss: 0.987803	validation's multi_logloss: 0.991929
[68]	training's multi_logloss: 0.987803	validation's multi_logloss: 0.991929
[69]	training's multi_logloss: 0.987803	validation's multi_logloss: 0.991929
[70]	training's multi_logloss: 0.987803	validation's multi_logloss: 0.991929
[71]	training's multi_logloss: 0.987623	validation's multi_logloss: 0.991908
[72]	training's multi_logloss: 0.987623	validation's multi_logloss: 0.991908
[73]	training's multi_logloss: 0.987503	validation's multi_logloss: 0.991744
[74]	training's multi_logloss: 0.987394	validation's multi_logloss: 0.991754
[75]	training's multi_logloss: 0.987394	validation's multi_logloss: 0.991754
[76]	training's multi_logloss: 0.987324	validation's multi_logloss: 0.991817
[77]	training's multi_logloss: 0.987324	validation's multi_logloss: 0.991817
[78]	training's multi_logloss: 0.987324	validation's multi_logloss: 0.991817
[79]	training's multi_logloss: 0.987218	validation's multi_logloss: 0.991727
[80]	training's multi_logloss: 0.987218	validation's multi_logloss: 0.991727
[81]	training's multi_logloss: 0.987028	validation's multi_logloss: 0.991694
[82]	training's multi_logloss: 0.987028	validation's multi_logloss: 0.991694
[83]	training's multi_logloss: 0.987028	validation's multi_logloss: 0.991694
[84]	training's multi_logloss: 0.986882	validation's multi_logloss: 0.991576
[85]	training's multi_logloss: 0.986882	validation's multi_logloss: 0.991576
[86]	training's multi_logloss: 0.986882	validation's multi_logloss: 0.991576
[87]	training's multi_logloss: 0.986818	validation's multi_logloss: 0.991676
[88]	training's multi_logloss: 0.986818	validation's multi_logloss: 0.991676
[89]	training's multi_logloss: 0.986723	validation's multi_logloss: 0.991835
[90]	training's multi_logloss: 0.986723	validation's multi_logloss: 0.991835
[91]	training's multi_logloss: 0.986664	validation's multi_logloss: 0.991919
[92]	training's multi_logloss: 0.986664	validation's multi_logloss: 0.991919
[93]	training's multi_logloss: 0.986664	validation's multi_logloss: 0.991919
[94]	training's multi_logloss: 0.986664	validation's multi_logloss: 0.991919
[95]	training's multi_logloss: 0.986664	validation's multi_logloss: 0.991919
[96]	training's multi_logloss: 0.986664	validation's multi_logloss: 0.991919
[97]	training's multi_logloss: 0.986664	validation's multi_logloss: 0.991919
[98]	training's multi_logloss: 0.986664	validation's multi_logloss: 0.991919
[99]	training's multi_logloss: 0.986664	validation's multi_logloss: 0.991919
[100]	training's multi_logloss: 0.986552	validation's multi_logloss: 0.991745
Did not meet early stopping. Best iteration is:
[100]	training's multi_logloss: 0.986552	validation's multi_logloss: 0.991745
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04608	validation's multi_logloss: 1.04914
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03411	validation's multi_logloss: 1.04068
[3]	training's multi_logloss: 1.02542	validation's multi_logloss: 1.03479
[4]	training's multi_logloss: 1.01811	validation's multi_logloss: 1.02887
[5]	training's multi_logloss: 1.01203	validation's multi_logloss: 1.02454
[6]	training's multi_logloss: 1.00672	validation's multi_logloss: 1.02023
[7]	training's multi_logloss: 1.00251	validation's multi_logloss: 1.01807
[8]	training's multi_logloss: 0.999103	validation's multi_logloss: 1.01594
[9]	training's multi_logloss: 0.996267	validation's multi_logloss: 1.0148
[10]	training's multi_logloss: 0.994352	validation's multi_logloss: 1.01362
[11]	training's multi_logloss: 0.992356	validation's multi_logloss: 1.01283
[12]	training's multi_logloss: 0.990988	validation's multi_logloss: 1.01249
[13]	training's multi_logloss: 0.989633	validation's multi_logloss: 1.01205
[14]	training's multi_logloss: 0.988585	validation's multi_logloss: 1.01179
[15]	training's multi_logloss: 0.988083	validation's multi_logloss: 1.0115
[16]	training's multi_logloss: 0.987261	validation's multi_logloss: 1.01101
[17]	training's multi_logloss: 0.986731	validation's multi_logloss: 1.01099
[18]	training's multi_logloss: 0.985885	validation's multi_logloss: 1.0108
[19]	training's multi_logloss: 0.985432	validation's multi_logloss: 1.01059
[20]	training's multi_logloss: 0.984987	validation's multi_logloss: 1.01051
[21]	training's multi_logloss: 0.984286	validation's multi_logloss: 1.01013
[22]	training's multi_logloss: 0.984049	validation's multi_logloss: 1.01011
[23]	training's multi_logloss: 0.98367	validation's multi_logloss: 1.00988
[24]	training's multi_logloss: 0.983299	validation's multi_logloss: 1.00977
[25]	training's multi_logloss: 0.983112	validation's multi_logloss: 1.00975
[26]	training's multi_logloss: 0.982683	validation's multi_logloss: 1.01003
[27]	training's multi_logloss: 0.982587	validation's multi_logloss: 1.01006
[28]	training's multi_logloss: 0.982444	validation's multi_logloss: 1.00998
[29]	training's multi_logloss: 0.982026	validation's multi_logloss: 1.01031
[30]	training's multi_logloss: 0.982026	validation's multi_logloss: 1.01031
[31]	training's multi_logloss: 0.98187	validation's multi_logloss: 1.01038
[32]	training's multi_logloss: 0.98187	validation's multi_logloss: 1.01038
[33]	training's multi_logloss: 0.98187	validation's multi_logloss: 1.01038
[34]	training's multi_logloss: 0.98187	validation's multi_logloss: 1.01038
[35]	training's multi_logloss: 0.98175	validation's multi_logloss: 1.01024
[36]	training's multi_logloss: 0.98175	validation's multi_logloss: 1.01024
[37]	training's multi_logloss: 0.981503	validation's multi_logloss: 1.01018
[38]	training's multi_logloss: 0.981394	validation's multi_logloss: 1.01018
[39]	training's multi_logloss: 0.981075	validation's multi_logloss: 1.01039
[40]	training's multi_logloss: 0.981075	validation's multi_logloss: 1.01039
[41]	training's multi_logloss: 0.981075	validation's multi_logloss: 1.01039
[42]	training's multi_logloss: 0.980971	validation's multi_logloss: 1.01049
[43]	training's multi_logloss: 0.980971	validation's multi_logloss: 1.01049
[44]	training's multi_logloss: 0.980971	validation's multi_logloss: 1.01049
[45]	training's multi_logloss: 0.980971	validation's multi_logloss: 1.01049
Early stopping, best iteration is:
[25]	training's multi_logloss: 0.983112	validation's multi_logloss: 1.00975
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04547	validation's multi_logloss: 1.04743
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03444	validation's multi_logloss: 1.03853
[3]	training's multi_logloss: 1.02502	validation's multi_logloss: 1.03017
[4]	training's multi_logloss: 1.01828	validation's multi_logloss: 1.0241
[5]	training's multi_logloss: 1.01254	validation's multi_logloss: 1.01948
[6]	training's multi_logloss: 1.00799	validation's multi_logloss: 1.01555
[7]	training's multi_logloss: 1.00466	validation's multi_logloss: 1.01299
[8]	training's multi_logloss: 1.00186	validation's multi_logloss: 1.0108
[9]	training's multi_logloss: 0.99908	validation's multi_logloss: 1.00791
[10]	training's multi_logloss: 0.996882	validation's multi_logloss: 1.0067
[11]	training's multi_logloss: 0.995014	validation's multi_logloss: 1.00599
[12]	training's multi_logloss: 0.993609	validation's multi_logloss: 1.00518
[13]	training's multi_logloss: 0.992301	validation's multi_logloss: 1.00442
[14]	training's multi_logloss: 0.991552	validation's multi_logloss: 1.00415
[15]	training's multi_logloss: 0.991088	validation's multi_logloss: 1.00414
[16]	training's multi_logloss: 0.990109	validation's multi_logloss: 1.00337
[17]	training's multi_logloss: 0.989531	validation's multi_logloss: 1.00322
[18]	training's multi_logloss: 0.989028	validation's multi_logloss: 1.00255
[19]	training's multi_logloss: 0.988466	validation's multi_logloss: 1.00212
[20]	training's multi_logloss: 0.988311	validation's multi_logloss: 1.00214
[21]	training's multi_logloss: 0.987883	validation's multi_logloss: 1.00195
[22]	training's multi_logloss: 0.987337	validation's multi_logloss: 1.00179
[23]	training's multi_logloss: 0.986979	validation's multi_logloss: 1.00163
[24]	training's multi_logloss: 0.986822	validation's multi_logloss: 1.0015
[25]	training's multi_logloss: 0.986822	validation's multi_logloss: 1.0015
[26]	training's multi_logloss: 0.986517	validation's multi_logloss: 1.00123
[27]	training's multi_logloss: 0.986346	validation's multi_logloss: 1.00124
[28]	training's multi_logloss: 0.986218	validation's multi_logloss: 1.00134
[29]	training's multi_logloss: 0.986071	validation's multi_logloss: 1.0013
[30]	training's multi_logloss: 0.985916	validation's multi_logloss: 1.00124
[31]	training's multi_logloss: 0.985601	validation's multi_logloss: 1.0013
[32]	training's multi_logloss: 0.985183	validation's multi_logloss: 1.00129
[33]	training's multi_logloss: 0.985183	validation's multi_logloss: 1.00129
[34]	training's multi_logloss: 0.985183	validation's multi_logloss: 1.00129
[35]	training's multi_logloss: 0.985183	validation's multi_logloss: 1.00129
[36]	training's multi_logloss: 0.985003	validation's multi_logloss: 1.00148
[37]	training's multi_logloss: 0.984875	validation's multi_logloss: 1.00164
[38]	training's multi_logloss: 0.984875	validation's multi_logloss: 1.00164
[39]	training's multi_logloss: 0.984759	validation's multi_logloss: 1.00166
[40]	training's multi_logloss: 0.984653	validation's multi_logloss: 1.00168
[41]	training's multi_logloss: 0.984531	validation's multi_logloss: 1.00176
[42]	training's multi_logloss: 0.984531	validation's multi_logloss: 1.00176
[43]	training's multi_logloss: 0.984531	validation's multi_logloss: 1.00176
[44]	training's multi_logloss: 0.984531	validation's multi_logloss: 1.00176
[45]	training's multi_logloss: 0.984382	validation's multi_logloss: 1.00168
[46]	training's multi_logloss: 0.984122	validation's multi_logloss: 1.00163
Early stopping, best iteration is:
[26]	training's multi_logloss: 0.986517	validation's multi_logloss: 1.00123
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=6.2914595938880895, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.2914595938880895
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.04413	validation's multi_logloss: 1.04035
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.03212	validation's multi_logloss: 1.02876
[3]	training's multi_logloss: 1.0228	validation's multi_logloss: 1.02062
[4]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.01534
[5]	training's multi_logloss: 1.01153	validation's multi_logloss: 1.01118
[6]	training's multi_logloss: 1.00693	validation's multi_logloss: 1.00761
[7]	training's multi_logloss: 1.00361	validation's multi_logloss: 1.00527
[8]	training's multi_logloss: 1.00095	validation's multi_logloss: 1.0026
[9]	training's multi_logloss: 0.998629	validation's multi_logloss: 1.00011
[10]	training's multi_logloss: 0.996623	validation's multi_logloss: 0.998477
[11]	training's multi_logloss: 0.994429	validation's multi_logloss: 0.996146
[12]	training's multi_logloss: 0.993216	validation's multi_logloss: 0.995282
[13]	training's multi_logloss: 0.992184	validation's multi_logloss: 0.994709
[14]	training's multi_logloss: 0.990964	validation's multi_logloss: 0.99413
[15]	training's multi_logloss: 0.990017	validation's multi_logloss: 0.9936
[16]	training's multi_logloss: 0.98948	validation's multi_logloss: 0.992884
[17]	training's multi_logloss: 0.988851	validation's multi_logloss: 0.992408
[18]	training's multi_logloss: 0.988404	validation's multi_logloss: 0.992142
[19]	training's multi_logloss: 0.987831	validation's multi_logloss: 0.991688
[20]	training's multi_logloss: 0.987425	validation's multi_logloss: 0.991527
[21]	training's multi_logloss: 0.986934	validation's multi_logloss: 0.991315
[22]	training's multi_logloss: 0.986742	validation's multi_logloss: 0.991104
[23]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[24]	training's multi_logloss: 0.986643	validation's multi_logloss: 0.9911
[25]	training's multi_logloss: 0.986481	validation's multi_logloss: 0.990898
[26]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[27]	training's multi_logloss: 0.98626	validation's multi_logloss: 0.990918
[28]	training's multi_logloss: 0.986094	validation's multi_logloss: 0.991035
[29]	training's multi_logloss: 0.98588	validation's multi_logloss: 0.990818
[30]	training's multi_logloss: 0.985772	validation's multi_logloss: 0.990726
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
[32]	training's multi_logloss: 0.98537	validation's multi_logloss: 0.990776
[33]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[34]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[35]	training's multi_logloss: 0.985293	validation's multi_logloss: 0.990715
[36]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[37]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[38]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[39]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[40]	training's multi_logloss: 0.985249	validation's multi_logloss: 0.990821
[41]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[42]	training's multi_logloss: 0.985163	validation's multi_logloss: 0.990923
[43]	training's multi_logloss: 0.984972	validation's multi_logloss: 0.990947
[44]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[45]	training's multi_logloss: 0.984874	validation's multi_logloss: 0.990962
[46]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[47]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[48]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[49]	training's multi_logloss: 0.984734	validation's multi_logloss: 0.990935
[50]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
[51]	training's multi_logloss: 0.984629	validation's multi_logloss: 0.990852
Early stopping, best iteration is:
[31]	training's multi_logloss: 0.985578	validation's multi_logloss: 0.990595
(80,)
0.990715489414942 0.52567
2376
['side_avg_15D_home' 'Scored_15D_home' 'Received_15D_home'
 'points_15D_home' 'Shots_15D_home' 'Target_15D_home' 'Corner_15D_home'
 'Faults_15D_home' 'YellowCards_15D_home' 'RedCards_15D_home'
 'side_avg_15D_away' 'Scored_15D_away' 'Received_15D_away'
 'points_15D_away' 'Shots_15D_away' 'Target_15D_away' 'Corner_15D_away'
 'Faults_15D_away' 'YellowCards_15D_away' 'RedCards_15D_away'
 'side_avg_30D_home' 'Scored_30D_home' 'Received_30D_home'
 'points_30D_home' 'Shots_30D_home' 'Target_30D_home' 'Corner_30D_home'
 'Faults_30D_home' 'YellowCards_30D_home' 'RedCards_30D_home'
 'side_avg_30D_away' 'Scored_30D_away' 'Received_30D_away'
 'points_30D_away' 'Shots_30D_away' 'Target_30D_away' 'Corner_30D_away'
 'Faults_30D_away' 'YellowCards_30D_away' 'RedCards_30D_away'
 'side_avg_60D_home' 'Scored_60D_home' 'Received_60D_home'
 'points_60D_home' 'Shots_60D_home' 'Target_60D_home' 'Corner_60D_home'
 'Faults_60D_home' 'YellowCards_60D_home' 'RedCards_60D_home'
 'side_avg_60D_away' 'Scored_60D_away' 'Received_60D_away'
 'points_60D_away' 'Shots_60D_away' 'Target_60D_away' 'Corner_60D_away'
 'Faults_60D_away' 'YellowCards_60D_away' 'RedCards_60D_away'
 'side_avg_180D_home' 'Scored_180D_home' 'Received_180D_home'
 'points_180D_home' 'Shots_180D_home' 'Target_180D_home'
 'Corner_180D_home' 'Faults_180D_home' 'YellowCards_180D_home'
 'RedCards_180D_home' 'side_avg_180D_away' 'Scored_180D_away'
 'Received_180D_away' 'points_180D_away' 'Shots_180D_away'
 'Target_180D_away' 'Corner_180D_away' 'Faults_180D_away'
 'YellowCards_180D_away' 'RedCards_180D_away' 'side_avg_365D_home'
 'Scored_365D_home' 'Received_365D_home' 'points_365D_home'
 'Shots_365D_home' 'Target_365D_home' 'Corner_365D_home'
 'Faults_365D_home' 'YellowCards_365D_home' 'RedCards_365D_home'
 'side_avg_365D_away' 'Scored_365D_away' 'Received_365D_away'
 'points_365D_away' 'Shots_365D_away' 'Target_365D_away'
 'Corner_365D_away' 'Faults_365D_away' 'YellowCards_365D_away'
 'RedCards_365D_away' 'side_avg_730D_home' 'Scored_730D_home'
 'Received_730D_home' 'points_730D_home' 'Shots_730D_home'
 'Target_730D_home' 'Corner_730D_home' 'Faults_730D_home'
 'YellowCards_730D_home' 'RedCards_730D_home' 'side_avg_730D_away'
 'Scored_730D_away' 'Received_730D_away' 'points_730D_away'
 'Shots_730D_away' 'Target_730D_away' 'Corner_730D_away'
 'Faults_730D_away' 'YellowCards_730D_away' 'RedCards_730D_away'
 'side_avg_1825D_home' 'Scored_1825D_home' 'Received_1825D_home'
 'points_1825D_home' 'Shots_1825D_home' 'Target_1825D_home'
 'Corner_1825D_home' 'Faults_1825D_home' 'YellowCards_1825D_home'
 'RedCards_1825D_home' 'side_avg_1825D_away' 'Scored_1825D_away'
 'Received_1825D_away' 'points_1825D_away' 'Shots_1825D_away'
 'Target_1825D_away' 'Corner_1825D_away' 'Faults_1825D_away'
 'YellowCards_1825D_away' 'RedCards_1825D_away']
Index(['side_avg_15D_home', 'Scored_15D_home', 'Received_15D_home',
       'points_15D_home', 'Shots_15D_home', 'Target_15D_home',
       'Corner_15D_home', 'Faults_15D_home', 'YellowCards_15D_home',
       'RedCards_15D_home',
       ...
       'side_avg_1825D_away', 'Scored_1825D_away', 'Received_1825D_away',
       'points_1825D_away', 'Shots_1825D_away', 'Target_1825D_away',
       'Corner_1825D_away', 'Faults_1825D_away', 'YellowCards_1825D_away',
       'RedCards_1825D_away'],
      dtype='object', length=140)
(13901, 140)
Index(['side_avg_15D_home', 'Scored_15D_home', 'Received_15D_home',
       'points_15D_home', 'Shots_15D_home', 'Target_15D_home',
       'Corner_15D_home', 'Faults_15D_home', 'YellowCards_15D_home',
       'RedCards_15D_home',
       ...
       'side_avg_1825D_away', 'Scored_1825D_away', 'Received_1825D_away',
       'points_1825D_away', 'Shots_1825D_away', 'Target_1825D_away',
       'Corner_1825D_away', 'Faults_1825D_away', 'YellowCards_1825D_away',
       'RedCards_1825D_away'],
      dtype='object', length=140)
(3472, 140)
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300
[LightGBM] [Warning] min_gain_to_split is set=10.415143331823046, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.415143331823046
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.1837	validation's multi_logloss: 1.18397
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.11826	validation's multi_logloss: 1.11906
[3]	training's multi_logloss: 1.10505	validation's multi_logloss: 1.10569
[4]	training's multi_logloss: 1.07172	validation's multi_logloss: 1.0732
[5]	training's multi_logloss: 1.06378	validation's multi_logloss: 1.06554
[6]	training's multi_logloss: 1.05663	validation's multi_logloss: 1.05834
[7]	training's multi_logloss: 1.05013	validation's multi_logloss: 1.05225
[8]	training's multi_logloss: 1.04458	validation's multi_logloss: 1.04693
[9]	training's multi_logloss: 1.03992	validation's multi_logloss: 1.04232
[10]	training's multi_logloss: 1.03525	validation's multi_logloss: 1.03794
[11]	training's multi_logloss: 1.03089	validation's multi_logloss: 1.03397
[12]	training's multi_logloss: 1.02745	validation's multi_logloss: 1.03081
[13]	training's multi_logloss: 1.02428	validation's multi_logloss: 1.02765
[14]	training's multi_logloss: 1.02123	validation's multi_logloss: 1.02441
[15]	training's multi_logloss: 1.01839	validation's multi_logloss: 1.02168
[16]	training's multi_logloss: 1.01576	validation's multi_logloss: 1.01912
[17]	training's multi_logloss: 1.0133	validation's multi_logloss: 1.01655
[18]	training's multi_logloss: 1.01115	validation's multi_logloss: 1.01437
[19]	training's multi_logloss: 1.00919	validation's multi_logloss: 1.01249
[20]	training's multi_logloss: 1.0073	validation's multi_logloss: 1.01068
[21]	training's multi_logloss: 1.00557	validation's multi_logloss: 1.00903
[22]	training's multi_logloss: 1.0048	validation's multi_logloss: 1.00827
[23]	training's multi_logloss: 1.00316	validation's multi_logloss: 1.00691
[24]	training's multi_logloss: 1.00316	validation's multi_logloss: 1.00691
[25]	training's multi_logloss: 1.00256	validation's multi_logloss: 1.00624
[26]	training's multi_logloss: 1.00256	validation's multi_logloss: 1.00624
[27]	training's multi_logloss: 1.00256	validation's multi_logloss: 1.00624
[28]	training's multi_logloss: 1.00256	validation's multi_logloss: 1.00624
[29]	training's multi_logloss: 1.00256	validation's multi_logloss: 1.00624
[30]	training's multi_logloss: 1.00169	validation's multi_logloss: 1.00531
[31]	training's multi_logloss: 1.00169	validation's multi_logloss: 1.00531
[32]	training's multi_logloss: 1.00169	validation's multi_logloss: 1.00531
[33]	training's multi_logloss: 1.00169	validation's multi_logloss: 1.00531
[34]	training's multi_logloss: 1.00169	validation's multi_logloss: 1.00531
[35]	training's multi_logloss: 1.00096	validation's multi_logloss: 1.00481
[36]	training's multi_logloss: 1.00096	validation's multi_logloss: 1.00481
[37]	training's multi_logloss: 1.00096	validation's multi_logloss: 1.00481
[38]	training's multi_logloss: 1.00096	validation's multi_logloss: 1.00481
[39]	training's multi_logloss: 1.00022	validation's multi_logloss: 1.00401
[40]	training's multi_logloss: 1.00022	validation's multi_logloss: 1.00401
[41]	training's multi_logloss: 1.00022	validation's multi_logloss: 1.00401
[42]	training's multi_logloss: 1.00022	validation's multi_logloss: 1.00401
[43]	training's multi_logloss: 0.998965	validation's multi_logloss: 1.00262
[44]	training's multi_logloss: 0.99838	validation's multi_logloss: 1.00222
[45]	training's multi_logloss: 0.99838	validation's multi_logloss: 1.00222
[46]	training's multi_logloss: 0.99838	validation's multi_logloss: 1.00222
[47]	training's multi_logloss: 0.99838	validation's multi_logloss: 1.00222
[48]	training's multi_logloss: 0.99838	validation's multi_logloss: 1.00222
[49]	training's multi_logloss: 0.99838	validation's multi_logloss: 1.00222
[50]	training's multi_logloss: 0.99838	validation's multi_logloss: 1.00222
[51]	training's multi_logloss: 0.99838	validation's multi_logloss: 1.00222
[52]	training's multi_logloss: 0.99838	validation's multi_logloss: 1.00222
[53]	training's multi_logloss: 0.99838	validation's multi_logloss: 1.00222
[54]	training's multi_logloss: 0.99838	validation's multi_logloss: 1.00222
[55]	training's multi_logloss: 0.99838	validation's multi_logloss: 1.00222
[56]	training's multi_logloss: 0.99838	validation's multi_logloss: 1.00222
[57]	training's multi_logloss: 0.99838	validation's multi_logloss: 1.00222
[58]	training's multi_logloss: 0.99838	validation's multi_logloss: 1.00222
[59]	training's multi_logloss: 0.99838	validation's multi_logloss: 1.00222
[60]	training's multi_logloss: 0.99838	validation's multi_logloss: 1.00222
[61]	training's multi_logloss: 0.99838	validation's multi_logloss: 1.00222
[62]	training's multi_logloss: 0.99838	validation's multi_logloss: 1.00222
[63]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[64]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[65]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[66]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[67]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[68]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[69]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[70]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[71]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[72]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[73]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[74]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[75]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[76]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[77]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[78]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[79]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[80]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[81]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[82]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[83]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
Early stopping, best iteration is:
[63]	training's multi_logloss: 0.997647	validation's multi_logloss: 1.00149
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300
[LightGBM] [Warning] min_gain_to_split is set=10.415143331823046, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.415143331823046
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18487	validation's multi_logloss: 1.18352
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.11763	validation's multi_logloss: 1.11586
[3]	training's multi_logloss: 1.07896	validation's multi_logloss: 1.07607
[4]	training's multi_logloss: 1.06947	validation's multi_logloss: 1.06667
[5]	training's multi_logloss: 1.0619	validation's multi_logloss: 1.05889
[6]	training's multi_logloss: 1.05605	validation's multi_logloss: 1.05272
[7]	training's multi_logloss: 1.04945	validation's multi_logloss: 1.04594
[8]	training's multi_logloss: 1.04406	validation's multi_logloss: 1.04057
[9]	training's multi_logloss: 1.03925	validation's multi_logloss: 1.03586
[10]	training's multi_logloss: 1.03533	validation's multi_logloss: 1.03155
[11]	training's multi_logloss: 1.03156	validation's multi_logloss: 1.02745
[12]	training's multi_logloss: 1.02801	validation's multi_logloss: 1.02378
[13]	training's multi_logloss: 1.02483	validation's multi_logloss: 1.0205
[14]	training's multi_logloss: 1.02205	validation's multi_logloss: 1.01727
[15]	training's multi_logloss: 1.01935	validation's multi_logloss: 1.01432
[16]	training's multi_logloss: 1.01699	validation's multi_logloss: 1.01186
[17]	training's multi_logloss: 1.01477	validation's multi_logloss: 1.00944
[18]	training's multi_logloss: 1.01262	validation's multi_logloss: 1.00707
[19]	training's multi_logloss: 1.01046	validation's multi_logloss: 1.00489
[20]	training's multi_logloss: 1.00956	validation's multi_logloss: 1.00403
[21]	training's multi_logloss: 1.00865	validation's multi_logloss: 1.00301
[22]	training's multi_logloss: 1.00697	validation's multi_logloss: 1.00127
[23]	training's multi_logloss: 1.00697	validation's multi_logloss: 1.00127
[24]	training's multi_logloss: 1.00697	validation's multi_logloss: 1.00127
[25]	training's multi_logloss: 1.00697	validation's multi_logloss: 1.00127
[26]	training's multi_logloss: 1.00614	validation's multi_logloss: 1.00059
[27]	training's multi_logloss: 1.00614	validation's multi_logloss: 1.00059
[28]	training's multi_logloss: 1.00526	validation's multi_logloss: 0.99972
[29]	training's multi_logloss: 1.00451	validation's multi_logloss: 0.998964
[30]	training's multi_logloss: 1.00381	validation's multi_logloss: 0.998132
[31]	training's multi_logloss: 1.00313	validation's multi_logloss: 0.997336
[32]	training's multi_logloss: 1.00313	validation's multi_logloss: 0.997336
[33]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[34]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[35]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[36]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[37]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[38]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[39]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[40]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[41]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[42]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[43]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[44]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[45]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[46]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[47]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[48]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[49]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[50]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[51]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[52]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[53]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
Early stopping, best iteration is:
[33]	training's multi_logloss: 1.00238	validation's multi_logloss: 0.99662
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300
[LightGBM] [Warning] min_gain_to_split is set=10.415143331823046, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.415143331823046
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18288	validation's multi_logloss: 1.18492
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.11535	validation's multi_logloss: 1.12085
[3]	training's multi_logloss: 1.10278	validation's multi_logloss: 1.10924
[4]	training's multi_logloss: 1.09158	validation's multi_logloss: 1.09914
[5]	training's multi_logloss: 1.08223	validation's multi_logloss: 1.09076
[6]	training's multi_logloss: 1.07383	validation's multi_logloss: 1.08352
[7]	training's multi_logloss: 1.0659	validation's multi_logloss: 1.07658
[8]	training's multi_logloss: 1.05892	validation's multi_logloss: 1.07069
[9]	training's multi_logloss: 1.05226	validation's multi_logloss: 1.06471
[10]	training's multi_logloss: 1.04643	validation's multi_logloss: 1.05922
[11]	training's multi_logloss: 1.04059	validation's multi_logloss: 1.05416
[12]	training's multi_logloss: 1.03575	validation's multi_logloss: 1.04973
[13]	training's multi_logloss: 1.03166	validation's multi_logloss: 1.04615
[14]	training's multi_logloss: 1.02776	validation's multi_logloss: 1.04245
[15]	training's multi_logloss: 1.02401	validation's multi_logloss: 1.03882
[16]	training's multi_logloss: 1.02052	validation's multi_logloss: 1.03537
[17]	training's multi_logloss: 1.0172	validation's multi_logloss: 1.03261
[18]	training's multi_logloss: 1.01383	validation's multi_logloss: 1.02953
[19]	training's multi_logloss: 1.0113	validation's multi_logloss: 1.02713
[20]	training's multi_logloss: 1.00866	validation's multi_logloss: 1.02486
[21]	training's multi_logloss: 1.00866	validation's multi_logloss: 1.02486
[22]	training's multi_logloss: 1.00763	validation's multi_logloss: 1.02393
[23]	training's multi_logloss: 1.00763	validation's multi_logloss: 1.02393
[24]	training's multi_logloss: 1.00674	validation's multi_logloss: 1.02316
[25]	training's multi_logloss: 1.00674	validation's multi_logloss: 1.02316
[26]	training's multi_logloss: 1.00547	validation's multi_logloss: 1.02209
[27]	training's multi_logloss: 1.00547	validation's multi_logloss: 1.02209
[28]	training's multi_logloss: 1.00434	validation's multi_logloss: 1.02117
[29]	training's multi_logloss: 1.00345	validation's multi_logloss: 1.02036
[30]	training's multi_logloss: 1.00267	validation's multi_logloss: 1.01956
[31]	training's multi_logloss: 1.00267	validation's multi_logloss: 1.01956
[32]	training's multi_logloss: 1.0014	validation's multi_logloss: 1.01842
[33]	training's multi_logloss: 1.00045	validation's multi_logloss: 1.01755
[34]	training's multi_logloss: 0.999554	validation's multi_logloss: 1.01662
[35]	training's multi_logloss: 0.999554	validation's multi_logloss: 1.01662
[36]	training's multi_logloss: 0.999554	validation's multi_logloss: 1.01662
[37]	training's multi_logloss: 0.999554	validation's multi_logloss: 1.01662
[38]	training's multi_logloss: 0.999554	validation's multi_logloss: 1.01662
[39]	training's multi_logloss: 0.999554	validation's multi_logloss: 1.01662
[40]	training's multi_logloss: 0.999554	validation's multi_logloss: 1.01662
[41]	training's multi_logloss: 0.999554	validation's multi_logloss: 1.01662
[42]	training's multi_logloss: 0.999554	validation's multi_logloss: 1.01662
[43]	training's multi_logloss: 0.999554	validation's multi_logloss: 1.01662
[44]	training's multi_logloss: 0.999554	validation's multi_logloss: 1.01662
[45]	training's multi_logloss: 0.999554	validation's multi_logloss: 1.01662
[46]	training's multi_logloss: 0.999554	validation's multi_logloss: 1.01662
[47]	training's multi_logloss: 0.999554	validation's multi_logloss: 1.01662
[48]	training's multi_logloss: 0.999554	validation's multi_logloss: 1.01662
[49]	training's multi_logloss: 0.999554	validation's multi_logloss: 1.01662
[50]	training's multi_logloss: 0.999554	validation's multi_logloss: 1.01662
[51]	training's multi_logloss: 0.999554	validation's multi_logloss: 1.01662
[52]	training's multi_logloss: 0.999554	validation's multi_logloss: 1.01662
[53]	training's multi_logloss: 0.99861	validation's multi_logloss: 1.01584
[54]	training's multi_logloss: 0.99861	validation's multi_logloss: 1.01584
[55]	training's multi_logloss: 0.99861	validation's multi_logloss: 1.01584
[56]	training's multi_logloss: 0.99861	validation's multi_logloss: 1.01584
[57]	training's multi_logloss: 0.99861	validation's multi_logloss: 1.01584
[58]	training's multi_logloss: 0.99861	validation's multi_logloss: 1.01584
[59]	training's multi_logloss: 0.99861	validation's multi_logloss: 1.01584
[60]	training's multi_logloss: 0.99861	validation's multi_logloss: 1.01584
[61]	training's multi_logloss: 0.99861	validation's multi_logloss: 1.01584
[62]	training's multi_logloss: 0.99861	validation's multi_logloss: 1.01584
[63]	training's multi_logloss: 0.997796	validation's multi_logloss: 1.01504
[64]	training's multi_logloss: 0.997796	validation's multi_logloss: 1.01504
[65]	training's multi_logloss: 0.997796	validation's multi_logloss: 1.01504
[66]	training's multi_logloss: 0.997796	validation's multi_logloss: 1.01504
[67]	training's multi_logloss: 0.997796	validation's multi_logloss: 1.01504
[68]	training's multi_logloss: 0.997796	validation's multi_logloss: 1.01504
[69]	training's multi_logloss: 0.997796	validation's multi_logloss: 1.01504
[70]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[71]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[72]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[73]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[74]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[75]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[76]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[77]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[78]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[79]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[80]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[81]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[82]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[83]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[84]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[85]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[86]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[87]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[88]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[89]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[90]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
Early stopping, best iteration is:
[70]	training's multi_logloss: 0.996898	validation's multi_logloss: 1.01427
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300
[LightGBM] [Warning] min_gain_to_split is set=10.415143331823046, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.415143331823046
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18313	validation's multi_logloss: 1.18457
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.16595	validation's multi_logloss: 1.16843
[3]	training's multi_logloss: 1.10815	validation's multi_logloss: 1.11198
[4]	training's multi_logloss: 1.09728	validation's multi_logloss: 1.10166
[5]	training's multi_logloss: 1.08736	validation's multi_logloss: 1.09262
[6]	training's multi_logloss: 1.05787	validation's multi_logloss: 1.06454
[7]	training's multi_logloss: 1.05121	validation's multi_logloss: 1.05813
[8]	training's multi_logloss: 1.04478	validation's multi_logloss: 1.05237
[9]	training's multi_logloss: 1.03925	validation's multi_logloss: 1.04778
[10]	training's multi_logloss: 1.03464	validation's multi_logloss: 1.04347
[11]	training's multi_logloss: 1.03016	validation's multi_logloss: 1.03987
[12]	training's multi_logloss: 1.02618	validation's multi_logloss: 1.03597
[13]	training's multi_logloss: 1.02285	validation's multi_logloss: 1.03278
[14]	training's multi_logloss: 1.01949	validation's multi_logloss: 1.02976
[15]	training's multi_logloss: 1.01671	validation's multi_logloss: 1.02752
[16]	training's multi_logloss: 1.01386	validation's multi_logloss: 1.02471
[17]	training's multi_logloss: 1.01131	validation's multi_logloss: 1.02234
[18]	training's multi_logloss: 1.00895	validation's multi_logloss: 1.02053
[19]	training's multi_logloss: 1.00688	validation's multi_logloss: 1.01864
[20]	training's multi_logloss: 1.0049	validation's multi_logloss: 1.01695
[21]	training's multi_logloss: 1.00398	validation's multi_logloss: 1.0162
[22]	training's multi_logloss: 1.00318	validation's multi_logloss: 1.01566
[23]	training's multi_logloss: 1.00219	validation's multi_logloss: 1.0147
[24]	training's multi_logloss: 1.00148	validation's multi_logloss: 1.01394
[25]	training's multi_logloss: 0.999646	validation's multi_logloss: 1.01235
[26]	training's multi_logloss: 0.998857	validation's multi_logloss: 1.01161
[27]	training's multi_logloss: 0.998857	validation's multi_logloss: 1.01161
[28]	training's multi_logloss: 0.998052	validation's multi_logloss: 1.01086
[29]	training's multi_logloss: 0.998052	validation's multi_logloss: 1.01086
[30]	training's multi_logloss: 0.997269	validation's multi_logloss: 1.01018
[31]	training's multi_logloss: 0.997269	validation's multi_logloss: 1.01018
[32]	training's multi_logloss: 0.996627	validation's multi_logloss: 1.00968
[33]	training's multi_logloss: 0.996627	validation's multi_logloss: 1.00968
[34]	training's multi_logloss: 0.996627	validation's multi_logloss: 1.00968
[35]	training's multi_logloss: 0.996627	validation's multi_logloss: 1.00968
[36]	training's multi_logloss: 0.996627	validation's multi_logloss: 1.00968
[37]	training's multi_logloss: 0.996627	validation's multi_logloss: 1.00968
[38]	training's multi_logloss: 0.996627	validation's multi_logloss: 1.00968
[39]	training's multi_logloss: 0.996627	validation's multi_logloss: 1.00968
[40]	training's multi_logloss: 0.996627	validation's multi_logloss: 1.00968
[41]	training's multi_logloss: 0.995922	validation's multi_logloss: 1.00913
[42]	training's multi_logloss: 0.995922	validation's multi_logloss: 1.00913
[43]	training's multi_logloss: 0.995922	validation's multi_logloss: 1.00913
[44]	training's multi_logloss: 0.995922	validation's multi_logloss: 1.00913
[45]	training's multi_logloss: 0.995922	validation's multi_logloss: 1.00913
[46]	training's multi_logloss: 0.995922	validation's multi_logloss: 1.00913
[47]	training's multi_logloss: 0.995922	validation's multi_logloss: 1.00913
[48]	training's multi_logloss: 0.995922	validation's multi_logloss: 1.00913
[49]	training's multi_logloss: 0.995273	validation's multi_logloss: 1.00858
[50]	training's multi_logloss: 0.995273	validation's multi_logloss: 1.00858
[51]	training's multi_logloss: 0.995273	validation's multi_logloss: 1.00858
[52]	training's multi_logloss: 0.995273	validation's multi_logloss: 1.00858
[53]	training's multi_logloss: 0.995273	validation's multi_logloss: 1.00858
[54]	training's multi_logloss: 0.995273	validation's multi_logloss: 1.00858
[55]	training's multi_logloss: 0.995273	validation's multi_logloss: 1.00858
[56]	training's multi_logloss: 0.995273	validation's multi_logloss: 1.00858
[57]	training's multi_logloss: 0.995273	validation's multi_logloss: 1.00858
[58]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[59]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[60]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[61]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[62]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[63]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[64]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[65]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[66]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[67]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[68]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[69]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[70]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[71]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[72]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[73]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[74]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[75]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[76]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[77]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[78]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
Early stopping, best iteration is:
[58]	training's multi_logloss: 0.994556	validation's multi_logloss: 1.00806
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600
[LightGBM] [Warning] min_gain_to_split is set=3.835501021354826, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.835501021354826
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600
[LightGBM] [Warning] min_gain_to_split is set=3.835501021354826, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.835501021354826
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600
[LightGBM] [Warning] min_gain_to_split is set=3.835501021354826, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.835501021354826
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=9600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9600
[LightGBM] [Warning] min_gain_to_split is set=3.835501021354826, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.835501021354826
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=1.8603616527504934, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.8603616527504934
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=1.8603616527504934, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.8603616527504934
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=1.8603616527504934, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.8603616527504934
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=1.8603616527504934, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.8603616527504934
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.19516	validation's multi_logloss: 1.19536
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.18914	validation's multi_logloss: 1.18935
[3]	training's multi_logloss: 1.18331	validation's multi_logloss: 1.18352
[4]	training's multi_logloss: 1.17791	validation's multi_logloss: 1.17804
[5]	training's multi_logloss: 1.1727	validation's multi_logloss: 1.17279
[6]	training's multi_logloss: 1.16772	validation's multi_logloss: 1.16778
[7]	training's multi_logloss: 1.16285	validation's multi_logloss: 1.16286
[8]	training's multi_logloss: 1.15819	validation's multi_logloss: 1.15816
[9]	training's multi_logloss: 1.15387	validation's multi_logloss: 1.1537
[10]	training's multi_logloss: 1.14951	validation's multi_logloss: 1.14933
[11]	training's multi_logloss: 1.14542	validation's multi_logloss: 1.14521
[12]	training's multi_logloss: 1.14144	validation's multi_logloss: 1.14124
[13]	training's multi_logloss: 1.13764	validation's multi_logloss: 1.13739
[14]	training's multi_logloss: 1.13396	validation's multi_logloss: 1.13369
[15]	training's multi_logloss: 1.13032	validation's multi_logloss: 1.13005
[16]	training's multi_logloss: 1.12684	validation's multi_logloss: 1.12651
[17]	training's multi_logloss: 1.12346	validation's multi_logloss: 1.1231
[18]	training's multi_logloss: 1.12022	validation's multi_logloss: 1.11981
[19]	training's multi_logloss: 1.11706	validation's multi_logloss: 1.11672
[20]	training's multi_logloss: 1.114	validation's multi_logloss: 1.11371
[21]	training's multi_logloss: 1.11099	validation's multi_logloss: 1.11065
[22]	training's multi_logloss: 1.10809	validation's multi_logloss: 1.10782
[23]	training's multi_logloss: 1.10521	validation's multi_logloss: 1.105
[24]	training's multi_logloss: 1.10259	validation's multi_logloss: 1.10225
[25]	training's multi_logloss: 1.09987	validation's multi_logloss: 1.09956
[26]	training's multi_logloss: 1.09726	validation's multi_logloss: 1.097
[27]	training's multi_logloss: 1.09473	validation's multi_logloss: 1.09451
[28]	training's multi_logloss: 1.09228	validation's multi_logloss: 1.09203
[29]	training's multi_logloss: 1.08985	validation's multi_logloss: 1.08958
[30]	training's multi_logloss: 1.08749	validation's multi_logloss: 1.08743
[31]	training's multi_logloss: 1.08527	validation's multi_logloss: 1.08525
[32]	training's multi_logloss: 1.08302	validation's multi_logloss: 1.08302
[33]	training's multi_logloss: 1.08081	validation's multi_logloss: 1.08094
[34]	training's multi_logloss: 1.07866	validation's multi_logloss: 1.07885
[35]	training's multi_logloss: 1.07661	validation's multi_logloss: 1.07687
[36]	training's multi_logloss: 1.07461	validation's multi_logloss: 1.07489
[37]	training's multi_logloss: 1.07258	validation's multi_logloss: 1.07294
[38]	training's multi_logloss: 1.07071	validation's multi_logloss: 1.07101
[39]	training's multi_logloss: 1.06883	validation's multi_logloss: 1.06919
[40]	training's multi_logloss: 1.06698	validation's multi_logloss: 1.06744
[41]	training's multi_logloss: 1.06522	validation's multi_logloss: 1.06571
[42]	training's multi_logloss: 1.0635	validation's multi_logloss: 1.06389
[43]	training's multi_logloss: 1.06176	validation's multi_logloss: 1.06215
[44]	training's multi_logloss: 1.06008	validation's multi_logloss: 1.06062
[45]	training's multi_logloss: 1.05934	validation's multi_logloss: 1.05992
[46]	training's multi_logloss: 1.05776	validation's multi_logloss: 1.05839
[47]	training's multi_logloss: 1.05618	validation's multi_logloss: 1.05685
[48]	training's multi_logloss: 1.05549	validation's multi_logloss: 1.05629
[49]	training's multi_logloss: 1.054	validation's multi_logloss: 1.05477
[50]	training's multi_logloss: 1.05335	validation's multi_logloss: 1.05424
[51]	training's multi_logloss: 1.05275	validation's multi_logloss: 1.05363
[52]	training's multi_logloss: 1.05221	validation's multi_logloss: 1.05316
[53]	training's multi_logloss: 1.05168	validation's multi_logloss: 1.05262
[54]	training's multi_logloss: 1.05118	validation's multi_logloss: 1.0522
[55]	training's multi_logloss: 1.05071	validation's multi_logloss: 1.05181
[56]	training's multi_logloss: 1.05028	validation's multi_logloss: 1.05133
[57]	training's multi_logloss: 1.04986	validation's multi_logloss: 1.05101
[58]	training's multi_logloss: 1.04948	validation's multi_logloss: 1.0506
[59]	training's multi_logloss: 1.0491	validation's multi_logloss: 1.0503
[60]	training's multi_logloss: 1.04875	validation's multi_logloss: 1.04991
[61]	training's multi_logloss: 1.0484	validation's multi_logloss: 1.04957
[62]	training's multi_logloss: 1.04808	validation's multi_logloss: 1.04931
[63]	training's multi_logloss: 1.04808	validation's multi_logloss: 1.04931
[64]	training's multi_logloss: 1.04778	validation's multi_logloss: 1.04905
[65]	training's multi_logloss: 1.04778	validation's multi_logloss: 1.04905
[66]	training's multi_logloss: 1.04749	validation's multi_logloss: 1.04873
[67]	training's multi_logloss: 1.04721	validation's multi_logloss: 1.04852
[68]	training's multi_logloss: 1.04721	validation's multi_logloss: 1.04852
[69]	training's multi_logloss: 1.04695	validation's multi_logloss: 1.04824
[70]	training's multi_logloss: 1.04672	validation's multi_logloss: 1.04804
[71]	training's multi_logloss: 1.04648	validation's multi_logloss: 1.04778
[72]	training's multi_logloss: 1.04648	validation's multi_logloss: 1.04778
[73]	training's multi_logloss: 1.04648	validation's multi_logloss: 1.04778
[74]	training's multi_logloss: 1.04648	validation's multi_logloss: 1.04778
[75]	training's multi_logloss: 1.04648	validation's multi_logloss: 1.04778
[76]	training's multi_logloss: 1.04625	validation's multi_logloss: 1.04751
[77]	training's multi_logloss: 1.04625	validation's multi_logloss: 1.04751
[78]	training's multi_logloss: 1.04625	validation's multi_logloss: 1.04751
[79]	training's multi_logloss: 1.04625	validation's multi_logloss: 1.04751
[80]	training's multi_logloss: 1.04603	validation's multi_logloss: 1.04736
[81]	training's multi_logloss: 1.04603	validation's multi_logloss: 1.04736
[82]	training's multi_logloss: 1.04603	validation's multi_logloss: 1.04736
[83]	training's multi_logloss: 1.04603	validation's multi_logloss: 1.04736
[84]	training's multi_logloss: 1.04603	validation's multi_logloss: 1.04736
[85]	training's multi_logloss: 1.04603	validation's multi_logloss: 1.04736
[86]	training's multi_logloss: 1.04603	validation's multi_logloss: 1.04736
[87]	training's multi_logloss: 1.04603	validation's multi_logloss: 1.04736
[88]	training's multi_logloss: 1.04581	validation's multi_logloss: 1.04717
[89]	training's multi_logloss: 1.04559	validation's multi_logloss: 1.04695
[90]	training's multi_logloss: 1.04559	validation's multi_logloss: 1.04695
[91]	training's multi_logloss: 1.04559	validation's multi_logloss: 1.04695
[92]	training's multi_logloss: 1.04559	validation's multi_logloss: 1.04695
[93]	training's multi_logloss: 1.04538	validation's multi_logloss: 1.0468
[94]	training's multi_logloss: 1.04538	validation's multi_logloss: 1.0468
[95]	training's multi_logloss: 1.04538	validation's multi_logloss: 1.0468
[96]	training's multi_logloss: 1.04538	validation's multi_logloss: 1.0468
[97]	training's multi_logloss: 1.04538	validation's multi_logloss: 1.0468
[98]	training's multi_logloss: 1.04538	validation's multi_logloss: 1.0468
[99]	training's multi_logloss: 1.04538	validation's multi_logloss: 1.0468
[100]	training's multi_logloss: 1.04538	validation's multi_logloss: 1.0468
Did not meet early stopping. Best iteration is:
[93]	training's multi_logloss: 1.04538	validation's multi_logloss: 1.0468
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.19527	validation's multi_logloss: 1.19461
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.18962	validation's multi_logloss: 1.18866
[3]	training's multi_logloss: 1.18379	validation's multi_logloss: 1.18263
[4]	training's multi_logloss: 1.17843	validation's multi_logloss: 1.17692
[5]	training's multi_logloss: 1.17328	validation's multi_logloss: 1.17145
[6]	training's multi_logloss: 1.16833	validation's multi_logloss: 1.16629
[7]	training's multi_logloss: 1.16353	validation's multi_logloss: 1.16116
[8]	training's multi_logloss: 1.15889	validation's multi_logloss: 1.15624
[9]	training's multi_logloss: 1.15462	validation's multi_logloss: 1.15166
[10]	training's multi_logloss: 1.15046	validation's multi_logloss: 1.14724
[11]	training's multi_logloss: 1.14639	validation's multi_logloss: 1.14303
[12]	training's multi_logloss: 1.14241	validation's multi_logloss: 1.13893
[13]	training's multi_logloss: 1.13866	validation's multi_logloss: 1.13516
[14]	training's multi_logloss: 1.13496	validation's multi_logloss: 1.13136
[15]	training's multi_logloss: 1.13138	validation's multi_logloss: 1.12754
[16]	training's multi_logloss: 1.1279	validation's multi_logloss: 1.12387
[17]	training's multi_logloss: 1.12453	validation's multi_logloss: 1.12042
[18]	training's multi_logloss: 1.1213	validation's multi_logloss: 1.11691
[19]	training's multi_logloss: 1.11817	validation's multi_logloss: 1.11367
[20]	training's multi_logloss: 1.11511	validation's multi_logloss: 1.11058
[21]	training's multi_logloss: 1.11214	validation's multi_logloss: 1.10744
[22]	training's multi_logloss: 1.10929	validation's multi_logloss: 1.1045
[23]	training's multi_logloss: 1.10656	validation's multi_logloss: 1.1018
[24]	training's multi_logloss: 1.10387	validation's multi_logloss: 1.09901
[25]	training's multi_logloss: 1.10116	validation's multi_logloss: 1.09623
[26]	training's multi_logloss: 1.09858	validation's multi_logloss: 1.09356
[27]	training's multi_logloss: 1.09615	validation's multi_logloss: 1.09099
[28]	training's multi_logloss: 1.0937	validation's multi_logloss: 1.08835
[29]	training's multi_logloss: 1.09133	validation's multi_logloss: 1.0858
[30]	training's multi_logloss: 1.08904	validation's multi_logloss: 1.0834
[31]	training's multi_logloss: 1.08678	validation's multi_logloss: 1.081
[32]	training's multi_logloss: 1.0846	validation's multi_logloss: 1.07875
[33]	training's multi_logloss: 1.08249	validation's multi_logloss: 1.07655
[34]	training's multi_logloss: 1.08041	validation's multi_logloss: 1.07446
[35]	training's multi_logloss: 1.07843	validation's multi_logloss: 1.07238
[36]	training's multi_logloss: 1.07645	validation's multi_logloss: 1.07024
[37]	training's multi_logloss: 1.07454	validation's multi_logloss: 1.06831
[38]	training's multi_logloss: 1.07268	validation's multi_logloss: 1.0663
[39]	training's multi_logloss: 1.07087	validation's multi_logloss: 1.06438
[40]	training's multi_logloss: 1.0691	validation's multi_logloss: 1.06255
[41]	training's multi_logloss: 1.06825	validation's multi_logloss: 1.0617
[42]	training's multi_logloss: 1.06657	validation's multi_logloss: 1.05989
[43]	training's multi_logloss: 1.06579	validation's multi_logloss: 1.05913
[44]	training's multi_logloss: 1.06506	validation's multi_logloss: 1.0584
[45]	training's multi_logloss: 1.0644	validation's multi_logloss: 1.05774
[46]	training's multi_logloss: 1.06375	validation's multi_logloss: 1.05707
[47]	training's multi_logloss: 1.06316	validation's multi_logloss: 1.05647
[48]	training's multi_logloss: 1.06259	validation's multi_logloss: 1.05584
[49]	training's multi_logloss: 1.06207	validation's multi_logloss: 1.05528
[50]	training's multi_logloss: 1.06158	validation's multi_logloss: 1.05481
[51]	training's multi_logloss: 1.06111	validation's multi_logloss: 1.05438
[52]	training's multi_logloss: 1.06067	validation's multi_logloss: 1.054
[53]	training's multi_logloss: 1.06027	validation's multi_logloss: 1.05359
[54]	training's multi_logloss: 1.05988	validation's multi_logloss: 1.05319
[55]	training's multi_logloss: 1.0595	validation's multi_logloss: 1.05291
[56]	training's multi_logloss: 1.05916	validation's multi_logloss: 1.05253
[57]	training's multi_logloss: 1.05882	validation's multi_logloss: 1.05222
[58]	training's multi_logloss: 1.05851	validation's multi_logloss: 1.05188
[59]	training's multi_logloss: 1.05822	validation's multi_logloss: 1.05156
[60]	training's multi_logloss: 1.05791	validation's multi_logloss: 1.05125
[61]	training's multi_logloss: 1.05765	validation's multi_logloss: 1.05096
[62]	training's multi_logloss: 1.05739	validation's multi_logloss: 1.05071
[63]	training's multi_logloss: 1.05713	validation's multi_logloss: 1.05047
[64]	training's multi_logloss: 1.05713	validation's multi_logloss: 1.05047
[65]	training's multi_logloss: 1.05713	validation's multi_logloss: 1.05047
[66]	training's multi_logloss: 1.05688	validation's multi_logloss: 1.05023
[67]	training's multi_logloss: 1.05688	validation's multi_logloss: 1.05023
[68]	training's multi_logloss: 1.05666	validation's multi_logloss: 1.05
[69]	training's multi_logloss: 1.05643	validation's multi_logloss: 1.04977
[70]	training's multi_logloss: 1.05623	validation's multi_logloss: 1.04954
[71]	training's multi_logloss: 1.05623	validation's multi_logloss: 1.04954
[72]	training's multi_logloss: 1.05603	validation's multi_logloss: 1.04933
[73]	training's multi_logloss: 1.05583	validation's multi_logloss: 1.04914
[74]	training's multi_logloss: 1.05561	validation's multi_logloss: 1.04892
[75]	training's multi_logloss: 1.05561	validation's multi_logloss: 1.04892
[76]	training's multi_logloss: 1.05561	validation's multi_logloss: 1.04892
[77]	training's multi_logloss: 1.05541	validation's multi_logloss: 1.04872
[78]	training's multi_logloss: 1.05541	validation's multi_logloss: 1.04872
[79]	training's multi_logloss: 1.05541	validation's multi_logloss: 1.04872
[80]	training's multi_logloss: 1.05525	validation's multi_logloss: 1.04852
[81]	training's multi_logloss: 1.05525	validation's multi_logloss: 1.04852
[82]	training's multi_logloss: 1.05525	validation's multi_logloss: 1.04852
[83]	training's multi_logloss: 1.05525	validation's multi_logloss: 1.04852
[84]	training's multi_logloss: 1.05525	validation's multi_logloss: 1.04852
[85]	training's multi_logloss: 1.05525	validation's multi_logloss: 1.04852
[86]	training's multi_logloss: 1.05525	validation's multi_logloss: 1.04852
[87]	training's multi_logloss: 1.05525	validation's multi_logloss: 1.04852
[88]	training's multi_logloss: 1.05525	validation's multi_logloss: 1.04852
[89]	training's multi_logloss: 1.05525	validation's multi_logloss: 1.04852
[90]	training's multi_logloss: 1.05525	validation's multi_logloss: 1.04852
[91]	training's multi_logloss: 1.05525	validation's multi_logloss: 1.04852
[92]	training's multi_logloss: 1.05525	validation's multi_logloss: 1.04852
[93]	training's multi_logloss: 1.05507	validation's multi_logloss: 1.04835
[94]	training's multi_logloss: 1.05507	validation's multi_logloss: 1.04835
[95]	training's multi_logloss: 1.05507	validation's multi_logloss: 1.04835
[96]	training's multi_logloss: 1.05507	validation's multi_logloss: 1.04835
[97]	training's multi_logloss: 1.05507	validation's multi_logloss: 1.04835
[98]	training's multi_logloss: 1.05507	validation's multi_logloss: 1.04835
[99]	training's multi_logloss: 1.05507	validation's multi_logloss: 1.04835
[100]	training's multi_logloss: 1.05507	validation's multi_logloss: 1.04835
Did not meet early stopping. Best iteration is:
[93]	training's multi_logloss: 1.05507	validation's multi_logloss: 1.04835
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.19461	validation's multi_logloss: 1.1953
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.18828	validation's multi_logloss: 1.18956
[3]	training's multi_logloss: 1.18225	validation's multi_logloss: 1.18408
[4]	training's multi_logloss: 1.1765	validation's multi_logloss: 1.17888
[5]	training's multi_logloss: 1.17111	validation's multi_logloss: 1.17386
[6]	training's multi_logloss: 1.166	validation's multi_logloss: 1.16909
[7]	training's multi_logloss: 1.16093	validation's multi_logloss: 1.16436
[8]	training's multi_logloss: 1.15613	validation's multi_logloss: 1.15987
[9]	training's multi_logloss: 1.15168	validation's multi_logloss: 1.15579
[10]	training's multi_logloss: 1.14723	validation's multi_logloss: 1.15177
[11]	training's multi_logloss: 1.14298	validation's multi_logloss: 1.14792
[12]	training's multi_logloss: 1.13884	validation's multi_logloss: 1.14404
[13]	training's multi_logloss: 1.13496	validation's multi_logloss: 1.14052
[14]	training's multi_logloss: 1.13119	validation's multi_logloss: 1.13712
[15]	training's multi_logloss: 1.12751	validation's multi_logloss: 1.13372
[16]	training's multi_logloss: 1.12391	validation's multi_logloss: 1.13057
[17]	training's multi_logloss: 1.12043	validation's multi_logloss: 1.12737
[18]	training's multi_logloss: 1.1171	validation's multi_logloss: 1.12423
[19]	training's multi_logloss: 1.11388	validation's multi_logloss: 1.1213
[20]	training's multi_logloss: 1.11067	validation's multi_logloss: 1.11843
[21]	training's multi_logloss: 1.10763	validation's multi_logloss: 1.11566
[22]	training's multi_logloss: 1.10463	validation's multi_logloss: 1.11283
[23]	training's multi_logloss: 1.10171	validation's multi_logloss: 1.11012
[24]	training's multi_logloss: 1.09888	validation's multi_logloss: 1.10766
[25]	training's multi_logloss: 1.09616	validation's multi_logloss: 1.10527
[26]	training's multi_logloss: 1.09348	validation's multi_logloss: 1.10276
[27]	training's multi_logloss: 1.09087	validation's multi_logloss: 1.10052
[28]	training's multi_logloss: 1.08826	validation's multi_logloss: 1.09808
[29]	training's multi_logloss: 1.08579	validation's multi_logloss: 1.09568
[30]	training's multi_logloss: 1.08338	validation's multi_logloss: 1.09357
[31]	training's multi_logloss: 1.08103	validation's multi_logloss: 1.09139
[32]	training's multi_logloss: 1.07875	validation's multi_logloss: 1.08927
[33]	training's multi_logloss: 1.07658	validation's multi_logloss: 1.08723
[34]	training's multi_logloss: 1.07441	validation's multi_logloss: 1.08535
[35]	training's multi_logloss: 1.07233	validation's multi_logloss: 1.08341
[36]	training's multi_logloss: 1.07028	validation's multi_logloss: 1.08157
[37]	training's multi_logloss: 1.06832	validation's multi_logloss: 1.0798
[38]	training's multi_logloss: 1.06643	validation's multi_logloss: 1.07808
[39]	training's multi_logloss: 1.06453	validation's multi_logloss: 1.07629
[40]	training's multi_logloss: 1.06267	validation's multi_logloss: 1.0746
[41]	training's multi_logloss: 1.06083	validation's multi_logloss: 1.073
[42]	training's multi_logloss: 1.05907	validation's multi_logloss: 1.07136
[43]	training's multi_logloss: 1.05741	validation's multi_logloss: 1.07
[44]	training's multi_logloss: 1.05573	validation's multi_logloss: 1.06852
[45]	training's multi_logloss: 1.05414	validation's multi_logloss: 1.06706
[46]	training's multi_logloss: 1.0526	validation's multi_logloss: 1.06556
[47]	training's multi_logloss: 1.05104	validation's multi_logloss: 1.06413
[48]	training's multi_logloss: 1.04957	validation's multi_logloss: 1.06271
[49]	training's multi_logloss: 1.04811	validation's multi_logloss: 1.06126
[50]	training's multi_logloss: 1.04741	validation's multi_logloss: 1.06061
[51]	training's multi_logloss: 1.04675	validation's multi_logloss: 1.06011
[52]	training's multi_logloss: 1.04612	validation's multi_logloss: 1.05955
[53]	training's multi_logloss: 1.04552	validation's multi_logloss: 1.05892
[54]	training's multi_logloss: 1.04552	validation's multi_logloss: 1.05892
[55]	training's multi_logloss: 1.04494	validation's multi_logloss: 1.05841
[56]	training's multi_logloss: 1.04442	validation's multi_logloss: 1.05794
[57]	training's multi_logloss: 1.04394	validation's multi_logloss: 1.05749
[58]	training's multi_logloss: 1.04394	validation's multi_logloss: 1.05749
[59]	training's multi_logloss: 1.04346	validation's multi_logloss: 1.05708
[60]	training's multi_logloss: 1.04346	validation's multi_logloss: 1.05708
[61]	training's multi_logloss: 1.04346	validation's multi_logloss: 1.05708
[62]	training's multi_logloss: 1.04346	validation's multi_logloss: 1.05708
[63]	training's multi_logloss: 1.043	validation's multi_logloss: 1.05671
[64]	training's multi_logloss: 1.04255	validation's multi_logloss: 1.05624
[65]	training's multi_logloss: 1.04255	validation's multi_logloss: 1.05624
[66]	training's multi_logloss: 1.04255	validation's multi_logloss: 1.05624
[67]	training's multi_logloss: 1.04217	validation's multi_logloss: 1.0559
[68]	training's multi_logloss: 1.04217	validation's multi_logloss: 1.0559
[69]	training's multi_logloss: 1.04217	validation's multi_logloss: 1.0559
[70]	training's multi_logloss: 1.04217	validation's multi_logloss: 1.0559
[71]	training's multi_logloss: 1.04179	validation's multi_logloss: 1.0555
[72]	training's multi_logloss: 1.04179	validation's multi_logloss: 1.0555
[73]	training's multi_logloss: 1.04179	validation's multi_logloss: 1.0555
[74]	training's multi_logloss: 1.04141	validation's multi_logloss: 1.05519
[75]	training's multi_logloss: 1.04107	validation's multi_logloss: 1.05496
[76]	training's multi_logloss: 1.04107	validation's multi_logloss: 1.05496
[77]	training's multi_logloss: 1.04076	validation's multi_logloss: 1.05465
[78]	training's multi_logloss: 1.04076	validation's multi_logloss: 1.05465
[79]	training's multi_logloss: 1.04076	validation's multi_logloss: 1.05465
[80]	training's multi_logloss: 1.04076	validation's multi_logloss: 1.05465
[81]	training's multi_logloss: 1.04076	validation's multi_logloss: 1.05465
[82]	training's multi_logloss: 1.04076	validation's multi_logloss: 1.05465
[83]	training's multi_logloss: 1.04076	validation's multi_logloss: 1.05465
[84]	training's multi_logloss: 1.04076	validation's multi_logloss: 1.05465
[85]	training's multi_logloss: 1.04076	validation's multi_logloss: 1.05465
[86]	training's multi_logloss: 1.04076	validation's multi_logloss: 1.05465
[87]	training's multi_logloss: 1.04076	validation's multi_logloss: 1.05465
[88]	training's multi_logloss: 1.04076	validation's multi_logloss: 1.05465
[89]	training's multi_logloss: 1.04076	validation's multi_logloss: 1.05465
[90]	training's multi_logloss: 1.04076	validation's multi_logloss: 1.05465
[91]	training's multi_logloss: 1.04046	validation's multi_logloss: 1.0544
[92]	training's multi_logloss: 1.04046	validation's multi_logloss: 1.0544
[93]	training's multi_logloss: 1.04046	validation's multi_logloss: 1.0544
[94]	training's multi_logloss: 1.04046	validation's multi_logloss: 1.0544
[95]	training's multi_logloss: 1.04015	validation's multi_logloss: 1.05417
[96]	training's multi_logloss: 1.04015	validation's multi_logloss: 1.05417
[97]	training's multi_logloss: 1.04015	validation's multi_logloss: 1.05417
[98]	training's multi_logloss: 1.04015	validation's multi_logloss: 1.05417
[99]	training's multi_logloss: 1.04015	validation's multi_logloss: 1.05417
[100]	training's multi_logloss: 1.04015	validation's multi_logloss: 1.05417
Did not meet early stopping. Best iteration is:
[95]	training's multi_logloss: 1.04015	validation's multi_logloss: 1.05417
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.19501	validation's multi_logloss: 1.19558
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.1889	validation's multi_logloss: 1.18939
[3]	training's multi_logloss: 1.18281	validation's multi_logloss: 1.18368
[4]	training's multi_logloss: 1.17727	validation's multi_logloss: 1.17822
[5]	training's multi_logloss: 1.17193	validation's multi_logloss: 1.17294
[6]	training's multi_logloss: 1.1669	validation's multi_logloss: 1.16801
[7]	training's multi_logloss: 1.16189	validation's multi_logloss: 1.16315
[8]	training's multi_logloss: 1.15714	validation's multi_logloss: 1.15853
[9]	training's multi_logloss: 1.15264	validation's multi_logloss: 1.15416
[10]	training's multi_logloss: 1.14829	validation's multi_logloss: 1.15
[11]	training's multi_logloss: 1.14414	validation's multi_logloss: 1.14594
[12]	training's multi_logloss: 1.1401	validation's multi_logloss: 1.14203
[13]	training's multi_logloss: 1.13629	validation's multi_logloss: 1.13826
[14]	training's multi_logloss: 1.1325	validation's multi_logloss: 1.13461
[15]	training's multi_logloss: 1.12897	validation's multi_logloss: 1.13126
[16]	training's multi_logloss: 1.12547	validation's multi_logloss: 1.128
[17]	training's multi_logloss: 1.12198	validation's multi_logloss: 1.12463
[18]	training's multi_logloss: 1.11867	validation's multi_logloss: 1.12144
[19]	training's multi_logloss: 1.11547	validation's multi_logloss: 1.11824
[20]	training's multi_logloss: 1.11234	validation's multi_logloss: 1.11518
[21]	training's multi_logloss: 1.10929	validation's multi_logloss: 1.11225
[22]	training's multi_logloss: 1.10637	validation's multi_logloss: 1.10948
[23]	training's multi_logloss: 1.10349	validation's multi_logloss: 1.10668
[24]	training's multi_logloss: 1.10074	validation's multi_logloss: 1.10388
[25]	training's multi_logloss: 1.09797	validation's multi_logloss: 1.10125
[26]	training's multi_logloss: 1.0953	validation's multi_logloss: 1.09875
[27]	training's multi_logloss: 1.09271	validation's multi_logloss: 1.09632
[28]	training's multi_logloss: 1.0902	validation's multi_logloss: 1.09389
[29]	training's multi_logloss: 1.08772	validation's multi_logloss: 1.09151
[30]	training's multi_logloss: 1.08537	validation's multi_logloss: 1.08929
[31]	training's multi_logloss: 1.08302	validation's multi_logloss: 1.08708
[32]	training's multi_logloss: 1.0807	validation's multi_logloss: 1.08498
[33]	training's multi_logloss: 1.07847	validation's multi_logloss: 1.08296
[34]	training's multi_logloss: 1.07634	validation's multi_logloss: 1.08106
[35]	training's multi_logloss: 1.07424	validation's multi_logloss: 1.07904
[36]	training's multi_logloss: 1.07217	validation's multi_logloss: 1.07707
[37]	training's multi_logloss: 1.07015	validation's multi_logloss: 1.07515
[38]	training's multi_logloss: 1.0682	validation's multi_logloss: 1.07334
[39]	training's multi_logloss: 1.06632	validation's multi_logloss: 1.07167
[40]	training's multi_logloss: 1.06443	validation's multi_logloss: 1.06989
[41]	training's multi_logloss: 1.06263	validation's multi_logloss: 1.06823
[42]	training's multi_logloss: 1.06088	validation's multi_logloss: 1.06661
[43]	training's multi_logloss: 1.0591	validation's multi_logloss: 1.0651
[44]	training's multi_logloss: 1.0574	validation's multi_logloss: 1.06342
[45]	training's multi_logloss: 1.05578	validation's multi_logloss: 1.06207
[46]	training's multi_logloss: 1.05418	validation's multi_logloss: 1.06058
[47]	training's multi_logloss: 1.05261	validation's multi_logloss: 1.0592
[48]	training's multi_logloss: 1.05108	validation's multi_logloss: 1.05787
[49]	training's multi_logloss: 1.04962	validation's multi_logloss: 1.05656
[50]	training's multi_logloss: 1.04891	validation's multi_logloss: 1.05588
[51]	training's multi_logloss: 1.04823	validation's multi_logloss: 1.05524
[52]	training's multi_logloss: 1.04757	validation's multi_logloss: 1.05467
[53]	training's multi_logloss: 1.04612	validation's multi_logloss: 1.05329
[54]	training's multi_logloss: 1.04553	validation's multi_logloss: 1.05281
[55]	training's multi_logloss: 1.04553	validation's multi_logloss: 1.05281
[56]	training's multi_logloss: 1.04498	validation's multi_logloss: 1.05233
[57]	training's multi_logloss: 1.04498	validation's multi_logloss: 1.05233
[58]	training's multi_logloss: 1.04446	validation's multi_logloss: 1.05188
[59]	training's multi_logloss: 1.04396	validation's multi_logloss: 1.05147
[60]	training's multi_logloss: 1.04396	validation's multi_logloss: 1.05147
[61]	training's multi_logloss: 1.04396	validation's multi_logloss: 1.05147
[62]	training's multi_logloss: 1.04349	validation's multi_logloss: 1.05113
[63]	training's multi_logloss: 1.04349	validation's multi_logloss: 1.05113
[64]	training's multi_logloss: 1.04305	validation's multi_logloss: 1.0508
[65]	training's multi_logloss: 1.04305	validation's multi_logloss: 1.0508
[66]	training's multi_logloss: 1.04305	validation's multi_logloss: 1.0508
[67]	training's multi_logloss: 1.04305	validation's multi_logloss: 1.0508
[68]	training's multi_logloss: 1.04305	validation's multi_logloss: 1.0508
[69]	training's multi_logloss: 1.04305	validation's multi_logloss: 1.0508
[70]	training's multi_logloss: 1.04264	validation's multi_logloss: 1.05044
[71]	training's multi_logloss: 1.04264	validation's multi_logloss: 1.05044
[72]	training's multi_logloss: 1.04264	validation's multi_logloss: 1.05044
[73]	training's multi_logloss: 1.04264	validation's multi_logloss: 1.05044
[74]	training's multi_logloss: 1.04264	validation's multi_logloss: 1.05044
[75]	training's multi_logloss: 1.04264	validation's multi_logloss: 1.05044
[76]	training's multi_logloss: 1.04226	validation's multi_logloss: 1.05015
[77]	training's multi_logloss: 1.0419	validation's multi_logloss: 1.04991
[78]	training's multi_logloss: 1.0419	validation's multi_logloss: 1.04991
[79]	training's multi_logloss: 1.04156	validation's multi_logloss: 1.0496
[80]	training's multi_logloss: 1.04156	validation's multi_logloss: 1.0496
[81]	training's multi_logloss: 1.04156	validation's multi_logloss: 1.0496
[82]	training's multi_logloss: 1.04124	validation's multi_logloss: 1.04935
[83]	training's multi_logloss: 1.04124	validation's multi_logloss: 1.04935
[84]	training's multi_logloss: 1.04092	validation's multi_logloss: 1.04907
[85]	training's multi_logloss: 1.04092	validation's multi_logloss: 1.04907
[86]	training's multi_logloss: 1.04092	validation's multi_logloss: 1.04907
[87]	training's multi_logloss: 1.04092	validation's multi_logloss: 1.04907
[88]	training's multi_logloss: 1.04092	validation's multi_logloss: 1.04907
[89]	training's multi_logloss: 1.04092	validation's multi_logloss: 1.04907
[90]	training's multi_logloss: 1.04092	validation's multi_logloss: 1.04907
[91]	training's multi_logloss: 1.04092	validation's multi_logloss: 1.04907
[92]	training's multi_logloss: 1.04092	validation's multi_logloss: 1.04907
[93]	training's multi_logloss: 1.04092	validation's multi_logloss: 1.04907
[94]	training's multi_logloss: 1.04092	validation's multi_logloss: 1.04907
[95]	training's multi_logloss: 1.04092	validation's multi_logloss: 1.04907
[96]	training's multi_logloss: 1.04092	validation's multi_logloss: 1.04907
[97]	training's multi_logloss: 1.04092	validation's multi_logloss: 1.04907
[98]	training's multi_logloss: 1.04092	validation's multi_logloss: 1.04907
[99]	training's multi_logloss: 1.04092	validation's multi_logloss: 1.04907
[100]	training's multi_logloss: 1.04092	validation's multi_logloss: 1.04907
Did not meet early stopping. Best iteration is:
[84]	training's multi_logloss: 1.04092	validation's multi_logloss: 1.04907
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=7000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7000
[LightGBM] [Warning] min_gain_to_split is set=5.43916784634248, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.43916784634248
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=7000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7000
[LightGBM] [Warning] min_gain_to_split is set=5.43916784634248, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.43916784634248
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=7000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7000
[LightGBM] [Warning] min_gain_to_split is set=5.43916784634248, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.43916784634248
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=7000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7000
[LightGBM] [Warning] min_gain_to_split is set=5.43916784634248, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.43916784634248
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=7700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7700
[LightGBM] [Warning] min_gain_to_split is set=1.0280794891442702, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.0280794891442702
[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=7700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7700
[LightGBM] [Warning] min_gain_to_split is set=1.0280794891442702, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.0280794891442702
[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=7700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7700
[LightGBM] [Warning] min_gain_to_split is set=1.0280794891442702, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.0280794891442702
[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=7700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7700
[LightGBM] [Warning] min_gain_to_split is set=1.0280794891442702, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.0280794891442702
[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=6500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6500
[LightGBM] [Warning] min_gain_to_split is set=6.971382248200028, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.971382248200028
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=6500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6500
[LightGBM] [Warning] min_gain_to_split is set=6.971382248200028, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.971382248200028
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=6500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6500
[LightGBM] [Warning] min_gain_to_split is set=6.971382248200028, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.971382248200028
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=6500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6500
[LightGBM] [Warning] min_gain_to_split is set=6.971382248200028, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.971382248200028
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=4100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4100
[LightGBM] [Warning] min_gain_to_split is set=2.4444386046466176, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.4444386046466176
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=4100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4100
[LightGBM] [Warning] min_gain_to_split is set=2.4444386046466176, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.4444386046466176
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=4100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4100
[LightGBM] [Warning] min_gain_to_split is set=2.4444386046466176, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.4444386046466176
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=4100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4100
[LightGBM] [Warning] min_gain_to_split is set=2.4444386046466176, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.4444386046466176
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200
[LightGBM] [Warning] min_gain_to_split is set=9.802288269351196, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.802288269351196
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200
[LightGBM] [Warning] min_gain_to_split is set=9.802288269351196, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.802288269351196
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200
[LightGBM] [Warning] min_gain_to_split is set=9.802288269351196, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.802288269351196
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200
[LightGBM] [Warning] min_gain_to_split is set=9.802288269351196, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.802288269351196
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100
[LightGBM] [Warning] min_gain_to_split is set=4.602237694432498, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.602237694432498
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=5100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5100
[LightGBM] [Warning] min_gain_to_split is set=13.606488206741162, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.606488206741162
[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=5100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5100
[LightGBM] [Warning] min_gain_to_split is set=13.606488206741162, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.606488206741162
[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=5100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5100
[LightGBM] [Warning] min_gain_to_split is set=13.606488206741162, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.606488206741162
[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=9900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9900
[LightGBM] [Warning] min_gain_to_split is set=14.63901736635309, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.63901736635309
[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=9900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9900
[LightGBM] [Warning] min_gain_to_split is set=14.63901736635309, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.63901736635309
[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=9900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9900
[LightGBM] [Warning] min_gain_to_split is set=14.63901736635309, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.63901736635309
[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=9900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9900
[LightGBM] [Warning] min_gain_to_split is set=14.63901736635309, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.63901736635309
[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=9900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9900
[LightGBM] [Warning] min_gain_to_split is set=9.520005409738104, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.520005409738104
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=9900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9900
[LightGBM] [Warning] min_gain_to_split is set=9.520005409738104, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.520005409738104
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=9900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9900
[LightGBM] [Warning] min_gain_to_split is set=9.520005409738104, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.520005409738104
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=9900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9900
[LightGBM] [Warning] min_gain_to_split is set=9.520005409738104, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.520005409738104
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=1900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1900
[LightGBM] [Warning] min_gain_to_split is set=11.82047363540951, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.82047363540951
[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=8300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8300
[LightGBM] [Warning] min_gain_to_split is set=7.685733190723137, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.685733190723137
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=8300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8300
[LightGBM] [Warning] min_gain_to_split is set=7.685733190723137, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.685733190723137
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=8300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8300
[LightGBM] [Warning] min_gain_to_split is set=7.685733190723137, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.685733190723137
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=5400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5400
[LightGBM] [Warning] min_gain_to_split is set=12.667942763557406, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.667942763557406
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=5400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5400
[LightGBM] [Warning] min_gain_to_split is set=12.667942763557406, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.667942763557406
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=5400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5400
[LightGBM] [Warning] min_gain_to_split is set=12.667942763557406, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.667942763557406
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=5400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5400
[LightGBM] [Warning] min_gain_to_split is set=12.667942763557406, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.667942763557406
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=4100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4100
[LightGBM] [Warning] min_gain_to_split is set=14.930314340117896, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.930314340117896
[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=4100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4100
[LightGBM] [Warning] min_gain_to_split is set=14.930314340117896, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.930314340117896
[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=4100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4100
[LightGBM] [Warning] min_gain_to_split is set=14.930314340117896, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.930314340117896
[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=4100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4100
[LightGBM] [Warning] min_gain_to_split is set=14.930314340117896, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.930314340117896
[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=5700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5700
[LightGBM] [Warning] min_gain_to_split is set=0.16611444240756246, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.16611444240756246
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=5700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5700
[LightGBM] [Warning] min_gain_to_split is set=0.16611444240756246, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.16611444240756246
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=5700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5700
[LightGBM] [Warning] min_gain_to_split is set=0.16611444240756246, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.16611444240756246
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=5700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5700
[LightGBM] [Warning] min_gain_to_split is set=0.16611444240756246, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.16611444240756246
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=8200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8200
[LightGBM] [Warning] min_gain_to_split is set=4.097749258048749, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.097749258048749
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=8200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8200
[LightGBM] [Warning] min_gain_to_split is set=4.097749258048749, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.097749258048749
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=8200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8200
[LightGBM] [Warning] min_gain_to_split is set=4.097749258048749, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.097749258048749
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=8200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8200
[LightGBM] [Warning] min_gain_to_split is set=4.097749258048749, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.097749258048749
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=2800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2800
[LightGBM] [Warning] min_gain_to_split is set=7.697424680264021, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.697424680264021
[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=2800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2800
[LightGBM] [Warning] min_gain_to_split is set=7.697424680264021, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.697424680264021
[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=2800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2800
[LightGBM] [Warning] min_gain_to_split is set=7.697424680264021, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.697424680264021
[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=2800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2800
[LightGBM] [Warning] min_gain_to_split is set=7.697424680264021, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.697424680264021
[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=4000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4000
[LightGBM] [Warning] min_gain_to_split is set=3.2122154651577595, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.2122154651577595
[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=2500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2500
[LightGBM] [Warning] min_gain_to_split is set=1.715425269113069, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.715425269113069
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=2500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2500
[LightGBM] [Warning] min_gain_to_split is set=1.715425269113069, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.715425269113069
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=2500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2500
[LightGBM] [Warning] min_gain_to_split is set=1.715425269113069, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.715425269113069
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700
[LightGBM] [Warning] min_gain_to_split is set=2.861684627908227, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.861684627908227
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700
[LightGBM] [Warning] min_gain_to_split is set=2.861684627908227, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.861684627908227
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700
[LightGBM] [Warning] min_gain_to_split is set=2.861684627908227, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.861684627908227
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=1700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1700
[LightGBM] [Warning] min_gain_to_split is set=2.861684627908227, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.861684627908227
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=3600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3600
[LightGBM] [Warning] min_gain_to_split is set=5.54733450878568, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.54733450878568
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=3600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3600
[LightGBM] [Warning] min_gain_to_split is set=5.54733450878568, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.54733450878568
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=3600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3600
[LightGBM] [Warning] min_gain_to_split is set=5.54733450878568, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.54733450878568
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=3600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3600
[LightGBM] [Warning] min_gain_to_split is set=5.54733450878568, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.54733450878568
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300
[LightGBM] [Warning] min_gain_to_split is set=0.3481194571240991, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.3481194571240991
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=4700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4700
[LightGBM] [Warning] min_gain_to_split is set=1.860224114211325, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.860224114211325
[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=4700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4700
[LightGBM] [Warning] min_gain_to_split is set=1.860224114211325, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.860224114211325
[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=4700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4700
[LightGBM] [Warning] min_gain_to_split is set=1.860224114211325, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.860224114211325
[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=9200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9200
[LightGBM] [Warning] min_gain_to_split is set=3.6937811072766973, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.6937811072766973
[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=9200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9200
[LightGBM] [Warning] min_gain_to_split is set=3.6937811072766973, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.6937811072766973
[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=9200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9200
[LightGBM] [Warning] min_gain_to_split is set=3.6937811072766973, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.6937811072766973
[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=9200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9200
[LightGBM] [Warning] min_gain_to_split is set=3.6937811072766973, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.6937811072766973
[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=6200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6200
[LightGBM] [Warning] min_gain_to_split is set=2.0390994163933196, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.0390994163933196
[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=6200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6200
[LightGBM] [Warning] min_gain_to_split is set=2.0390994163933196, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.0390994163933196
[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=6200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6200
[LightGBM] [Warning] min_gain_to_split is set=2.0390994163933196, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.0390994163933196
[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=6200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6200
[LightGBM] [Warning] min_gain_to_split is set=2.0390994163933196, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.0390994163933196
[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200
[LightGBM] [Warning] min_gain_to_split is set=3.192665277265877, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.192665277265877
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=2200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2200
[LightGBM] [Warning] min_gain_to_split is set=1.2290179169383304, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.2290179169383304
[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=2200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2200
[LightGBM] [Warning] min_gain_to_split is set=1.2290179169383304, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.2290179169383304
[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=2200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2200
[LightGBM] [Warning] min_gain_to_split is set=1.2290179169383304, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.2290179169383304
[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=6800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6800
[LightGBM] [Warning] min_gain_to_split is set=4.960390907821093, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.960390907821093
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=6800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6800
[LightGBM] [Warning] min_gain_to_split is set=4.960390907821093, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.960390907821093
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=6800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6800
[LightGBM] [Warning] min_gain_to_split is set=4.960390907821093, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.960390907821093
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=6800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6800
[LightGBM] [Warning] min_gain_to_split is set=4.960390907821093, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.960390907821093
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=9000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9000
[LightGBM] [Warning] min_gain_to_split is set=5.954094623645899, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.954094623645899
[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=9000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9000
[LightGBM] [Warning] min_gain_to_split is set=5.954094623645899, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.954094623645899
[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=9000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9000
[LightGBM] [Warning] min_gain_to_split is set=5.954094623645899, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.954094623645899
[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=9000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9000
[LightGBM] [Warning] min_gain_to_split is set=5.954094623645899, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.954094623645899
[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=3300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3300
[LightGBM] [Warning] min_gain_to_split is set=4.016430603399469, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.016430603399469
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=7200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7200
[LightGBM] [Warning] min_gain_to_split is set=6.17556120907582, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.17556120907582
[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=7200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7200
[LightGBM] [Warning] min_gain_to_split is set=6.17556120907582, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.17556120907582
[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=7200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7200
[LightGBM] [Warning] min_gain_to_split is set=6.17556120907582, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.17556120907582
[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=7500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7500
[LightGBM] [Warning] min_gain_to_split is set=6.734270631548082, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.734270631548082
[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=7500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7500
[LightGBM] [Warning] min_gain_to_split is set=6.734270631548082, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.734270631548082
[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=7500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7500
[LightGBM] [Warning] min_gain_to_split is set=6.734270631548082, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.734270631548082
[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=7500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7500
[LightGBM] [Warning] min_gain_to_split is set=6.734270631548082, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=6.734270631548082
[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=4700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4700
[LightGBM] [Warning] min_gain_to_split is set=2.670397637342254, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.670397637342254
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=4700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4700
[LightGBM] [Warning] min_gain_to_split is set=2.670397637342254, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.670397637342254
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=4700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4700
[LightGBM] [Warning] min_gain_to_split is set=2.670397637342254, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.670397637342254
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=4700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4700
[LightGBM] [Warning] min_gain_to_split is set=2.670397637342254, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.670397637342254
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=6000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6000
[LightGBM] [Warning] min_gain_to_split is set=4.90947930412827, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.90947930412827
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=6000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6000
[LightGBM] [Warning] min_gain_to_split is set=4.90947930412827, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.90947930412827
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=6000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6000
[LightGBM] [Warning] min_gain_to_split is set=4.90947930412827, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.90947930412827
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=6000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6000
[LightGBM] [Warning] min_gain_to_split is set=4.90947930412827, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.90947930412827
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=8000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8000
[LightGBM] [Warning] min_gain_to_split is set=8.363007475534618, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.363007475534618
[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=8000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8000
[LightGBM] [Warning] min_gain_to_split is set=8.363007475534618, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.363007475534618
[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=8000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8000
[LightGBM] [Warning] min_gain_to_split is set=8.363007475534618, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.363007475534618
[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=8000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8000
[LightGBM] [Warning] min_gain_to_split is set=8.363007475534618, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.363007475534618
[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800
[LightGBM] [Warning] min_gain_to_split is set=5.341827908182357, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.341827908182357
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800
[LightGBM] [Warning] min_gain_to_split is set=5.341827908182357, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.341827908182357
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800
[LightGBM] [Warning] min_gain_to_split is set=5.341827908182357, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.341827908182357
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=8800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8800
[LightGBM] [Warning] min_gain_to_split is set=5.341827908182357, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=5.341827908182357
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=4600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4600
[LightGBM] [Warning] min_gain_to_split is set=9.081696128186312, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.081696128186312
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=4600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4600
[LightGBM] [Warning] min_gain_to_split is set=9.081696128186312, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.081696128186312
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=4600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4600
[LightGBM] [Warning] min_gain_to_split is set=9.081696128186312, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.081696128186312
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=4600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4600
[LightGBM] [Warning] min_gain_to_split is set=9.081696128186312, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.081696128186312
[LightGBM] [Warning] lambda_l1 is set=0, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=9500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9500
[LightGBM] [Warning] min_gain_to_split is set=4.391352544239509, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.391352544239509
[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=9500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9500
[LightGBM] [Warning] min_gain_to_split is set=4.391352544239509, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.391352544239509
[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=9500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9500
[LightGBM] [Warning] min_gain_to_split is set=4.391352544239509, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.391352544239509
[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=9500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9500
[LightGBM] [Warning] min_gain_to_split is set=4.391352544239509, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.391352544239509
[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=7500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7500
[LightGBM] [Warning] min_gain_to_split is set=10.313006496664464, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.313006496664464
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=7500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7500
[LightGBM] [Warning] min_gain_to_split is set=10.313006496664464, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.313006496664464
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=7500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7500
[LightGBM] [Warning] min_gain_to_split is set=10.313006496664464, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.313006496664464
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=7500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7500
[LightGBM] [Warning] min_gain_to_split is set=10.313006496664464, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.313006496664464
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=6700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6700
[LightGBM] [Warning] min_gain_to_split is set=13.724974296840596, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.724974296840596
[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=6700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6700
[LightGBM] [Warning] min_gain_to_split is set=13.724974296840596, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.724974296840596
[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=6700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6700
[LightGBM] [Warning] min_gain_to_split is set=13.724974296840596, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.724974296840596
[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=6700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6700
[LightGBM] [Warning] min_gain_to_split is set=13.724974296840596, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.724974296840596
[LightGBM] [Warning] lambda_l1 is set=10, reg_alpha=0.0 will be ignored. Current value: lambda_l1=10
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=8700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8700
[LightGBM] [Warning] min_gain_to_split is set=1.0523962422349975, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.0523962422349975
[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=8700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8700
[LightGBM] [Warning] min_gain_to_split is set=1.0523962422349975, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.0523962422349975
[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=8700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8700
[LightGBM] [Warning] min_gain_to_split is set=1.0523962422349975, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.0523962422349975
[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=8700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8700
[LightGBM] [Warning] min_gain_to_split is set=1.0523962422349975, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=1.0523962422349975
[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=9700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9700
[LightGBM] [Warning] min_gain_to_split is set=2.4968925962665662, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.4968925962665662
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=9700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9700
[LightGBM] [Warning] min_gain_to_split is set=2.4968925962665662, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.4968925962665662
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=9700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9700
[LightGBM] [Warning] min_gain_to_split is set=2.4968925962665662, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.4968925962665662
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=9700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9700
[LightGBM] [Warning] min_gain_to_split is set=2.4968925962665662, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.4968925962665662
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=5200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5200
[LightGBM] [Warning] min_gain_to_split is set=3.4631931515063714, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.4631931515063714
[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=5200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5200
[LightGBM] [Warning] min_gain_to_split is set=3.4631931515063714, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.4631931515063714
[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=5200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5200
[LightGBM] [Warning] min_gain_to_split is set=3.4631931515063714, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.4631931515063714
[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=5200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5200
[LightGBM] [Warning] min_gain_to_split is set=3.4631931515063714, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.4631931515063714
[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=7800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7800
[LightGBM] [Warning] min_gain_to_split is set=4.611084103797177, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.611084103797177
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09912
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=7800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7800
[LightGBM] [Warning] min_gain_to_split is set=4.611084103797177, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.611084103797177
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09888
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=7800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7800
[LightGBM] [Warning] min_gain_to_split is set=4.611084103797177, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.611084103797177
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09927
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=7800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7800
[LightGBM] [Warning] min_gain_to_split is set=4.611084103797177, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.611084103797177
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[3]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[4]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[5]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[6]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[7]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[8]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[9]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[10]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[11]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[12]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[13]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[14]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[15]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[16]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[17]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[18]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[19]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[20]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[21]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09915	validation's multi_logloss: 1.09934
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=3.786823805618879, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=3.786823805618879
[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=2900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2900
[LightGBM] [Warning] min_gain_to_split is set=13.173444966901522, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.173444966901522
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.05548	validation's multi_logloss: 1.05733
Training until validation scores don't improve for 20 rounds
[2]	training's multi_logloss: 1.05089	validation's multi_logloss: 1.05273
[3]	training's multi_logloss: 1.04669	validation's multi_logloss: 1.04848
[4]	training's multi_logloss: 1.04303	validation's multi_logloss: 1.04492
[5]	training's multi_logloss: 1.0397	validation's multi_logloss: 1.04178
[6]	training's multi_logloss: 1.03653	validation's multi_logloss: 1.0388
[7]	training's multi_logloss: 1.0337	validation's multi_logloss: 1.03605
[8]	training's multi_logloss: 1.03125	validation's multi_logloss: 1.03356
[9]	training's multi_logloss: 1.02877	validation's multi_logloss: 1.03119
[10]	training's multi_logloss: 1.02654	validation's multi_logloss: 1.02897
[11]	training's multi_logloss: 1.02458	validation's multi_logloss: 1.02707
[12]	training's multi_logloss: 1.02268	validation's multi_logloss: 1.02524
[13]	training's multi_logloss: 1.02092	validation's multi_logloss: 1.02355
[14]	training's multi_logloss: 1.01944	validation's multi_logloss: 1.02208
[15]	training's multi_logloss: 1.01789	validation's multi_logloss: 1.02059
[16]	training's multi_logloss: 1.01651	validation's multi_logloss: 1.01918
[17]	training's multi_logloss: 1.01513	validation's multi_logloss: 1.01788
[18]	training's multi_logloss: 1.01387	validation's multi_logloss: 1.01663
[19]	training's multi_logloss: 1.01269	validation's multi_logloss: 1.01548
[20]	training's multi_logloss: 1.01163	validation's multi_logloss: 1.0145
[21]	training's multi_logloss: 1.0106	validation's multi_logloss: 1.01353
[22]	training's multi_logloss: 1.00959	validation's multi_logloss: 1.01245
[23]	training's multi_logloss: 1.00859	validation's multi_logloss: 1.01158
[24]	training's multi_logloss: 1.00774	validation's multi_logloss: 1.01085
[25]	training's multi_logloss: 1.007	validation's multi_logloss: 1.01024
[26]	training's multi_logloss: 1.00623	validation's multi_logloss: 1.00947
[27]	training's multi_logloss: 1.00534	validation's multi_logloss: 1.00879
[28]	training's multi_logloss: 1.00475	validation's multi_logloss: 1.00827
[29]	training's multi_logloss: 1.00416	validation's multi_logloss: 1.00773
[30]	training's multi_logloss: 1.00357	validation's multi_logloss: 1.0073
[31]	training's multi_logloss: 1.00303	validation's multi_logloss: 1.00679
[32]	training's multi_logloss: 1.0026	validation's multi_logloss: 1.00636
[33]	training's multi_logloss: 1.00222	validation's multi_logloss: 1.00606
[34]	training's multi_logloss: 1.00179	validation's multi_logloss: 1.00562
[35]	training's multi_logloss: 1.00128	validation's multi_logloss: 1.00517
[36]	training's multi_logloss: 1.00082	validation's multi_logloss: 1.00474
[37]	training's multi_logloss: 1.00048	validation's multi_logloss: 1.00442
[38]	training's multi_logloss: 1.00014	validation's multi_logloss: 1.0041
[39]	training's multi_logloss: 0.999664	validation's multi_logloss: 1.00367
[40]	training's multi_logloss: 0.999344	validation's multi_logloss: 1.00335
[41]	training's multi_logloss: 0.999049	validation's multi_logloss: 1.00312
[42]	training's multi_logloss: 0.998623	validation's multi_logloss: 1.00278
[43]	training's multi_logloss: 0.998333	validation's multi_logloss: 1.00246
[44]	training's multi_logloss: 0.997967	validation's multi_logloss: 1.00218
[45]	training's multi_logloss: 0.997535	validation's multi_logloss: 1.00186
[46]	training's multi_logloss: 0.997292	validation's multi_logloss: 1.00165
[47]	training's multi_logloss: 0.997036	validation's multi_logloss: 1.00145
[48]	training's multi_logloss: 0.996788	validation's multi_logloss: 1.00123
[49]	training's multi_logloss: 0.996675	validation's multi_logloss: 1.00114
[50]	training's multi_logloss: 0.996559	validation's multi_logloss: 1.00108
[51]	training's multi_logloss: 0.996441	validation's multi_logloss: 1.00096
[52]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[53]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[54]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[55]	training's multi_logloss: 0.996208	validation's multi_logloss: 1.00078
[56]	training's multi_logloss: 0.995976	validation's multi_logloss: 1.00058
[57]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[58]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[59]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[60]	training's multi_logloss: 0.995862	validation's multi_logloss: 1.00052
[61]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[62]	training's multi_logloss: 0.995747	validation's multi_logloss: 1.00046
[63]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[64]	training's multi_logloss: 0.995531	validation's multi_logloss: 1.00027
[65]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[66]	training's multi_logloss: 0.995422	validation's multi_logloss: 1.00021
[67]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[68]	training's multi_logloss: 0.995312	validation's multi_logloss: 1.00016
[69]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[70]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[71]	training's multi_logloss: 0.995198	validation's multi_logloss: 1.00007
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[73]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[74]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[75]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[76]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[77]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[78]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[79]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[80]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[81]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[82]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[83]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[84]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[85]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[86]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[87]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[88]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[89]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[90]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[91]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
[92]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
Early stopping, best iteration is:
[72]	training's multi_logloss: 0.99508	validation's multi_logloss: 1.00006
(140,)
1.0000615308636769 0.51959
3472
INFO: end
