{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import mytrain_lib as ml\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(error,accuracy_train,accuracy_test,confusion_matrix, hyperparams, title=''):\n",
    "\n",
    "    acc_test_lastepoch = accuracy_test[:,:,-1]  # only interested in last epoch\n",
    "\n",
    "    # best models of each configuration\n",
    "    best_cv          = acc_test_lastepoch.argmax(axis=1)\n",
    "    best_config_cv   = np.unique(acc_test_lastepoch.argmax(axis=0))\n",
    "\n",
    "    # best configurations are:\n",
    "    print('config','\\t', 'accuracy_test\\t', '\\taccuracy_train\\t', '\\terror')\n",
    "\n",
    "    for c in best_config_cv:\n",
    "        print(c,'\\t', accuracy_test[c,best_cv[c],-1]\n",
    "                    , accuracy_train[c,best_cv[c],-1]\n",
    "                    , error[c,best_cv[c],-1])\n",
    "\n",
    "    if title=='':\n",
    "        title = datetime.now().strftime(\"_%m%d_%H%M%S\")\n",
    "\n",
    "    for i,c in enumerate(best_config_cv):\n",
    "        print(f'Config of {c} - Fold {best_cv[c]}: {hyperparams[c]}')\n",
    "        ml.dispConfusionMatrix(confusion_matrix[c,best_cv[c]],\n",
    "                        f'Confusion Matrix: MLP 1x5 {title} - {hyperparams[c]}',\n",
    "                        f'confmat_{title}_id{i}', save=True)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train      = 'F://TFG//datasets//data_train//'\n",
    "path_graphs     = 'F://TFG//graphs//plot_results//'\n",
    "path_results    = 'F://TFG//results//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data        = pd.read_csv(path_train+'training_features_DF.csv',sep=';',index_col='wyId')\n",
    "raw_Data    = pd.read_json('F://TFG//datasets/raw_datasets//RAW_partidos.json').set_index('wyId')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OBJETIVOS:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ENTRE LAS DIFERENTES EJECUCIONES    \n",
    "    - Comparar accuracy\n",
    "    - Comparar error \n",
    "    - Comparar resultados de las diferentes ejecuciones:\n",
    "        - Comparar optimizador, reduccion de dimensionlidad y hiperparámetros.\n",
    "    - Concluir que modelos tienen mejores resultados. \n",
    "    - Concluir que hiperparámetros afectan más al modelo y deben ser optimizados más detalladamente.\n",
    "        - Comparar max con la media\n",
    "<br><br>\n",
    "- DENTRO DE CADA EJECUCIÓN\n",
    "    - Evolución del error y accuracy\n",
    "    - Comprobar los resultados predecidos\n",
    "    - Concluir si los resultados tienen sentido (p.e. si la red aprende o no)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['adam_anova02_epochs5', 'adam_anova05_epochs5',\n",
       "       'adam_anova07_epochs5', 'adam_anova10_epochs5',\n",
       "       'adam_anova2_epochs5', 'adam_anova5_epochs5',\n",
       "       'adam_anova7_epochs5', 'adam_epochs5', 'adam_featsel_epochs5',\n",
       "       'adam_pca10_epochs5_', 'adam_pca3_epochs5_', 'adam_pca5_epochs5_',\n",
       "       'sgd_anova02_epochs5', 'sgd_anova05_epochs5',\n",
       "       'sgd_anova07_epochs5', 'sgd_anova10_epochs5', 'sgd_anova2_epochs5',\n",
       "       'sgd_anova5_epochs5', 'sgd_anova7_epochs5', 'sgd_epochs5',\n",
       "       'sgd_featsel_epochs5', 'sgd_pca10_epochs5_', 'sgd_pca3_epochs5_',\n",
       "       'sgd_pca5_epochs5_', 'adam_anova02_epochs20',\n",
       "       'adam_anova05_epochs20', 'adam_anova07_epochs20',\n",
       "       'adam_anova10_epochs20', 'adam_anova2_epochs20',\n",
       "       'adam_anova5_epochs20', 'adam_anova7_epochs20', 'adam_epochs20',\n",
       "       'adam_featsel_epochs20', 'adam_pca10_epochs20',\n",
       "       'adam_pca3_epochs20_', 'adam_pca5_epochs20',\n",
       "       'sgd_anova02_epochs20', 'sgd_anova05_epochs20',\n",
       "       'sgd_anova07_epochs20', 'sgd_anova10_epochs20',\n",
       "       'sgd_anova2_epochs20', 'sgd_anova5_epochs20',\n",
       "       'sgd_anova7_epochs20', 'sgd_epochs20', 'sgd_featsel_epochs20',\n",
       "       'sgd_pca10_epochs20', 'sgd_pca3_epochs20_', 'sgd_pca5_epochs20',\n",
       "       'adam_anova10_epochs100epochs100', 'adam_anova10_epochs100',\n",
       "       'adam_anova2_epochs100epochs100', 'adam_anova5_epochs100epochs100',\n",
       "       'adam_anova7_epochs100epochs100', 'adam_pca03_epochs100',\n",
       "       'adam_pca05_epochs100', 'adam_pca10_epochs100',\n",
       "       'sgd_anova02_epochs100epochs100', 'sgd_anova10_epochs100epochs100',\n",
       "       'sgd_anova2_epochs100epochs100', 'sgd_anova5_epochs100epochs100',\n",
       "       'sgd_anova7_epochs100epochs100', 'sgd_pca05epochs100',\n",
       "       'sgd_pca10epochs100'], dtype='<U31')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_res, acctrain_res, err_res, hyp_res, cm_res, config = {}, {}, {}, {}, {}, {}\n",
    "\n",
    "architecture = 'mlp1x5'\n",
    "path_model = path_results + architecture + '//'\n",
    "epochs = ['epochs005','epochs020','epochs100']\n",
    "# epochs = ['anova_mlp5']\n",
    "ep100 = ''\n",
    "\n",
    "# reg_exp = re.compile(r'(((sgd)|(adam))(_(\\w)+)*(_pca(\\d)+)*(_\\d\\d))+')\n",
    "reg_exp = re.compile(r'(((sgd)|(adam))(_(\\w)+)*(_pca(\\d)+)*((_34)|(_09)|(_16)))+')\n",
    "\n",
    "if architecture!='mlp1x5': epochs = ['']\n",
    "for ep in epochs:\n",
    "    paths   = list(filter(reg_exp.match, os.listdir(path_model+ep+'//')))\n",
    "    for path in paths:\n",
    "        if ep=='epochs100': ep100 = 'epochs100'\n",
    "        key = f'{path[:-15]}'\n",
    "        acc_res[key+ep100]      = np.load(path_model+ep+'//'+path+'//acctest.npy')\n",
    "        acctrain_res[key+ep100] = np.load(path_model+ep+'//'+path+'//acctrain.npy')\n",
    "        err_res[key+ep100]      = np.load(path_model+ep+'//'+path+'//error.npy')\n",
    "        hyp_res[key+ep100]      = np.load(path_model+ep+'//'+path+'//hyperparams.npy',allow_pickle=True)\n",
    "        cm_res[key+ep100]       = np.load(path_model+ep+'//'+path+'//confmat.npy')\n",
    "        # config[key+ep100]       = {'layers': int(architecture[-3]),'units':int(architecture[-1]),\n",
    "        #                             'opt':(lambda x: 'sgd' if 'sgd' in x else 'adam')(key),'epochs': int(ep[6:])}\n",
    "\n",
    "keys = (list(acc_res.keys()))\n",
    "np.array(keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron: 5 units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy with Adam and ANOVA-7 input and 20 epochs: 60.45% \n",
      "Average accuracy with Adam and ANOVA-7 input and 20 epochs: 56.87% \n"
     ]
    }
   ],
   "source": [
    "acc_cvs = np.mean(acc_res['adam_anova10_epochs100epochs100'][:,:,-1],axis=1)\n",
    "print('Best accuracy with Adam and ANOVA-7 input and 20 epochs: {:.2f}% '.format(100*np.max(acc_cvs)))\n",
    "print('Average accuracy with Adam and ANOVA-7 input and 20 epochs: {:.2f}% '.format(100*np.mean(acc_cvs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6227272727272727"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(acc_res['adam_anova10_epochs100epochs100'][:,:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_res['sgd_pca10_epochs20'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam_anova10_epochs5 ------- 59.82% \n",
      "\n",
      "sgd_anova10_epochs5 ------- 57.91% \n",
      "\n",
      "adam_anova10_epochs20 ------- 59.55% \n",
      "\n",
      "sgd_anova10_epochs20 ------- 59.36% \n",
      "\n",
      "adam_anova10_epochs100epochs100 ------- 60.45% \n",
      "\n",
      "adam_anova10_epochs100 ------- 56.45% \n",
      "\n",
      "sgd_anova10_epochs100epochs100 ------- 59.27% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for k in keys:\n",
    "    if 'anova10' in k:\n",
    "        acc_cvs = np.mean(acc_res[k][:,:,-1],axis=1)\n",
    "        print('{} ------- {:.2f}% '.format(k,100*np.max(acc_cvs)))\n",
    "        # print('Average accuracy {}: {:.2f}% '.format(k,100*np.mean(acc_cvs)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of optimizers and dimensional reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xticks   = [k[:-8] for k in keys[:12]]\n",
    "xticks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(2,1,figsize=(13,10),constrained_layout = True)\n",
    "\n",
    "fig.suptitle('Accuracy on experiments',fontsize=18)\n",
    "\n",
    "idx_lim = 6\n",
    "w = 0.25\n",
    "labels = ['5', '20', '100']\n",
    "\n",
    "# ADAM\n",
    "ax1.set_title('Adam models')\n",
    "\n",
    "colors = ['#4EE043','#F3C54F','#64F0F9']\n",
    "for i,ep in enumerate(['_epochs5','_epochs20','_']):\n",
    "    max_values  = [ np.max(acc_res[k+ep][:,:,-1]) for k in xticks[:idx_lim]]\n",
    "    mean_values = [np.mean(acc_res[k+ep][:,:,-1]) for k in xticks[:idx_lim]]\n",
    "    ax1.bar(x=np.arange(idx_lim)+w*i,width=w,height=max_values,\n",
    "                color=colors[i],label=labels[i])\n",
    "\n",
    "ax1.twinx()\n",
    "\n",
    "colors = ['#3CAD34','#B3913B','#5AD7E0']\n",
    "for i,ep in enumerate(['_epochs5','_epochs20','_']):\n",
    "    max_values  = [ np.max(acc_res[k+ep][:,:,-1]) for k in xticks[:idx_lim]]\n",
    "    mean_values = [np.mean(acc_res[k+ep][:,:,-1]) for k in xticks[:idx_lim]]\n",
    "    ax1.bar(x=np.arange(idx_lim)+w*i,width=w,height=mean_values,\n",
    "                color=colors[i])\n",
    "\n",
    "ax1.set_ylabel('accuracy')\n",
    "ax1.set_ylim([0,1])\n",
    "ax1.legend(title='Epochs:')\n",
    "ax1.grid()\n",
    "ax1.set_xticks(ticks=np.arange(6)+w)\n",
    "ax1.set_xticklabels(xticks[:idx_lim],fontsize=12,rotation=25)\n",
    "\n",
    "# SGD\n",
    "ax2.set_title('Stochastic Gradient Descend models')\n",
    "\n",
    "colors = ['#4EE043','#F3C54F','#64F0F9']\n",
    "for i,ep in enumerate(['_epochs5','_epochs20','_']):\n",
    "    max_values  = [ np.max(acc_res[k+ep][:,:,-1]) for k in xticks[idx_lim:]]\n",
    "    mean_values = [np.mean(acc_res[k+ep][:,:,-1]) for k in xticks[idx_lim:]]\n",
    "    ax2.bar(x=np.arange(idx_lim)+w*i,width=w,height=max_values,\n",
    "                color=colors[i],label=labels[i])\n",
    "\n",
    "ax2.twinx()\n",
    "\n",
    "colors = ['#3CAD34','#B3913B','#5AD7E0']\n",
    "for i,ep in enumerate(['_epochs5','_epochs20','_']):\n",
    "    max_values  = [ np.max(acc_res[k+ep][:,:,-1]) for k in xticks[idx_lim:]]\n",
    "    mean_values = [np.mean(acc_res[k+ep][:,:,-1]) for k in xticks[idx_lim:]]\n",
    "    ax2.bar(x=np.arange(idx_lim)+w*i,width=w,height=mean_values,\n",
    "                color=colors[i])\n",
    "\n",
    "ax2.set_ylabel('accuracy')\n",
    "ax2.set_ylim([0,1])\n",
    "# ax2.legend(title='Epochs:')\n",
    "ax2.grid()\n",
    "ax2.set_xticks(ticks=np.arange(6)+w)\n",
    "ax2.set_xticklabels(xticks[idx_lim:],fontsize=12,rotation=25)\n",
    "\n",
    "plt.savefig(path_graphs + 'accuracy_MLP1x5_epochs.jpg', format='jpg', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(2,1,figsize=(13,10),constrained_layout = True)\n",
    "\n",
    "fig.suptitle('Accuracy on experiments',fontsize=18)\n",
    "\n",
    "idx_lim = 6\n",
    "w = 0.25\n",
    "labels = ['5', '20', '100']\n",
    "colors = ['#FF3A1C','#C42D16','#BF5D4E']\n",
    "\n",
    "# ADAM\n",
    "ax1.set_title('Adam models')\n",
    "\n",
    "for i,ep in enumerate(['_epochs5','_epochs20','_']):\n",
    "    max_values  = [ np.min(acc_res[k+ep][:,:,-1]) for k in xticks[:idx_lim]]\n",
    "    ax1.bar(x=np.arange(idx_lim)+w*i,width=w,height=max_values,\n",
    "                color=colors[i],label=labels[i])\n",
    "\n",
    "ax1.set_ylabel('error')\n",
    "ax1.set_ylim([0,0.5])\n",
    "ax1.legend(title='Epochs:')\n",
    "ax1.set_xticks(ticks=np.arange(6)+w)\n",
    "ax1.set_xticklabels(xticks[:idx_lim],fontsize=12,rotation=25)\n",
    "\n",
    "# SGD\n",
    "ax2.set_title('Stochastic Gradient Descend models')\n",
    "\n",
    "for i,ep in enumerate(['_epochs5','_epochs20','_']):\n",
    "    max_values  = [ np.min(acc_res[k+ep][:,:,-1]) for k in xticks[idx_lim:]]\n",
    "    ax2.bar(x=np.arange(idx_lim)+w*i,width=w,height=max_values,\n",
    "                color=colors[i],label=labels[i])\n",
    "\n",
    "ax2.set_ylabel('error')\n",
    "ax2.set_ylim([0,0.5])\n",
    "ax2.set_xticks(ticks=np.arange(6)+w)\n",
    "ax2.set_xticklabels(xticks[idx_lim:],fontsize=12,rotation=25)\n",
    "\n",
    "plt.savefig(path_graphs + 'error_MLP1x5_epochs.jpg', format='jpg', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values  = [ np.max(acc_res[k][:,:,-1]) for k in keys]\n",
    "mean_values = [np.mean(acc_res[k][:,:,-1]) for k in keys]\n",
    "\n",
    "color = ['#1183C4','#17CA45','#0E5F8E','#108C30']\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(2,1,figsize=(11,10),constrained_layout = True)\n",
    "\n",
    "fig.suptitle('Accuracy on experiments',fontsize=18)\n",
    "\n",
    "idx_lim = 13\n",
    "\n",
    "ax1.set_title('Adam models')\n",
    "ax1.bar(x=keys[:idx_lim],height=max_values[:idx_lim],color='#17CA45',label='max value')\n",
    "ax1.twinx()\n",
    "ax1.bar(x=keys[:idx_lim],height=mean_values[:idx_lim],color='#108C30',label='mean value')\n",
    "ax1.set_ylabel('accuracy')\n",
    "ax1.set_ylim([0,1])\n",
    "ax1.legend()\n",
    "ax1.set_xticklabels(keys[:idx_lim],fontsize=9,rotation=25)\n",
    "# ax1.grid()\n",
    "\n",
    "ax2.set_title('SGD models')\n",
    "ax2.bar(x=keys[idx_lim:],height=max_values[idx_lim:],color='#1183C4',label='max value')\n",
    "ax2.twinx()\n",
    "ax2.bar(x=keys[idx_lim:],height=mean_values[idx_lim:],color='#0E5F8E',label='mean value')\n",
    "ax2.set_xlabel('experiments'); ax2.set_ylabel('accuracy')\n",
    "ax2.set_xticklabels(ax2.get_xticks(), rotation = 0)\n",
    "ax2.legend()\n",
    "ax2.set_ylim([0,1])\n",
    "ax2.set_xticklabels(keys[idx_lim:],fontsize=9,rotation=25)\n",
    "# ax2.grid()\n",
    "\n",
    "plt.savefig(path_graphs + 'accuracy_MLP1x5.jpg', format='jpg', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values  = [ np.min(err_res[k][:,:,-1]) for k in keys]\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(2,1,figsize=(11,10),constrained_layout = True)\n",
    "\n",
    "fig.suptitle('Error on experiments',fontsize=18)\n",
    "\n",
    "idx_lim = 13\n",
    "\n",
    "ax1.set_title('Adam models')\n",
    "ax1.bar(x=keys[:idx_lim],height=max_values[:idx_lim],color='#FF1100')\n",
    "ax1.set_ylabel('error')\n",
    "ax1.set_ylim([0,max(max_values)+0.2])\n",
    "ax1.legend()\n",
    "ax1.set_xticklabels(keys[:idx_lim],fontsize=9,rotation=25)\n",
    "# ax1.grid()\n",
    "\n",
    "ax2.set_title('SGD models')\n",
    "ax2.bar(x=keys[idx_lim:],height=max_values[idx_lim:],color='#FF4300')\n",
    "ax2.set_xlabel('experiments'); ax2.set_ylabel('error')\n",
    "ax2.set_xticklabels(ax2.get_xticks(), rotation = 0)\n",
    "ax2.legend()\n",
    "ax2.set_ylim([0,max(max_values)+0.2])\n",
    "ax2.set_xticklabels(keys[idx_lim:],fontsize=9,rotation=25)\n",
    "# ax2.grid()\n",
    "\n",
    "plt.savefig(path_graphs + 'error_MLP1x5.jpg', format='jpg', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot de las mejores ejecuciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos la evolucion del error durante el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "\n",
    "k = 'sgd_varthr14_'\n",
    "print(k)\n",
    "print()\n",
    "\n",
    "plot_results(err_res[k],acctrain_res[k],acc_res[k],cm_res[k],hyp_res[k],k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toplot = []\n",
    "for r,c in zip([41,255,16,241,30],[0,3,4,3,4]):\n",
    "    toplot.append(err_res['adam'][r,c])\n",
    "\n",
    "plot_data = np.array(toplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "\n",
    "color  = ['#FA5C7A','#564FD6','#64EDC2','#CED64F','#FA9D4E']\n",
    "label  = [41,255,16,241,30]\n",
    "\n",
    "for i,p in enumerate(plot_data):\n",
    "    plt.plot(p,color=color[i],label=label[i])\n",
    "\n",
    "plt.title(f'Error Adam')\n",
    "plt.xticks(np.arange(0,101,10))\n",
    "plt.legend(title='Config.')\n",
    "# plt.grid()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('error')\n",
    "plt.ylim([0.2,np.max(plot_data)+np.min(plot_data)-0.2])\n",
    "plt.savefig(path_graphs + f'error_adam.jpg', format='jpg', dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plot de cada hiperparámetro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostraremos unas gráficos de box plot para analizar la influencia de cada hiperparámetro entrenado en el porcentaje de acierto de nuestros modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparacion hiperparámetros (Batch-size, learning rate, scaler...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_array = np.concatenate([acc_res[k][:,:,-1] for k in keys]).reshape(-1)\n",
    "\n",
    "fig, (ax1,ax3,ax4) = plt.subplots(1,3,figsize=(24,6))\n",
    "fig.suptitle('General Hyperparameters Box Plot',fontsize=18)\n",
    "\n",
    "# scalers\n",
    "lr_array  = np.concatenate([hyp_res[k][:,0] for k in keys])\n",
    "lr_array  = np.array([[type(lr),type(lr),type(lr),type(lr),type(lr)] for lr in lr_array]).reshape(-1)\n",
    "assert len(lr_array) == len(acc_array)\n",
    "idxs = [np.where(lr_array == lr) for lr in list(set(lr_array))]\n",
    "plot_data = [acc_array[i] for i in idxs]\n",
    "ax1.boxplot(plot_data)\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Scalers Box Plot')\n",
    "ax1.set_xlabel('Scaler')\n",
    "ax1.set_xticklabels(['MinMax','None Scaler','Normaliz.'])\n",
    "\n",
    "# learning-rate\n",
    "lr_array  = np.concatenate([hyp_res[k][:,2] for k in keys])\n",
    "lr_array  = np.array([np.ones(5)*lr for lr in lr_array]).reshape(-1)\n",
    "assert len(lr_array) == len(acc_array)\n",
    "idxs = [np.where(lr_array == lr) for lr in list(set(lr_array))]\n",
    "plot_data = [acc_array[i] for i in idxs]\n",
    "ax3.boxplot(plot_data)\n",
    "ax3.set_title('Learning rate Box Plot')\n",
    "ax3.set_xlabel('Learning rate')\n",
    "ax3.set_xticklabels(list(set(lr_array)))\n",
    "\n",
    "# batch-size\n",
    "lr_array  = np.concatenate([hyp_res[k][:,-1] for k in keys])\n",
    "lr_array  = np.array([np.ones(5)*lr for lr in lr_array]).reshape(-1)\n",
    "assert len(lr_array) == len(acc_array)\n",
    "idxs = [np.where(lr_array == lr) for lr in list(set(lr_array))]\n",
    "plot_data = [acc_array[i] for i in idxs]\n",
    "ax4.boxplot(plot_data)\n",
    "ax4.set_title('Batch-size Box Plot')\n",
    "ax4.set_xlabel('Batch size')\n",
    "ax4.set_xticklabels(list(set(lr_array)))\n",
    "\n",
    "plt.savefig(path_graphs + f'bxplt_generalhyper.jpg', format='jpg', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparacion optimizador (SGD vs Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = ([np.concatenate([acc_res[k][:,:,-1] for k in keys[:4]]).reshape(-1), \n",
    "                np.concatenate([acc_res[k][:,:,-1] for k in keys[4:]]).reshape(-1)])\n",
    "\n",
    "print(np.array(plot_data).shape)\n",
    "plt.figure(figsize=(4,6))\n",
    "plt.boxplot(plot_data)\n",
    "plt.title('Optimizer Boxplot',fontsize=15)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Optimizer')\n",
    "# plt.grid()\n",
    "plt.xticks(ticks=[1,2],labels=['Adam','Stochastic Gradient Descend'])\n",
    "# plt.savefig(path_graphs + f'bxplt_optimizer.jpg', format='jpg', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparacion de Momentum y Nesterov (para SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_array = np.concatenate([acc_res[k][:,:,-1] for k in keys[:4]]).reshape(-1)\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(13,6))\n",
    "fig.suptitle('SGD Hyperparameters Box Plot',fontsize=18)\n",
    "\n",
    "# momentum\n",
    "lr_array  = np.concatenate([hyp_res[k][:,3] for k in keys[:4]])\n",
    "lr_array  = np.array([np.ones(5)*lr for lr in lr_array]).reshape(-1)\n",
    "assert len(lr_array) == len(acc_array)\n",
    "idxs = [np.where(lr_array == lr) for lr in list(set(lr_array))]\n",
    "plot_data = [acc_array[i] for i in idxs]\n",
    "print(np.array(plot_data).shape)\n",
    "ax1.boxplot(plot_data)\n",
    "ax1.set_title('Momentum Box Plot')\n",
    "ax1.set_xlabel('Momentum')\n",
    "print(type(ax1))\n",
    "ax1.set_xticklabels(list(set(lr_array)))\n",
    "\n",
    "\n",
    "# nesterov\n",
    "lr_array  = np.concatenate([hyp_res[k][:,4] for k in keys[:4]])\n",
    "lr_array  = np.array([np.ones(5)*lr for lr in lr_array]).reshape(-1)\n",
    "assert len(lr_array) == len(acc_array)\n",
    "idxs = [np.where(lr_array == lr) for lr in list(set(lr_array))]\n",
    "plot_data = [acc_array[i] for i in idxs]\n",
    "ax2.boxplot(plot_data)\n",
    "ax2.set_title('Nesterov Box Plot')\n",
    "ax2.set_xlabel('Nesterov')\n",
    "ax2.set_xticklabels(list(set(lr_array)))\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "# plt.savefig(path_graphs + f'bxplt_sgdhyp.jpg', format='jpg', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparacion hyperparámetros Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_array = np.concatenate([acc_res[k][:,:,-1] for k in keys[:4]]).reshape(-1)\n",
    "\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3,figsize=(18,6))\n",
    "fig.suptitle('Adam Hyperparameters Box Plot',fontsize=18)\n",
    "\n",
    "# b1\n",
    "lr_array  = np.concatenate([hyp_res[k][:,3] for k in keys[:4]])\n",
    "lr_array  = np.array([np.ones(5)*lr for lr in lr_array]).reshape(-1)\n",
    "assert len(lr_array) == len(acc_array)\n",
    "idxs = [np.where(lr_array == lr) for lr in list(set(lr_array))]\n",
    "plot_data = [acc_array[i] for i in idxs]\n",
    "ax1.boxplot(plot_data)\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('b1 Box Plot')\n",
    "ax1.set_xlabel('b1')\n",
    "print(type(ax1))\n",
    "ax1.set_xticklabels(list(set(lr_array)))\n",
    "\n",
    "\n",
    "# b2\n",
    "lr_array  = np.concatenate([hyp_res[k][:,4] for k in keys[:4]])\n",
    "lr_array  = np.array([np.ones(5)*lr for lr in lr_array]).reshape(-1)\n",
    "assert len(lr_array) == len(acc_array)\n",
    "idxs = [np.where(lr_array == lr) for lr in list(set(lr_array))]\n",
    "plot_data = [acc_array[i] for i in idxs]\n",
    "print(np.array(plot_data).shape)\n",
    "ax2.boxplot(plot_data)\n",
    "ax2.set_title('b2 Box Plot')\n",
    "ax2.set_xlabel('b2')\n",
    "ax2.set_xticklabels(list(set(lr_array)))\n",
    "\n",
    "# weight_decay\n",
    "lr_array  = np.concatenate([hyp_res[k][:,5] for k in keys[:4]])\n",
    "lr_array  = np.array([np.ones(5)*lr for lr in lr_array]).reshape(-1)\n",
    "assert len(lr_array) == len(acc_array)\n",
    "idxs = [np.where(lr_array == lr) for lr in list(set(lr_array))]\n",
    "plot_data = [acc_array[i] for i in idxs]\n",
    "ax3.boxplot(plot_data)\n",
    "ax3.set_title('Weight decay Box Plot')\n",
    "ax3.set_xlabel('Weight decay')\n",
    "ax3.set_xticklabels(list(set(lr_array)))\n",
    "\n",
    "# plt.savefig(path_graphs + f'bxplt_adamhyp.jpg', format='jpg', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparacion de PCAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(14,6))\n",
    "fig.suptitle('PCA Box Plot',fontsize=18)\n",
    "\n",
    "# SGD\n",
    "plot_data = np.array([acc_res[i][:,:,-1] for i in keys[4:]]).reshape(4,-1)\n",
    "ax1.boxplot(list(plot_data))\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('PCAs with SGD Box Plot')\n",
    "# ax1.set_xlabel('PCA')\n",
    "ax1.set_xticklabels(['No Dim.Reduction','PCA 3','PCA 5','PCA 10'])\n",
    "\n",
    "# ADAM\n",
    "plot_data = np.array([acc_res[i][:,:,-1] for i in keys[:4]]).reshape(4,-1)\n",
    "ax2.boxplot(list(plot_data))\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.set_title('PCAs with Adam Box Plot')\n",
    "# ax2.set_xlabel('PCA')\n",
    "ax2.set_xticklabels(['No Dim.Reduction','PCA 3','PCA 5','PCA 10'])\n",
    "\n",
    "plt.savefig(path_graphs + f'bxplt_sgdvsadam.jpg', format='jpg', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparacion Batch-Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sobre Batch-Normalization:\n",
    "\n",
    "https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_values  = [ np.max(acc_res[k][:,:,-1]) for k in np.array(keys)[[4,5,6]]]\n",
    "mean_values = [np.mean(acc_res[k][:,:,-1]) for k in np.array(keys)[[4,5,6]]]\n",
    "\n",
    "# color = ['#D14444','#B5189D','#6F2424','#630E56']\n",
    "# color = ['#1183C4','#17CA45','#0E5F8E','#108C30']\n",
    "\n",
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(10,6))\n",
    "\n",
    "fig.suptitle('Accuracy on experiments based on Batch-normalization',fontsize=18)\n",
    "ax1.set_title('Max Accuracy')\n",
    "ax1.bar(x=list(np.array(keys)[[4,5,6]]),height=max_values,color='#D14444')\n",
    "ax1.set_xlabel('experiments'); ax1.set_ylabel('accuracy')\n",
    "ax1.set_ylim([0,1])\n",
    "ax1.set_xticklabels(['BN 1', 'BN 2', 'No BN'],fontsize=8)\n",
    "\n",
    "ax2.set_title('Mean Accuracy')\n",
    "ax2.bar(x=list(np.array(keys)[[4,5,6]]),height=mean_values,color='#6F2424')\n",
    "ax2.set_xticklabels(ax2.get_xticks(), rotation = 0)\n",
    "ax2.set_ylim([0,1])\n",
    "ax2.set_xticklabels(['BN 1', 'BN 2', 'No BN'],fontsize=8)\n",
    "\n",
    "plt.savefig(path_graphs + 'accuracy_expBatchNorm.jpg', format='jpg', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = [acc_res[k][:,:,-1].reshape(-1) for k in np.array(keys)[[4,5,6]]]\n",
    "plt.figure(figsize=(9,7))\n",
    "plt.boxplot(plot_data)\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Batch-normalization')\n",
    "plt.xticks(ticks=[1,2,3],labels=['BN 1', 'BN 2', 'No BN'])\n",
    "plt.title('Batch-Normalization Box Plot')\n",
    "plt.savefig(path_graphs + f'bxplt_batchnorm.jpg', format='jpg', dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparacion Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuales son los mejores modelos para predecir empates? O para predecir que gana el visitante?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podrá ser útil en un futuro, cuando intentemos hacer un modelo basándonos en la técnica de bagging con varias redes entrenadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron: 3 units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparacion of optimizers and dimensional reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depuracion entrenamiento Red Neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a depurar el entrenamiento de nuestro modelo para intentar identificar las causas por las cuales no aprende correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('tfg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "288ff6fe8157f43ba3e1fb4cfa0011490e9beb907b54ad0d71ae70a61946bdb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
