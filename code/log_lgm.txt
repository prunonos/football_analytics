INFO: start
['side_avg_15D_home' 'Scored_15D_home' 'Received_15D_home'
 'points_15D_home' 'side_avg_15D_away' 'Scored_15D_away'
 'Received_15D_away' 'points_15D_away' 'side_avg_30D_home'
 'Scored_30D_home' 'Received_30D_home' 'points_30D_home'
 'side_avg_30D_away' 'Scored_30D_away' 'Received_30D_away'
 'points_30D_away' 'side_avg_60D_home' 'Scored_60D_home'
 'Received_60D_home' 'points_60D_home' 'side_avg_60D_away'
 'Scored_60D_away' 'Received_60D_away' 'points_60D_away'
 'side_avg_180D_home' 'Scored_180D_home' 'Received_180D_home'
 'points_180D_home' 'side_avg_180D_away' 'Scored_180D_away'
 'Received_180D_away' 'points_180D_away' 'side_avg_365D_home'
 'Scored_365D_home' 'Received_365D_home' 'points_365D_home'
 'side_avg_365D_away' 'Scored_365D_away' 'Received_365D_away'
 'points_365D_away' 'side_avg_730D_home' 'Scored_730D_home'
 'Received_730D_home' 'points_730D_home' 'side_avg_730D_away'
 'Scored_730D_away' 'Received_730D_away' 'points_730D_away'
 'side_avg_1825D_home' 'Scored_1825D_home' 'Received_1825D_home'
 'points_1825D_home' 'side_avg_1825D_away' 'Scored_1825D_away'
 'Received_1825D_away' 'points_1825D_away' 'derby_Scored_1_home'
 'derby_Side_1_home' 'derby_points_1_home' 'derby_Scored_1_away'
 'derby_Side_1_away' 'derby_points_1_away' 'derby_Scored_3_home'
 'derby_Side_3_home' 'derby_points_3_home' 'derby_Scored_3_away'
 'derby_Side_3_away' 'derby_points_3_away' 'derby_Scored_5_home'
 'derby_Side_5_home' 'derby_points_5_home' 'derby_Scored_5_away'
 'derby_Side_5_away' 'derby_points_5_away' 'derby_Scored_10_home'
 'derby_Side_10_home' 'derby_points_10_home' 'derby_Scored_10_away'
 'derby_Side_10_away' 'derby_points_10_away']
(11895, 80) (11895, 80)
(9519, 50)
(2376, 50)
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.19045	validation's multi_logloss: 1.19016
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17692	validation's multi_logloss: 1.17664
[3]	training's multi_logloss: 1.16474	validation's multi_logloss: 1.16403
[4]	training's multi_logloss: 1.15372	validation's multi_logloss: 1.15243
[5]	training's multi_logloss: 1.14414	validation's multi_logloss: 1.14278
[6]	training's multi_logloss: 1.13469	validation's multi_logloss: 1.13334
[7]	training's multi_logloss: 1.13469	validation's multi_logloss: 1.13334
[8]	training's multi_logloss: 1.12637	validation's multi_logloss: 1.12465
[9]	training's multi_logloss: 1.12289	validation's multi_logloss: 1.12117
[10]	training's multi_logloss: 1.12289	validation's multi_logloss: 1.12117
[11]	training's multi_logloss: 1.12289	validation's multi_logloss: 1.12117
[12]	training's multi_logloss: 1.12289	validation's multi_logloss: 1.12117
[13]	training's multi_logloss: 1.11519	validation's multi_logloss: 1.11328
[14]	training's multi_logloss: 1.11274	validation's multi_logloss: 1.11068
[15]	training's multi_logloss: 1.11274	validation's multi_logloss: 1.11068
[16]	training's multi_logloss: 1.11016	validation's multi_logloss: 1.10785
[17]	training's multi_logloss: 1.10581	validation's multi_logloss: 1.10339
[18]	training's multi_logloss: 1.10344	validation's multi_logloss: 1.10146
[19]	training's multi_logloss: 1.10344	validation's multi_logloss: 1.10146
[20]	training's multi_logloss: 1.10344	validation's multi_logloss: 1.10146
[21]	training's multi_logloss: 1.10344	validation's multi_logloss: 1.10146
[22]	training's multi_logloss: 1.10344	validation's multi_logloss: 1.10146
[23]	training's multi_logloss: 1.10344	validation's multi_logloss: 1.10146
[24]	training's multi_logloss: 1.10105	validation's multi_logloss: 1.0988
[25]	training's multi_logloss: 1.10105	validation's multi_logloss: 1.0988
[26]	training's multi_logloss: 1.10105	validation's multi_logloss: 1.0988
[27]	training's multi_logloss: 1.10105	validation's multi_logloss: 1.0988
[28]	training's multi_logloss: 1.10105	validation's multi_logloss: 1.0988
[29]	training's multi_logloss: 1.10105	validation's multi_logloss: 1.0988
[30]	training's multi_logloss: 1.10105	validation's multi_logloss: 1.0988
[31]	training's multi_logloss: 1.10105	validation's multi_logloss: 1.0988
[32]	training's multi_logloss: 1.10105	validation's multi_logloss: 1.0988
[33]	training's multi_logloss: 1.10105	validation's multi_logloss: 1.0988
[34]	training's multi_logloss: 1.10105	validation's multi_logloss: 1.0988
Early stopping, best iteration is:
[24]	training's multi_logloss: 1.10105	validation's multi_logloss: 1.0988
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.19134	validation's multi_logloss: 1.19186
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17846	validation's multi_logloss: 1.17865
[3]	training's multi_logloss: 1.16553	validation's multi_logloss: 1.16607
[4]	training's multi_logloss: 1.15513	validation's multi_logloss: 1.15579
[5]	training's multi_logloss: 1.14584	validation's multi_logloss: 1.14608
[6]	training's multi_logloss: 1.13671	validation's multi_logloss: 1.13598
[7]	training's multi_logloss: 1.13339	validation's multi_logloss: 1.13242
[8]	training's multi_logloss: 1.12525	validation's multi_logloss: 1.12396
[9]	training's multi_logloss: 1.12229	validation's multi_logloss: 1.12117
[10]	training's multi_logloss: 1.11814	validation's multi_logloss: 1.11752
[11]	training's multi_logloss: 1.11814	validation's multi_logloss: 1.11752
[12]	training's multi_logloss: 1.11814	validation's multi_logloss: 1.11752
[13]	training's multi_logloss: 1.11333	validation's multi_logloss: 1.11236
[14]	training's multi_logloss: 1.10959	validation's multi_logloss: 1.10854
[15]	training's multi_logloss: 1.10248	validation's multi_logloss: 1.10124
[16]	training's multi_logloss: 1.10248	validation's multi_logloss: 1.10124
[17]	training's multi_logloss: 1.09929	validation's multi_logloss: 1.09771
[18]	training's multi_logloss: 1.09929	validation's multi_logloss: 1.09771
[19]	training's multi_logloss: 1.09929	validation's multi_logloss: 1.09771
[20]	training's multi_logloss: 1.09929	validation's multi_logloss: 1.09771
[21]	training's multi_logloss: 1.09929	validation's multi_logloss: 1.09771
[22]	training's multi_logloss: 1.09929	validation's multi_logloss: 1.09771
[23]	training's multi_logloss: 1.09929	validation's multi_logloss: 1.09771
[24]	training's multi_logloss: 1.09929	validation's multi_logloss: 1.09771
[25]	training's multi_logloss: 1.09929	validation's multi_logloss: 1.09771
[26]	training's multi_logloss: 1.09929	validation's multi_logloss: 1.09771
[27]	training's multi_logloss: 1.09929	validation's multi_logloss: 1.09771
Early stopping, best iteration is:
[17]	training's multi_logloss: 1.09929	validation's multi_logloss: 1.09771
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.19148	validation's multi_logloss: 1.19226
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17686	validation's multi_logloss: 1.17888
[3]	training's multi_logloss: 1.16482	validation's multi_logloss: 1.16742
[4]	training's multi_logloss: 1.15468	validation's multi_logloss: 1.15774
[5]	training's multi_logloss: 1.14405	validation's multi_logloss: 1.14758
[6]	training's multi_logloss: 1.13546	validation's multi_logloss: 1.14002
[7]	training's multi_logloss: 1.13169	validation's multi_logloss: 1.13635
[8]	training's multi_logloss: 1.12266	validation's multi_logloss: 1.12794
[9]	training's multi_logloss: 1.11446	validation's multi_logloss: 1.12006
[10]	training's multi_logloss: 1.11052	validation's multi_logloss: 1.11692
[11]	training's multi_logloss: 1.10774	validation's multi_logloss: 1.11408
[12]	training's multi_logloss: 1.10328	validation's multi_logloss: 1.11011
[13]	training's multi_logloss: 1.10028	validation's multi_logloss: 1.10705
[14]	training's multi_logloss: 1.09606	validation's multi_logloss: 1.10279
[15]	training's multi_logloss: 1.09606	validation's multi_logloss: 1.10279
[16]	training's multi_logloss: 1.0929	validation's multi_logloss: 1.09968
[17]	training's multi_logloss: 1.0929	validation's multi_logloss: 1.09968
[18]	training's multi_logloss: 1.0929	validation's multi_logloss: 1.09968
[19]	training's multi_logloss: 1.0929	validation's multi_logloss: 1.09968
[20]	training's multi_logloss: 1.0929	validation's multi_logloss: 1.09968
[21]	training's multi_logloss: 1.0929	validation's multi_logloss: 1.09968
[22]	training's multi_logloss: 1.0929	validation's multi_logloss: 1.09968
[23]	training's multi_logloss: 1.0929	validation's multi_logloss: 1.09968
[24]	training's multi_logloss: 1.0929	validation's multi_logloss: 1.09968
[25]	training's multi_logloss: 1.09016	validation's multi_logloss: 1.09736
[26]	training's multi_logloss: 1.09016	validation's multi_logloss: 1.09736
[27]	training's multi_logloss: 1.09016	validation's multi_logloss: 1.09736
[28]	training's multi_logloss: 1.09016	validation's multi_logloss: 1.09736
[29]	training's multi_logloss: 1.09016	validation's multi_logloss: 1.09736
[30]	training's multi_logloss: 1.09016	validation's multi_logloss: 1.09736
[31]	training's multi_logloss: 1.09016	validation's multi_logloss: 1.09736
[32]	training's multi_logloss: 1.09016	validation's multi_logloss: 1.09736
[33]	training's multi_logloss: 1.0877	validation's multi_logloss: 1.09511
[34]	training's multi_logloss: 1.0877	validation's multi_logloss: 1.09511
[35]	training's multi_logloss: 1.0877	validation's multi_logloss: 1.09511
[36]	training's multi_logloss: 1.0877	validation's multi_logloss: 1.09511
[37]	training's multi_logloss: 1.0877	validation's multi_logloss: 1.09511
[38]	training's multi_logloss: 1.0877	validation's multi_logloss: 1.09511
[39]	training's multi_logloss: 1.0877	validation's multi_logloss: 1.09511
[40]	training's multi_logloss: 1.0877	validation's multi_logloss: 1.09511
[41]	training's multi_logloss: 1.0877	validation's multi_logloss: 1.09511
[42]	training's multi_logloss: 1.0877	validation's multi_logloss: 1.09511
[43]	training's multi_logloss: 1.0877	validation's multi_logloss: 1.09511
Early stopping, best iteration is:
[33]	training's multi_logloss: 1.0877	validation's multi_logloss: 1.09511
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18919	validation's multi_logloss: 1.18932
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17607	validation's multi_logloss: 1.17676
[3]	training's multi_logloss: 1.16424	validation's multi_logloss: 1.16571
[4]	training's multi_logloss: 1.15367	validation's multi_logloss: 1.1558
[5]	training's multi_logloss: 1.14405	validation's multi_logloss: 1.14704
[6]	training's multi_logloss: 1.1357	validation's multi_logloss: 1.13884
[7]	training's multi_logloss: 1.12788	validation's multi_logloss: 1.13111
[8]	training's multi_logloss: 1.12245	validation's multi_logloss: 1.12619
[9]	training's multi_logloss: 1.1193	validation's multi_logloss: 1.12307
[10]	training's multi_logloss: 1.11182	validation's multi_logloss: 1.11634
[11]	training's multi_logloss: 1.11182	validation's multi_logloss: 1.11634
[12]	training's multi_logloss: 1.10835	validation's multi_logloss: 1.1136
[13]	training's multi_logloss: 1.10507	validation's multi_logloss: 1.1107
[14]	training's multi_logloss: 1.10507	validation's multi_logloss: 1.1107
[15]	training's multi_logloss: 1.10507	validation's multi_logloss: 1.1107
[16]	training's multi_logloss: 1.10167	validation's multi_logloss: 1.10762
[17]	training's multi_logloss: 1.10167	validation's multi_logloss: 1.10762
[18]	training's multi_logloss: 1.09805	validation's multi_logloss: 1.10391
[19]	training's multi_logloss: 1.09492	validation's multi_logloss: 1.10075
[20]	training's multi_logloss: 1.09492	validation's multi_logloss: 1.10075
[21]	training's multi_logloss: 1.09492	validation's multi_logloss: 1.10075
[22]	training's multi_logloss: 1.09492	validation's multi_logloss: 1.10075
[23]	training's multi_logloss: 1.09114	validation's multi_logloss: 1.09728
[24]	training's multi_logloss: 1.09114	validation's multi_logloss: 1.09728
[25]	training's multi_logloss: 1.09114	validation's multi_logloss: 1.09728
[26]	training's multi_logloss: 1.09114	validation's multi_logloss: 1.09728
[27]	training's multi_logloss: 1.09114	validation's multi_logloss: 1.09728
[28]	training's multi_logloss: 1.09114	validation's multi_logloss: 1.09728
[29]	training's multi_logloss: 1.09114	validation's multi_logloss: 1.09728
[30]	training's multi_logloss: 1.09114	validation's multi_logloss: 1.09728
[31]	training's multi_logloss: 1.09114	validation's multi_logloss: 1.09728
[32]	training's multi_logloss: 1.09114	validation's multi_logloss: 1.09728
[33]	training's multi_logloss: 1.09114	validation's multi_logloss: 1.09728
Early stopping, best iteration is:
[23]	training's multi_logloss: 1.09114	validation's multi_logloss: 1.09728
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=6000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6000
[LightGBM] [Warning] min_gain_to_split is set=4.267286556301382, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.267286556301382
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=6000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6000
[LightGBM] [Warning] min_gain_to_split is set=4.267286556301382, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.267286556301382
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=6000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6000
[LightGBM] [Warning] min_gain_to_split is set=4.267286556301382, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.267286556301382
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=6000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6000
[LightGBM] [Warning] min_gain_to_split is set=4.267286556301382, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.267286556301382
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=6600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6600
[LightGBM] [Warning] min_gain_to_split is set=10.656731014243222, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.656731014243222
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=6600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6600
[LightGBM] [Warning] min_gain_to_split is set=10.656731014243222, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.656731014243222
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=6600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6600
[LightGBM] [Warning] min_gain_to_split is set=10.656731014243222, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.656731014243222
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=6600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6600
[LightGBM] [Warning] min_gain_to_split is set=10.656731014243222, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.656731014243222
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=5600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5600
[LightGBM] [Warning] min_gain_to_split is set=2.8725355651365425, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.8725355651365425
[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=5600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5600
[LightGBM] [Warning] min_gain_to_split is set=2.8725355651365425, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.8725355651365425
[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=5600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5600
[LightGBM] [Warning] min_gain_to_split is set=2.8725355651365425, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.8725355651365425
[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=5600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5600
[LightGBM] [Warning] min_gain_to_split is set=2.8725355651365425, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=2.8725355651365425
[LightGBM] [Warning] lambda_l1 is set=20, reg_alpha=0.0 will be ignored. Current value: lambda_l1=20
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=2500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2500
[LightGBM] [Warning] min_gain_to_split is set=8.853858478848641, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.853858478848641
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=2500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2500
[LightGBM] [Warning] min_gain_to_split is set=8.853858478848641, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.853858478848641
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=2500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2500
[LightGBM] [Warning] min_gain_to_split is set=8.853858478848641, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.853858478848641
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=2500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2500
[LightGBM] [Warning] min_gain_to_split is set=8.853858478848641, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.853858478848641
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=6500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6500
[LightGBM] [Warning] min_gain_to_split is set=8.154696954804486, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.154696954804486
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=6500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6500
[LightGBM] [Warning] min_gain_to_split is set=8.154696954804486, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.154696954804486
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=6500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6500
[LightGBM] [Warning] min_gain_to_split is set=8.154696954804486, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.154696954804486
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=6500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6500
[LightGBM] [Warning] min_gain_to_split is set=8.154696954804486, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.154696954804486
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=1500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1500
[LightGBM] [Warning] min_gain_to_split is set=8.628428682208202, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=8.628428682208202
[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=3900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3900
[LightGBM] [Warning] min_gain_to_split is set=7.126216111348876, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.126216111348876
[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=3900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3900
[LightGBM] [Warning] min_gain_to_split is set=7.126216111348876, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.126216111348876
[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=3900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3900
[LightGBM] [Warning] min_gain_to_split is set=7.126216111348876, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.126216111348876
[LightGBM] [Warning] lambda_l1 is set=95, reg_alpha=0.0 will be ignored. Current value: lambda_l1=95
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=5, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=6200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6200
[LightGBM] [Warning] min_gain_to_split is set=4.1776258476039505, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.1776258476039505
[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=6200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6200
[LightGBM] [Warning] min_gain_to_split is set=4.1776258476039505, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.1776258476039505
[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=6200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6200
[LightGBM] [Warning] min_gain_to_split is set=4.1776258476039505, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.1776258476039505
[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=6200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=6200
[LightGBM] [Warning] min_gain_to_split is set=4.1776258476039505, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=4.1776258476039505
[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=7100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7100
[LightGBM] [Warning] min_gain_to_split is set=7.0974843079728505, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.0974843079728505
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=7100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7100
[LightGBM] [Warning] min_gain_to_split is set=7.0974843079728505, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.0974843079728505
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=7100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7100
[LightGBM] [Warning] min_gain_to_split is set=7.0974843079728505, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.0974843079728505
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.2, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.2
[LightGBM] [Warning] min_data_in_leaf is set=7100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7100
[LightGBM] [Warning] min_gain_to_split is set=7.0974843079728505, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=7.0974843079728505
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400
[LightGBM] [Warning] min_gain_to_split is set=12.970815238476968, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.970815238476968
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400
[LightGBM] [Warning] min_gain_to_split is set=12.970815238476968, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.970815238476968
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400
[LightGBM] [Warning] min_gain_to_split is set=12.970815238476968, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.970815238476968
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=9400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=9400
[LightGBM] [Warning] min_gain_to_split is set=12.970815238476968, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.970815238476968
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300
[LightGBM] [Warning] min_gain_to_split is set=14.80150008802974, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.80150008802974
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08608	validation's multi_logloss: 1.08551
[3]	training's multi_logloss: 1.07671	validation's multi_logloss: 1.0762
[4]	training's multi_logloss: 1.0683	validation's multi_logloss: 1.06766
[5]	training's multi_logloss: 1.06188	validation's multi_logloss: 1.06094
[6]	training's multi_logloss: 1.06188	validation's multi_logloss: 1.06094
[7]	training's multi_logloss: 1.06188	validation's multi_logloss: 1.06094
[8]	training's multi_logloss: 1.06188	validation's multi_logloss: 1.06094
[9]	training's multi_logloss: 1.06188	validation's multi_logloss: 1.06094
[10]	training's multi_logloss: 1.06188	validation's multi_logloss: 1.06094
[11]	training's multi_logloss: 1.06188	validation's multi_logloss: 1.06094
[12]	training's multi_logloss: 1.06188	validation's multi_logloss: 1.06094
[13]	training's multi_logloss: 1.06188	validation's multi_logloss: 1.06094
[14]	training's multi_logloss: 1.06188	validation's multi_logloss: 1.06094
[15]	training's multi_logloss: 1.06188	validation's multi_logloss: 1.06094
Early stopping, best iteration is:
[5]	training's multi_logloss: 1.06188	validation's multi_logloss: 1.06094
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300
[LightGBM] [Warning] min_gain_to_split is set=14.80150008802974, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.80150008802974
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.0879	validation's multi_logloss: 1.08772
[3]	training's multi_logloss: 1.07809	validation's multi_logloss: 1.07786
[4]	training's multi_logloss: 1.07809	validation's multi_logloss: 1.07786
[5]	training's multi_logloss: 1.07809	validation's multi_logloss: 1.07786
[6]	training's multi_logloss: 1.07809	validation's multi_logloss: 1.07786
[7]	training's multi_logloss: 1.07809	validation's multi_logloss: 1.07786
[8]	training's multi_logloss: 1.07809	validation's multi_logloss: 1.07786
[9]	training's multi_logloss: 1.07809	validation's multi_logloss: 1.07786
[10]	training's multi_logloss: 1.07809	validation's multi_logloss: 1.07786
[11]	training's multi_logloss: 1.07809	validation's multi_logloss: 1.07786
[12]	training's multi_logloss: 1.07809	validation's multi_logloss: 1.07786
[13]	training's multi_logloss: 1.06979	validation's multi_logloss: 1.06978
[14]	training's multi_logloss: 1.06979	validation's multi_logloss: 1.06978
[15]	training's multi_logloss: 1.06979	validation's multi_logloss: 1.06978
[16]	training's multi_logloss: 1.06979	validation's multi_logloss: 1.06978
[17]	training's multi_logloss: 1.06258	validation's multi_logloss: 1.06245
[18]	training's multi_logloss: 1.06258	validation's multi_logloss: 1.06245
[19]	training's multi_logloss: 1.06258	validation's multi_logloss: 1.06245
[20]	training's multi_logloss: 1.06258	validation's multi_logloss: 1.06245
[21]	training's multi_logloss: 1.06258	validation's multi_logloss: 1.06245
[22]	training's multi_logloss: 1.06258	validation's multi_logloss: 1.06245
[23]	training's multi_logloss: 1.06258	validation's multi_logloss: 1.06245
[24]	training's multi_logloss: 1.06258	validation's multi_logloss: 1.06245
[25]	training's multi_logloss: 1.06258	validation's multi_logloss: 1.06245
[26]	training's multi_logloss: 1.06258	validation's multi_logloss: 1.06245
[27]	training's multi_logloss: 1.06258	validation's multi_logloss: 1.06245
Early stopping, best iteration is:
[17]	training's multi_logloss: 1.06258	validation's multi_logloss: 1.06245
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300
[LightGBM] [Warning] min_gain_to_split is set=14.80150008802974, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.80150008802974
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08672	validation's multi_logloss: 1.08774
[3]	training's multi_logloss: 1.08672	validation's multi_logloss: 1.08774
[4]	training's multi_logloss: 1.07604	validation's multi_logloss: 1.07779
[5]	training's multi_logloss: 1.07604	validation's multi_logloss: 1.07779
[6]	training's multi_logloss: 1.06718	validation's multi_logloss: 1.06998
[7]	training's multi_logloss: 1.06718	validation's multi_logloss: 1.06998
[8]	training's multi_logloss: 1.06718	validation's multi_logloss: 1.06998
[9]	training's multi_logloss: 1.06718	validation's multi_logloss: 1.06998
[10]	training's multi_logloss: 1.06718	validation's multi_logloss: 1.06998
[11]	training's multi_logloss: 1.06718	validation's multi_logloss: 1.06998
[12]	training's multi_logloss: 1.06718	validation's multi_logloss: 1.06998
[13]	training's multi_logloss: 1.06718	validation's multi_logloss: 1.06998
[14]	training's multi_logloss: 1.06718	validation's multi_logloss: 1.06998
[15]	training's multi_logloss: 1.06718	validation's multi_logloss: 1.06998
[16]	training's multi_logloss: 1.06718	validation's multi_logloss: 1.06998
Early stopping, best iteration is:
[6]	training's multi_logloss: 1.06718	validation's multi_logloss: 1.06998
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=300
[LightGBM] [Warning] min_gain_to_split is set=14.80150008802974, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.80150008802974
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08766	validation's multi_logloss: 1.0876
[3]	training's multi_logloss: 1.0773	validation's multi_logloss: 1.07767
[4]	training's multi_logloss: 1.0773	validation's multi_logloss: 1.07767
[5]	training's multi_logloss: 1.0773	validation's multi_logloss: 1.07767
[6]	training's multi_logloss: 1.0773	validation's multi_logloss: 1.07767
[7]	training's multi_logloss: 1.0773	validation's multi_logloss: 1.07767
[8]	training's multi_logloss: 1.0773	validation's multi_logloss: 1.07767
[9]	training's multi_logloss: 1.0773	validation's multi_logloss: 1.07767
[10]	training's multi_logloss: 1.0773	validation's multi_logloss: 1.07767
[11]	training's multi_logloss: 1.0773	validation's multi_logloss: 1.07767
[12]	training's multi_logloss: 1.0773	validation's multi_logloss: 1.07767
[13]	training's multi_logloss: 1.06762	validation's multi_logloss: 1.06766
[14]	training's multi_logloss: 1.06762	validation's multi_logloss: 1.06766
[15]	training's multi_logloss: 1.06762	validation's multi_logloss: 1.06766
[16]	training's multi_logloss: 1.06762	validation's multi_logloss: 1.06766
[17]	training's multi_logloss: 1.06762	validation's multi_logloss: 1.06766
[18]	training's multi_logloss: 1.06762	validation's multi_logloss: 1.06766
[19]	training's multi_logloss: 1.06762	validation's multi_logloss: 1.06766
[20]	training's multi_logloss: 1.06762	validation's multi_logloss: 1.06766
[21]	training's multi_logloss: 1.06762	validation's multi_logloss: 1.06766
[22]	training's multi_logloss: 1.06762	validation's multi_logloss: 1.06766
[23]	training's multi_logloss: 1.06762	validation's multi_logloss: 1.06766
Early stopping, best iteration is:
[13]	training's multi_logloss: 1.06762	validation's multi_logloss: 1.06766
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400
[LightGBM] [Warning] min_gain_to_split is set=14.50065374814284, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.50065374814284
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08534	validation's multi_logloss: 1.08474
[3]	training's multi_logloss: 1.07562	validation's multi_logloss: 1.07482
[4]	training's multi_logloss: 1.06698	validation's multi_logloss: 1.06603
[5]	training's multi_logloss: 1.06698	validation's multi_logloss: 1.06603
[6]	training's multi_logloss: 1.06698	validation's multi_logloss: 1.06603
[7]	training's multi_logloss: 1.06698	validation's multi_logloss: 1.06603
[8]	training's multi_logloss: 1.06698	validation's multi_logloss: 1.06603
[9]	training's multi_logloss: 1.06698	validation's multi_logloss: 1.06603
[10]	training's multi_logloss: 1.06698	validation's multi_logloss: 1.06603
[11]	training's multi_logloss: 1.06698	validation's multi_logloss: 1.06603
[12]	training's multi_logloss: 1.06698	validation's multi_logloss: 1.06603
[13]	training's multi_logloss: 1.06698	validation's multi_logloss: 1.06603
[14]	training's multi_logloss: 1.06698	validation's multi_logloss: 1.06603
Early stopping, best iteration is:
[4]	training's multi_logloss: 1.06698	validation's multi_logloss: 1.06603
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400
[LightGBM] [Warning] min_gain_to_split is set=14.50065374814284, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.50065374814284
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08726	validation's multi_logloss: 1.08706
[3]	training's multi_logloss: 1.07705	validation's multi_logloss: 1.07682
[4]	training's multi_logloss: 1.07705	validation's multi_logloss: 1.07682
[5]	training's multi_logloss: 1.07705	validation's multi_logloss: 1.07682
[6]	training's multi_logloss: 1.07705	validation's multi_logloss: 1.07682
[7]	training's multi_logloss: 1.07705	validation's multi_logloss: 1.07682
[8]	training's multi_logloss: 1.07705	validation's multi_logloss: 1.07682
[9]	training's multi_logloss: 1.07705	validation's multi_logloss: 1.07682
[10]	training's multi_logloss: 1.07705	validation's multi_logloss: 1.07682
[11]	training's multi_logloss: 1.07705	validation's multi_logloss: 1.07682
[12]	training's multi_logloss: 1.07705	validation's multi_logloss: 1.07682
[13]	training's multi_logloss: 1.06856	validation's multi_logloss: 1.06855
[14]	training's multi_logloss: 1.06856	validation's multi_logloss: 1.06855
[15]	training's multi_logloss: 1.06856	validation's multi_logloss: 1.06855
[16]	training's multi_logloss: 1.06856	validation's multi_logloss: 1.06855
[17]	training's multi_logloss: 1.06129	validation's multi_logloss: 1.06114
[18]	training's multi_logloss: 1.06129	validation's multi_logloss: 1.06114
[19]	training's multi_logloss: 1.06129	validation's multi_logloss: 1.06114
[20]	training's multi_logloss: 1.06129	validation's multi_logloss: 1.06114
[21]	training's multi_logloss: 1.06129	validation's multi_logloss: 1.06114
[22]	training's multi_logloss: 1.06129	validation's multi_logloss: 1.06114
[23]	training's multi_logloss: 1.06129	validation's multi_logloss: 1.06114
[24]	training's multi_logloss: 1.06129	validation's multi_logloss: 1.06114
[25]	training's multi_logloss: 1.06129	validation's multi_logloss: 1.06114
[26]	training's multi_logloss: 1.06129	validation's multi_logloss: 1.06114
[27]	training's multi_logloss: 1.06129	validation's multi_logloss: 1.06114
Early stopping, best iteration is:
[17]	training's multi_logloss: 1.06129	validation's multi_logloss: 1.06114
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400
[LightGBM] [Warning] min_gain_to_split is set=14.50065374814284, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.50065374814284
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08601	validation's multi_logloss: 1.0871
[3]	training's multi_logloss: 1.08601	validation's multi_logloss: 1.0871
[4]	training's multi_logloss: 1.07538	validation's multi_logloss: 1.07701
[5]	training's multi_logloss: 1.07538	validation's multi_logloss: 1.07701
[6]	training's multi_logloss: 1.07538	validation's multi_logloss: 1.07701
[7]	training's multi_logloss: 1.07538	validation's multi_logloss: 1.07701
[8]	training's multi_logloss: 1.07538	validation's multi_logloss: 1.07701
[9]	training's multi_logloss: 1.06665	validation's multi_logloss: 1.06915
[10]	training's multi_logloss: 1.06665	validation's multi_logloss: 1.06915
[11]	training's multi_logloss: 1.06665	validation's multi_logloss: 1.06915
[12]	training's multi_logloss: 1.06665	validation's multi_logloss: 1.06915
[13]	training's multi_logloss: 1.06665	validation's multi_logloss: 1.06915
[14]	training's multi_logloss: 1.06665	validation's multi_logloss: 1.06915
[15]	training's multi_logloss: 1.06665	validation's multi_logloss: 1.06915
[16]	training's multi_logloss: 1.06665	validation's multi_logloss: 1.06915
[17]	training's multi_logloss: 1.06665	validation's multi_logloss: 1.06915
[18]	training's multi_logloss: 1.06665	validation's multi_logloss: 1.06915
[19]	training's multi_logloss: 1.06665	validation's multi_logloss: 1.06915
Early stopping, best iteration is:
[9]	training's multi_logloss: 1.06665	validation's multi_logloss: 1.06915
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=400
[LightGBM] [Warning] min_gain_to_split is set=14.50065374814284, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.50065374814284
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.087	validation's multi_logloss: 1.08692
[3]	training's multi_logloss: 1.07623	validation's multi_logloss: 1.0766
[4]	training's multi_logloss: 1.07623	validation's multi_logloss: 1.0766
[5]	training's multi_logloss: 1.07623	validation's multi_logloss: 1.0766
[6]	training's multi_logloss: 1.07623	validation's multi_logloss: 1.0766
[7]	training's multi_logloss: 1.07623	validation's multi_logloss: 1.0766
[8]	training's multi_logloss: 1.07623	validation's multi_logloss: 1.0766
[9]	training's multi_logloss: 1.07623	validation's multi_logloss: 1.0766
[10]	training's multi_logloss: 1.07623	validation's multi_logloss: 1.0766
[11]	training's multi_logloss: 1.07623	validation's multi_logloss: 1.0766
[12]	training's multi_logloss: 1.07623	validation's multi_logloss: 1.0766
[13]	training's multi_logloss: 1.06631	validation's multi_logloss: 1.06634
[14]	training's multi_logloss: 1.06631	validation's multi_logloss: 1.06634
[15]	training's multi_logloss: 1.06631	validation's multi_logloss: 1.06634
[16]	training's multi_logloss: 1.06631	validation's multi_logloss: 1.06634
[17]	training's multi_logloss: 1.06631	validation's multi_logloss: 1.06634
[18]	training's multi_logloss: 1.06631	validation's multi_logloss: 1.06634
[19]	training's multi_logloss: 1.06631	validation's multi_logloss: 1.06634
[20]	training's multi_logloss: 1.06631	validation's multi_logloss: 1.06634
[21]	training's multi_logloss: 1.06631	validation's multi_logloss: 1.06634
[22]	training's multi_logloss: 1.06631	validation's multi_logloss: 1.06634
[23]	training's multi_logloss: 1.06631	validation's multi_logloss: 1.06634
Early stopping, best iteration is:
[13]	training's multi_logloss: 1.06631	validation's multi_logloss: 1.06634
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=14.325973431787746, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.325973431787746
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100
[LightGBM] [Warning] min_gain_to_split is set=12.60534823626305, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.60534823626305
[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100
[LightGBM] [Warning] min_gain_to_split is set=12.60534823626305, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.60534823626305
[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=3100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3100
[LightGBM] [Warning] min_gain_to_split is set=12.60534823626305, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.60534823626305
[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=30, reg_lambda=0.0 will be ignored. Current value: lambda_l2=30
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800
[LightGBM] [Warning] min_gain_to_split is set=11.761629353446324, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.761629353446324
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800
[LightGBM] [Warning] min_gain_to_split is set=11.761629353446324, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.761629353446324
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800
[LightGBM] [Warning] min_gain_to_split is set=11.761629353446324, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.761629353446324
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=1800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1800
[LightGBM] [Warning] min_gain_to_split is set=11.761629353446324, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.761629353446324
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=4200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4200
[LightGBM] [Warning] min_gain_to_split is set=14.697067338294904, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.697067338294904
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=4200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4200
[LightGBM] [Warning] min_gain_to_split is set=14.697067338294904, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.697067338294904
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=4200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4200
[LightGBM] [Warning] min_gain_to_split is set=14.697067338294904, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.697067338294904
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=4200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4200
[LightGBM] [Warning] min_gain_to_split is set=14.697067338294904, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.697067338294904
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200
[LightGBM] [Warning] min_gain_to_split is set=10.567110795400058, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.567110795400058
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200
[LightGBM] [Warning] min_gain_to_split is set=10.567110795400058, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.567110795400058
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200
[LightGBM] [Warning] min_gain_to_split is set=10.567110795400058, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.567110795400058
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200
[LightGBM] [Warning] min_gain_to_split is set=10.567110795400058, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=10.567110795400058
[LightGBM] [Warning] lambda_l1 is set=5, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=35, reg_lambda=0.0 will be ignored. Current value: lambda_l2=35
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100
[LightGBM] [Warning] min_gain_to_split is set=13.010271148705986, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.010271148705986
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100
[LightGBM] [Warning] min_gain_to_split is set=13.010271148705986, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.010271148705986
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100
[LightGBM] [Warning] min_gain_to_split is set=13.010271148705986, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.010271148705986
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=8100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=8100
[LightGBM] [Warning] min_gain_to_split is set=13.010271148705986, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.010271148705986
[LightGBM] [Warning] lambda_l1 is set=25, reg_alpha=0.0 will be ignored. Current value: lambda_l1=25
[LightGBM] [Warning] bagging_fraction is set=0.6000000000000001, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6000000000000001
[LightGBM] [Warning] lambda_l2 is set=20, reg_lambda=0.0 will be ignored. Current value: lambda_l2=20
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=4600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4600
[LightGBM] [Warning] min_gain_to_split is set=11.010158898856327, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.010158898856327
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=4600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4600
[LightGBM] [Warning] min_gain_to_split is set=11.010158898856327, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.010158898856327
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=4600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4600
[LightGBM] [Warning] min_gain_to_split is set=11.010158898856327, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.010158898856327
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=4600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=4600
[LightGBM] [Warning] min_gain_to_split is set=11.010158898856327, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.010158898856327
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=3000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3000
[LightGBM] [Warning] min_gain_to_split is set=13.63860720458263, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.63860720458263
[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=3000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3000
[LightGBM] [Warning] min_gain_to_split is set=13.63860720458263, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.63860720458263
[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=3000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3000
[LightGBM] [Warning] min_gain_to_split is set=13.63860720458263, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.63860720458263
[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=3000, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3000
[LightGBM] [Warning] min_gain_to_split is set=13.63860720458263, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.63860720458263
[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=25, reg_lambda=0.0 will be ignored. Current value: lambda_l2=25
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=14.716893057309743, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.716893057309743
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08577	validation's multi_logloss: 1.08519
[3]	training's multi_logloss: 1.07599	validation's multi_logloss: 1.07545
[4]	training's multi_logloss: 1.06737	validation's multi_logloss: 1.06669
[5]	training's multi_logloss: 1.0608	validation's multi_logloss: 1.05981
[6]	training's multi_logloss: 1.0608	validation's multi_logloss: 1.05981
[7]	training's multi_logloss: 1.0608	validation's multi_logloss: 1.05981
[8]	training's multi_logloss: 1.0608	validation's multi_logloss: 1.05981
[9]	training's multi_logloss: 1.0608	validation's multi_logloss: 1.05981
[10]	training's multi_logloss: 1.0608	validation's multi_logloss: 1.05981
[11]	training's multi_logloss: 1.0608	validation's multi_logloss: 1.05981
[12]	training's multi_logloss: 1.0608	validation's multi_logloss: 1.05981
[13]	training's multi_logloss: 1.0608	validation's multi_logloss: 1.05981
[14]	training's multi_logloss: 1.0608	validation's multi_logloss: 1.05981
[15]	training's multi_logloss: 1.0608	validation's multi_logloss: 1.05981
Early stopping, best iteration is:
[5]	training's multi_logloss: 1.0608	validation's multi_logloss: 1.05981
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=14.716893057309743, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.716893057309743
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08751	validation's multi_logloss: 1.08732
[3]	training's multi_logloss: 1.0774	validation's multi_logloss: 1.07717
[4]	training's multi_logloss: 1.0774	validation's multi_logloss: 1.07717
[5]	training's multi_logloss: 1.0774	validation's multi_logloss: 1.07717
[6]	training's multi_logloss: 1.06958	validation's multi_logloss: 1.06934
[7]	training's multi_logloss: 1.06958	validation's multi_logloss: 1.06934
[8]	training's multi_logloss: 1.06958	validation's multi_logloss: 1.06934
[9]	training's multi_logloss: 1.06958	validation's multi_logloss: 1.06934
[10]	training's multi_logloss: 1.06958	validation's multi_logloss: 1.06934
[11]	training's multi_logloss: 1.06958	validation's multi_logloss: 1.06934
[12]	training's multi_logloss: 1.06958	validation's multi_logloss: 1.06934
[13]	training's multi_logloss: 1.06292	validation's multi_logloss: 1.06286
[14]	training's multi_logloss: 1.06292	validation's multi_logloss: 1.06286
[15]	training's multi_logloss: 1.06292	validation's multi_logloss: 1.06286
[16]	training's multi_logloss: 1.06292	validation's multi_logloss: 1.06286
[17]	training's multi_logloss: 1.05707	validation's multi_logloss: 1.05687
[18]	training's multi_logloss: 1.05707	validation's multi_logloss: 1.05687
[19]	training's multi_logloss: 1.05707	validation's multi_logloss: 1.05687
[20]	training's multi_logloss: 1.05707	validation's multi_logloss: 1.05687
[21]	training's multi_logloss: 1.05707	validation's multi_logloss: 1.05687
[22]	training's multi_logloss: 1.05707	validation's multi_logloss: 1.05687
[23]	training's multi_logloss: 1.05707	validation's multi_logloss: 1.05687
[24]	training's multi_logloss: 1.05707	validation's multi_logloss: 1.05687
[25]	training's multi_logloss: 1.05707	validation's multi_logloss: 1.05687
[26]	training's multi_logloss: 1.05707	validation's multi_logloss: 1.05687
[27]	training's multi_logloss: 1.05707	validation's multi_logloss: 1.05687
Early stopping, best iteration is:
[17]	training's multi_logloss: 1.05707	validation's multi_logloss: 1.05687
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=14.716893057309743, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.716893057309743
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08635	validation's multi_logloss: 1.0874
[3]	training's multi_logloss: 1.08635	validation's multi_logloss: 1.0874
[4]	training's multi_logloss: 1.07539	validation's multi_logloss: 1.0772
[5]	training's multi_logloss: 1.06733	validation's multi_logloss: 1.06984
[6]	training's multi_logloss: 1.06733	validation's multi_logloss: 1.06984
[7]	training's multi_logloss: 1.06733	validation's multi_logloss: 1.06984
[8]	training's multi_logloss: 1.06733	validation's multi_logloss: 1.06984
[9]	training's multi_logloss: 1.06733	validation's multi_logloss: 1.06984
[10]	training's multi_logloss: 1.06733	validation's multi_logloss: 1.06984
[11]	training's multi_logloss: 1.06733	validation's multi_logloss: 1.06984
[12]	training's multi_logloss: 1.06733	validation's multi_logloss: 1.06984
[13]	training's multi_logloss: 1.06733	validation's multi_logloss: 1.06984
[14]	training's multi_logloss: 1.06733	validation's multi_logloss: 1.06984
[15]	training's multi_logloss: 1.06733	validation's multi_logloss: 1.06984
Early stopping, best iteration is:
[5]	training's multi_logloss: 1.06733	validation's multi_logloss: 1.06984
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=14.716893057309743, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.716893057309743
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08714	validation's multi_logloss: 1.08805
[3]	training's multi_logloss: 1.07685	validation's multi_logloss: 1.07752
[4]	training's multi_logloss: 1.07685	validation's multi_logloss: 1.07752
[5]	training's multi_logloss: 1.06909	validation's multi_logloss: 1.06923
[6]	training's multi_logloss: 1.06909	validation's multi_logloss: 1.06923
[7]	training's multi_logloss: 1.06909	validation's multi_logloss: 1.06923
[8]	training's multi_logloss: 1.06909	validation's multi_logloss: 1.06923
[9]	training's multi_logloss: 1.06909	validation's multi_logloss: 1.06923
[10]	training's multi_logloss: 1.06909	validation's multi_logloss: 1.06923
[11]	training's multi_logloss: 1.06909	validation's multi_logloss: 1.06923
[12]	training's multi_logloss: 1.06909	validation's multi_logloss: 1.06923
[13]	training's multi_logloss: 1.06126	validation's multi_logloss: 1.0611
[14]	training's multi_logloss: 1.06126	validation's multi_logloss: 1.0611
[15]	training's multi_logloss: 1.06126	validation's multi_logloss: 1.0611
[16]	training's multi_logloss: 1.06126	validation's multi_logloss: 1.0611
[17]	training's multi_logloss: 1.06126	validation's multi_logloss: 1.0611
[18]	training's multi_logloss: 1.06126	validation's multi_logloss: 1.0611
[19]	training's multi_logloss: 1.06126	validation's multi_logloss: 1.0611
[20]	training's multi_logloss: 1.06126	validation's multi_logloss: 1.0611
[21]	training's multi_logloss: 1.06126	validation's multi_logloss: 1.0611
[22]	training's multi_logloss: 1.06126	validation's multi_logloss: 1.0611
[23]	training's multi_logloss: 1.06126	validation's multi_logloss: 1.0611
Early stopping, best iteration is:
[13]	training's multi_logloss: 1.06126	validation's multi_logloss: 1.0611
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900
[LightGBM] [Warning] min_gain_to_split is set=14.969949759156659, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.969949759156659
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900
[LightGBM] [Warning] min_gain_to_split is set=14.969949759156659, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.969949759156659
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900
[LightGBM] [Warning] min_gain_to_split is set=14.969949759156659, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.969949759156659
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=900
[LightGBM] [Warning] min_gain_to_split is set=14.969949759156659, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.969949759156659
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=2600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2600
[LightGBM] [Warning] min_gain_to_split is set=13.451766249255055, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.451766249255055
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=2600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2600
[LightGBM] [Warning] min_gain_to_split is set=13.451766249255055, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.451766249255055
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=2600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2600
[LightGBM] [Warning] min_gain_to_split is set=13.451766249255055, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.451766249255055
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=2600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2600
[LightGBM] [Warning] min_gain_to_split is set=13.451766249255055, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.451766249255055
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=80, reg_lambda=0.0 will be ignored. Current value: lambda_l2=80
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=1900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1900
[LightGBM] [Warning] min_gain_to_split is set=12.00089517061691, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.00089517061691
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=1900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1900
[LightGBM] [Warning] min_gain_to_split is set=12.00089517061691, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.00089517061691
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=1900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1900
[LightGBM] [Warning] min_gain_to_split is set=12.00089517061691, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.00089517061691
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=1900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1900
[LightGBM] [Warning] min_gain_to_split is set=12.00089517061691, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.00089517061691
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=100, reg_lambda=0.0 will be ignored. Current value: lambda_l2=100
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=13.635599846927493, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.635599846927493
[LightGBM] [Warning] lambda_l1 is set=50, reg_alpha=0.0 will be ignored. Current value: lambda_l1=50
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=1900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1900
[LightGBM] [Warning] min_gain_to_split is set=13.796976350169139, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.796976350169139
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=1900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1900
[LightGBM] [Warning] min_gain_to_split is set=13.796976350169139, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.796976350169139
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=1900, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1900
[LightGBM] [Warning] min_gain_to_split is set=13.796976350169139, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.796976350169139
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=90, reg_lambda=0.0 will be ignored. Current value: lambda_l2=90
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
[LightGBM] [Warning] min_data_in_leaf is set=1100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1100
[LightGBM] [Warning] min_gain_to_split is set=14.83957524977307, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.83957524977307
[LightGBM] [Warning] lambda_l1 is set=15, reg_alpha=0.0 will be ignored. Current value: lambda_l1=15
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=3400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3400
[LightGBM] [Warning] min_gain_to_split is set=12.488983723944234, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.488983723944234
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=3400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3400
[LightGBM] [Warning] min_gain_to_split is set=12.488983723944234, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.488983723944234
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=3400, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=3400
[LightGBM] [Warning] min_gain_to_split is set=12.488983723944234, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.488983723944234
[LightGBM] [Warning] lambda_l1 is set=100, reg_alpha=0.0 will be ignored. Current value: lambda_l1=100
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=2300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2300
[LightGBM] [Warning] min_gain_to_split is set=0.6022944233898553, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.6022944233898553
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=2300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2300
[LightGBM] [Warning] min_gain_to_split is set=0.6022944233898553, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.6022944233898553
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=2300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2300
[LightGBM] [Warning] min_gain_to_split is set=0.6022944233898553, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.6022944233898553
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=2300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2300
[LightGBM] [Warning] min_gain_to_split is set=0.6022944233898553, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=0.6022944233898553
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=14.88141752737253, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.88141752737253
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08621	validation's multi_logloss: 1.08564
[3]	training's multi_logloss: 1.07678	validation's multi_logloss: 1.07625
[4]	training's multi_logloss: 1.06842	validation's multi_logloss: 1.06775
[5]	training's multi_logloss: 1.06202	validation's multi_logloss: 1.06106
[6]	training's multi_logloss: 1.06202	validation's multi_logloss: 1.06106
[7]	training's multi_logloss: 1.06202	validation's multi_logloss: 1.06106
[8]	training's multi_logloss: 1.06202	validation's multi_logloss: 1.06106
[9]	training's multi_logloss: 1.06202	validation's multi_logloss: 1.06106
[10]	training's multi_logloss: 1.06202	validation's multi_logloss: 1.06106
[11]	training's multi_logloss: 1.06202	validation's multi_logloss: 1.06106
[12]	training's multi_logloss: 1.06202	validation's multi_logloss: 1.06106
[13]	training's multi_logloss: 1.06202	validation's multi_logloss: 1.06106
[14]	training's multi_logloss: 1.06202	validation's multi_logloss: 1.06106
[15]	training's multi_logloss: 1.06202	validation's multi_logloss: 1.06106
Early stopping, best iteration is:
[5]	training's multi_logloss: 1.06202	validation's multi_logloss: 1.06106
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=14.88141752737253, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.88141752737253
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08801	validation's multi_logloss: 1.08783
[3]	training's multi_logloss: 1.07826	validation's multi_logloss: 1.07804
[4]	training's multi_logloss: 1.07826	validation's multi_logloss: 1.07804
[5]	training's multi_logloss: 1.07826	validation's multi_logloss: 1.07804
[6]	training's multi_logloss: 1.07826	validation's multi_logloss: 1.07804
[7]	training's multi_logloss: 1.07826	validation's multi_logloss: 1.07804
[8]	training's multi_logloss: 1.07826	validation's multi_logloss: 1.07804
[9]	training's multi_logloss: 1.07826	validation's multi_logloss: 1.07804
[10]	training's multi_logloss: 1.07826	validation's multi_logloss: 1.07804
[11]	training's multi_logloss: 1.07826	validation's multi_logloss: 1.07804
[12]	training's multi_logloss: 1.07826	validation's multi_logloss: 1.07804
[13]	training's multi_logloss: 1.07	validation's multi_logloss: 1.06999
[14]	training's multi_logloss: 1.07	validation's multi_logloss: 1.06999
[15]	training's multi_logloss: 1.07	validation's multi_logloss: 1.06999
[16]	training's multi_logloss: 1.07	validation's multi_logloss: 1.06999
[17]	training's multi_logloss: 1.06281	validation's multi_logloss: 1.06268
[18]	training's multi_logloss: 1.06281	validation's multi_logloss: 1.06268
[19]	training's multi_logloss: 1.06281	validation's multi_logloss: 1.06268
[20]	training's multi_logloss: 1.06281	validation's multi_logloss: 1.06268
[21]	training's multi_logloss: 1.06281	validation's multi_logloss: 1.06268
[22]	training's multi_logloss: 1.06281	validation's multi_logloss: 1.06268
[23]	training's multi_logloss: 1.06281	validation's multi_logloss: 1.06268
[24]	training's multi_logloss: 1.06281	validation's multi_logloss: 1.06268
[25]	training's multi_logloss: 1.06281	validation's multi_logloss: 1.06268
[26]	training's multi_logloss: 1.06281	validation's multi_logloss: 1.06268
[27]	training's multi_logloss: 1.06281	validation's multi_logloss: 1.06268
Early stopping, best iteration is:
[17]	training's multi_logloss: 1.06281	validation's multi_logloss: 1.06268
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=14.88141752737253, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.88141752737253
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08684	validation's multi_logloss: 1.08785
[3]	training's multi_logloss: 1.08684	validation's multi_logloss: 1.08785
[4]	training's multi_logloss: 1.07623	validation's multi_logloss: 1.07797
[5]	training's multi_logloss: 1.07623	validation's multi_logloss: 1.07797
[6]	training's multi_logloss: 1.06741	validation's multi_logloss: 1.07018
[7]	training's multi_logloss: 1.06741	validation's multi_logloss: 1.07018
[8]	training's multi_logloss: 1.06741	validation's multi_logloss: 1.07018
[9]	training's multi_logloss: 1.06741	validation's multi_logloss: 1.07018
[10]	training's multi_logloss: 1.06741	validation's multi_logloss: 1.07018
[11]	training's multi_logloss: 1.06741	validation's multi_logloss: 1.07018
[12]	training's multi_logloss: 1.06741	validation's multi_logloss: 1.07018
[13]	training's multi_logloss: 1.06741	validation's multi_logloss: 1.07018
[14]	training's multi_logloss: 1.06741	validation's multi_logloss: 1.07018
[15]	training's multi_logloss: 1.06741	validation's multi_logloss: 1.07018
[16]	training's multi_logloss: 1.06741	validation's multi_logloss: 1.07018
Early stopping, best iteration is:
[6]	training's multi_logloss: 1.06741	validation's multi_logloss: 1.07018
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=14.88141752737253, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.88141752737253
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08777	validation's multi_logloss: 1.08771
[3]	training's multi_logloss: 1.07748	validation's multi_logloss: 1.07785
[4]	training's multi_logloss: 1.07748	validation's multi_logloss: 1.07785
[5]	training's multi_logloss: 1.07748	validation's multi_logloss: 1.07785
[6]	training's multi_logloss: 1.07748	validation's multi_logloss: 1.07785
[7]	training's multi_logloss: 1.07748	validation's multi_logloss: 1.07785
[8]	training's multi_logloss: 1.07748	validation's multi_logloss: 1.07785
[9]	training's multi_logloss: 1.07748	validation's multi_logloss: 1.07785
[10]	training's multi_logloss: 1.07748	validation's multi_logloss: 1.07785
[11]	training's multi_logloss: 1.07748	validation's multi_logloss: 1.07785
[12]	training's multi_logloss: 1.07748	validation's multi_logloss: 1.07785
[13]	training's multi_logloss: 1.06785	validation's multi_logloss: 1.0679
[14]	training's multi_logloss: 1.06785	validation's multi_logloss: 1.0679
[15]	training's multi_logloss: 1.06785	validation's multi_logloss: 1.0679
[16]	training's multi_logloss: 1.06785	validation's multi_logloss: 1.0679
[17]	training's multi_logloss: 1.06785	validation's multi_logloss: 1.0679
[18]	training's multi_logloss: 1.06785	validation's multi_logloss: 1.0679
[19]	training's multi_logloss: 1.06785	validation's multi_logloss: 1.0679
[20]	training's multi_logloss: 1.06785	validation's multi_logloss: 1.0679
[21]	training's multi_logloss: 1.06785	validation's multi_logloss: 1.0679
[22]	training's multi_logloss: 1.06785	validation's multi_logloss: 1.0679
[23]	training's multi_logloss: 1.06785	validation's multi_logloss: 1.0679
Early stopping, best iteration is:
[13]	training's multi_logloss: 1.06785	validation's multi_logloss: 1.0679
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=14.037261486811481, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.037261486811481
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=14.037261486811481, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.037261486811481
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=14.037261486811481, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.037261486811481
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=14.037261486811481, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.037261486811481
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=50, reg_lambda=0.0 will be ignored. Current value: lambda_l2=50
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=14.080574180355253, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.080574180355253
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=65, reg_lambda=0.0 will be ignored. Current value: lambda_l2=65
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08856	validation's multi_logloss: 1.08833
[3]	training's multi_logloss: 1.08856	validation's multi_logloss: 1.08833
[4]	training's multi_logloss: 1.08856	validation's multi_logloss: 1.08833
[5]	training's multi_logloss: 1.08856	validation's multi_logloss: 1.08833
[6]	training's multi_logloss: 1.08856	validation's multi_logloss: 1.08833
[7]	training's multi_logloss: 1.08856	validation's multi_logloss: 1.08833
[8]	training's multi_logloss: 1.08856	validation's multi_logloss: 1.08833
[9]	training's multi_logloss: 1.08856	validation's multi_logloss: 1.08833
[10]	training's multi_logloss: 1.08856	validation's multi_logloss: 1.08833
[11]	training's multi_logloss: 1.08856	validation's multi_logloss: 1.08833
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300
[LightGBM] [Warning] min_gain_to_split is set=14.994391548410675, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.994391548410675
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300
[LightGBM] [Warning] min_gain_to_split is set=14.994391548410675, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.994391548410675
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=1300, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1300
[LightGBM] [Warning] min_gain_to_split is set=14.994391548410675, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.994391548410675
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=40, reg_lambda=0.0 will be ignored. Current value: lambda_l2=40
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=13.047169115536626, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.047169115536626
[LightGBM] [Warning] lambda_l1 is set=30, reg_alpha=0.0 will be ignored. Current value: lambda_l1=30
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=5500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5500
[LightGBM] [Warning] min_gain_to_split is set=9.997059921169138, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.997059921169138
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=5500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5500
[LightGBM] [Warning] min_gain_to_split is set=9.997059921169138, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.997059921169138
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=5500, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=5500
[LightGBM] [Warning] min_gain_to_split is set=9.997059921169138, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=9.997059921169138
[LightGBM] [Warning] lambda_l1 is set=80, reg_alpha=0.0 will be ignored. Current value: lambda_l1=80
[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600
[LightGBM] [Warning] min_gain_to_split is set=13.865819775407866, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.865819775407866
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
[LightGBM] [Warning] lambda_l2 is set=45, reg_lambda=0.0 will be ignored. Current value: lambda_l2=45
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=2200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2200
[LightGBM] [Warning] min_gain_to_split is set=12.361546415224547, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.361546415224547
[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=2200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2200
[LightGBM] [Warning] min_gain_to_split is set=12.361546415224547, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.361546415224547
[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=2200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2200
[LightGBM] [Warning] min_gain_to_split is set=12.361546415224547, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.361546415224547
[LightGBM] [Warning] lambda_l1 is set=90, reg_alpha=0.0 will be ignored. Current value: lambda_l1=90
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=11.316963917745934, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.316963917745934
[LightGBM] [Warning] lambda_l1 is set=75, reg_alpha=0.0 will be ignored. Current value: lambda_l1=75
[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8
[LightGBM] [Warning] lambda_l2 is set=15, reg_lambda=0.0 will be ignored. Current value: lambda_l2=15
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08612	validation's multi_logloss: 1.08556
[3]	training's multi_logloss: 1.07665	validation's multi_logloss: 1.07612
[4]	training's multi_logloss: 1.06826	validation's multi_logloss: 1.0676
[5]	training's multi_logloss: 1.06187	validation's multi_logloss: 1.0609
[6]	training's multi_logloss: 1.06187	validation's multi_logloss: 1.0609
[7]	training's multi_logloss: 1.06187	validation's multi_logloss: 1.0609
[8]	training's multi_logloss: 1.06187	validation's multi_logloss: 1.0609
[9]	training's multi_logloss: 1.06187	validation's multi_logloss: 1.0609
[10]	training's multi_logloss: 1.06187	validation's multi_logloss: 1.0609
[11]	training's multi_logloss: 1.06187	validation's multi_logloss: 1.0609
[12]	training's multi_logloss: 1.06187	validation's multi_logloss: 1.0609
[13]	training's multi_logloss: 1.06187	validation's multi_logloss: 1.0609
[14]	training's multi_logloss: 1.06187	validation's multi_logloss: 1.0609
[15]	training's multi_logloss: 1.06187	validation's multi_logloss: 1.0609
Early stopping, best iteration is:
[5]	training's multi_logloss: 1.06187	validation's multi_logloss: 1.0609
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=14.130436398820837, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.130436398820837
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08794	validation's multi_logloss: 1.08775
[3]	training's multi_logloss: 1.07814	validation's multi_logloss: 1.07792
[4]	training's multi_logloss: 1.07814	validation's multi_logloss: 1.07792
[5]	training's multi_logloss: 1.07814	validation's multi_logloss: 1.07792
[6]	training's multi_logloss: 1.07814	validation's multi_logloss: 1.07792
[7]	training's multi_logloss: 1.07814	validation's multi_logloss: 1.07792
[8]	training's multi_logloss: 1.07814	validation's multi_logloss: 1.07792
[9]	training's multi_logloss: 1.07814	validation's multi_logloss: 1.07792
[10]	training's multi_logloss: 1.07814	validation's multi_logloss: 1.07792
[11]	training's multi_logloss: 1.07814	validation's multi_logloss: 1.07792
[12]	training's multi_logloss: 1.07112	validation's multi_logloss: 1.07067
[13]	training's multi_logloss: 1.07112	validation's multi_logloss: 1.07067
[14]	training's multi_logloss: 1.07112	validation's multi_logloss: 1.07067
[15]	training's multi_logloss: 1.07112	validation's multi_logloss: 1.07067
[16]	training's multi_logloss: 1.07112	validation's multi_logloss: 1.07067
[17]	training's multi_logloss: 1.06362	validation's multi_logloss: 1.06305
[18]	training's multi_logloss: 1.06362	validation's multi_logloss: 1.06305
[19]	training's multi_logloss: 1.06362	validation's multi_logloss: 1.06305
[20]	training's multi_logloss: 1.06362	validation's multi_logloss: 1.06305
[21]	training's multi_logloss: 1.06362	validation's multi_logloss: 1.06305
[22]	training's multi_logloss: 1.06362	validation's multi_logloss: 1.06305
[23]	training's multi_logloss: 1.06362	validation's multi_logloss: 1.06305
[24]	training's multi_logloss: 1.06362	validation's multi_logloss: 1.06305
[25]	training's multi_logloss: 1.06362	validation's multi_logloss: 1.06305
[26]	training's multi_logloss: 1.06362	validation's multi_logloss: 1.06305
[27]	training's multi_logloss: 1.06362	validation's multi_logloss: 1.06305
Early stopping, best iteration is:
[17]	training's multi_logloss: 1.06362	validation's multi_logloss: 1.06305
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=14.130436398820837, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.130436398820837
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08676	validation's multi_logloss: 1.08778
[3]	training's multi_logloss: 1.08676	validation's multi_logloss: 1.08778
[4]	training's multi_logloss: 1.0761	validation's multi_logloss: 1.07785
[5]	training's multi_logloss: 1.0761	validation's multi_logloss: 1.07785
[6]	training's multi_logloss: 1.06725	validation's multi_logloss: 1.07005
[7]	training's multi_logloss: 1.06725	validation's multi_logloss: 1.07005
[8]	training's multi_logloss: 1.06725	validation's multi_logloss: 1.07005
[9]	training's multi_logloss: 1.06725	validation's multi_logloss: 1.07005
[10]	training's multi_logloss: 1.06725	validation's multi_logloss: 1.07005
[11]	training's multi_logloss: 1.06725	validation's multi_logloss: 1.07005
[12]	training's multi_logloss: 1.06725	validation's multi_logloss: 1.07005
[13]	training's multi_logloss: 1.06725	validation's multi_logloss: 1.07005
[14]	training's multi_logloss: 1.06725	validation's multi_logloss: 1.07005
[15]	training's multi_logloss: 1.06725	validation's multi_logloss: 1.07005
[16]	training's multi_logloss: 1.06725	validation's multi_logloss: 1.07005
Early stopping, best iteration is:
[6]	training's multi_logloss: 1.06725	validation's multi_logloss: 1.07005
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=200
[LightGBM] [Warning] min_gain_to_split is set=14.130436398820837, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.130436398820837
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08769	validation's multi_logloss: 1.08763
[3]	training's multi_logloss: 1.07736	validation's multi_logloss: 1.07773
[4]	training's multi_logloss: 1.07736	validation's multi_logloss: 1.07773
[5]	training's multi_logloss: 1.07736	validation's multi_logloss: 1.07773
[6]	training's multi_logloss: 1.07736	validation's multi_logloss: 1.07773
[7]	training's multi_logloss: 1.07736	validation's multi_logloss: 1.07773
[8]	training's multi_logloss: 1.07736	validation's multi_logloss: 1.07773
[9]	training's multi_logloss: 1.07736	validation's multi_logloss: 1.07773
[10]	training's multi_logloss: 1.07736	validation's multi_logloss: 1.07773
[11]	training's multi_logloss: 1.07736	validation's multi_logloss: 1.07773
[12]	training's multi_logloss: 1.07736	validation's multi_logloss: 1.07773
[13]	training's multi_logloss: 1.06769	validation's multi_logloss: 1.06774
[14]	training's multi_logloss: 1.06769	validation's multi_logloss: 1.06774
[15]	training's multi_logloss: 1.06769	validation's multi_logloss: 1.06774
[16]	training's multi_logloss: 1.06769	validation's multi_logloss: 1.06774
[17]	training's multi_logloss: 1.06769	validation's multi_logloss: 1.06774
[18]	training's multi_logloss: 1.06769	validation's multi_logloss: 1.06774
[19]	training's multi_logloss: 1.06769	validation's multi_logloss: 1.06774
[20]	training's multi_logloss: 1.06135	validation's multi_logloss: 1.06088
[21]	training's multi_logloss: 1.06135	validation's multi_logloss: 1.06088
[22]	training's multi_logloss: 1.06135	validation's multi_logloss: 1.06088
[23]	training's multi_logloss: 1.06135	validation's multi_logloss: 1.06088
[24]	training's multi_logloss: 1.06135	validation's multi_logloss: 1.06088
[25]	training's multi_logloss: 1.06135	validation's multi_logloss: 1.06088
[26]	training's multi_logloss: 1.06135	validation's multi_logloss: 1.06088
[27]	training's multi_logloss: 1.06135	validation's multi_logloss: 1.06088
[28]	training's multi_logloss: 1.06135	validation's multi_logloss: 1.06088
[29]	training's multi_logloss: 1.06135	validation's multi_logloss: 1.06088
[30]	training's multi_logloss: 1.06135	validation's multi_logloss: 1.06088
Early stopping, best iteration is:
[20]	training's multi_logloss: 1.06135	validation's multi_logloss: 1.06088
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=14.291583233893594, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.291583233893594
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=700
[LightGBM] [Warning] min_gain_to_split is set=14.291583233893594, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.291583233893594
[LightGBM] [Warning] lambda_l1 is set=65, reg_alpha=0.0 will be ignored. Current value: lambda_l1=65
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=70, reg_lambda=0.0 will be ignored. Current value: lambda_l2=70
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08933	validation's multi_logloss: 1.08917
[3]	training's multi_logloss: 1.08933	validation's multi_logloss: 1.08917
[4]	training's multi_logloss: 1.08933	validation's multi_logloss: 1.08917
[5]	training's multi_logloss: 1.08933	validation's multi_logloss: 1.08917
[6]	training's multi_logloss: 1.08933	validation's multi_logloss: 1.08917
[7]	training's multi_logloss: 1.08933	validation's multi_logloss: 1.08917
[8]	training's multi_logloss: 1.08933	validation's multi_logloss: 1.08917
[9]	training's multi_logloss: 1.08933	validation's multi_logloss: 1.08917
[10]	training's multi_logloss: 1.08933	validation's multi_logloss: 1.08917
[11]	training's multi_logloss: 1.08933	validation's multi_logloss: 1.08917
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08671	validation's multi_logloss: 1.08616
[3]	training's multi_logloss: 1.07759	validation's multi_logloss: 1.07707
[4]	training's multi_logloss: 1.06944	validation's multi_logloss: 1.0688
[5]	training's multi_logloss: 1.06317	validation's multi_logloss: 1.06224
[6]	training's multi_logloss: 1.06317	validation's multi_logloss: 1.06224
[7]	training's multi_logloss: 1.06317	validation's multi_logloss: 1.06224
[8]	training's multi_logloss: 1.06317	validation's multi_logloss: 1.06224
[9]	training's multi_logloss: 1.06317	validation's multi_logloss: 1.06224
[10]	training's multi_logloss: 1.06317	validation's multi_logloss: 1.06224
[11]	training's multi_logloss: 1.06317	validation's multi_logloss: 1.06224
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200
[LightGBM] [Warning] min_gain_to_split is set=14.33793201468554, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.33793201468554
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200
[LightGBM] [Warning] min_gain_to_split is set=14.33793201468554, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.33793201468554
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=1200, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1200
[LightGBM] [Warning] min_gain_to_split is set=14.33793201468554, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.33793201468554
[LightGBM] [Warning] lambda_l1 is set=45, reg_alpha=0.0 will be ignored. Current value: lambda_l1=45
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=75, reg_lambda=0.0 will be ignored. Current value: lambda_l2=75
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
[LightGBM] [Warning] min_data_in_leaf is set=600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=600
[LightGBM] [Warning] min_gain_to_split is set=12.418593980076082, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.418593980076082
[LightGBM] [Warning] lambda_l1 is set=60, reg_alpha=0.0 will be ignored. Current value: lambda_l1=60
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.08638	validation's multi_logloss: 1.08662
[3]	training's multi_logloss: 1.08638	validation's multi_logloss: 1.08662
[4]	training's multi_logloss: 1.07535	validation's multi_logloss: 1.07537
[5]	training's multi_logloss: 1.06729	validation's multi_logloss: 1.06727
[6]	training's multi_logloss: 1.06729	validation's multi_logloss: 1.06727
[7]	training's multi_logloss: 1.06729	validation's multi_logloss: 1.06727
[8]	training's multi_logloss: 1.06729	validation's multi_logloss: 1.06727
[9]	training's multi_logloss: 1.06729	validation's multi_logloss: 1.06727
[10]	training's multi_logloss: 1.06729	validation's multi_logloss: 1.06727
[11]	training's multi_logloss: 1.06729	validation's multi_logloss: 1.06727
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700
[LightGBM] [Warning] min_gain_to_split is set=14.262587907516423, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.262587907516423
[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700
[LightGBM] [Warning] min_gain_to_split is set=14.262587907516423, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.262587907516423
[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.7, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7
[LightGBM] [Warning] min_data_in_leaf is set=2700, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2700
[LightGBM] [Warning] min_gain_to_split is set=14.262587907516423, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=14.262587907516423
[LightGBM] [Warning] lambda_l1 is set=85, reg_alpha=0.0 will be ignored. Current value: lambda_l1=85
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=95, reg_lambda=0.0 will be ignored. Current value: lambda_l2=95
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=7800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7800
[LightGBM] [Warning] min_gain_to_split is set=13.132058545031391, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.132058545031391
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=7800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7800
[LightGBM] [Warning] min_gain_to_split is set=13.132058545031391, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.132058545031391
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=7800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7800
[LightGBM] [Warning] min_gain_to_split is set=13.132058545031391, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.132058545031391
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=7800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=7800
[LightGBM] [Warning] min_gain_to_split is set=13.132058545031391, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.132058545031391
[LightGBM] [Warning] lambda_l1 is set=55, reg_alpha=0.0 will be ignored. Current value: lambda_l1=55
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=60, reg_lambda=0.0 will be ignored. Current value: lambda_l2=60
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600
[LightGBM] [Warning] min_gain_to_split is set=11.502605149650268, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.502605149650268
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600
[LightGBM] [Warning] min_gain_to_split is set=11.502605149650268, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.502605149650268
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600
[LightGBM] [Warning] min_gain_to_split is set=11.502605149650268, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.502605149650268
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.9, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9
[LightGBM] [Warning] min_data_in_leaf is set=1600, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=1600
[LightGBM] [Warning] min_gain_to_split is set=11.502605149650268, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=11.502605149650268
[LightGBM] [Warning] lambda_l1 is set=40, reg_alpha=0.0 will be ignored. Current value: lambda_l1=40
[LightGBM] [Warning] bagging_fraction is set=0.2, subsample=1.0 will be ignored. Current value: bagging_fraction=0.2
[LightGBM] [Warning] lambda_l2 is set=55, reg_lambda=0.0 will be ignored. Current value: lambda_l2=55
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100
[LightGBM] [Warning] min_gain_to_split is set=13.492861778721426, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.492861778721426
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100
[LightGBM] [Warning] min_gain_to_split is set=13.492861778721426, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.492861778721426
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100
[LightGBM] [Warning] min_gain_to_split is set=13.492861778721426, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.492861778721426
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.09946
[LightGBM] [Warning] feature_fraction is set=0.30000000000000004, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.30000000000000004
[LightGBM] [Warning] min_data_in_leaf is set=2100, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=2100
[LightGBM] [Warning] min_gain_to_split is set=13.492861778721426, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=13.492861778721426
[LightGBM] [Warning] lambda_l1 is set=70, reg_alpha=0.0 will be ignored. Current value: lambda_l1=70
[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
[LightGBM] [Warning] lambda_l2 is set=85, reg_lambda=0.0 will be ignored. Current value: lambda_l2=85
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[3]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[4]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[5]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[6]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[7]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[8]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[9]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[10]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[11]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
Early stopping, best iteration is:
[1]	training's multi_logloss: 1.09954	validation's multi_logloss: 1.0998
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[LightGBM] [Warning] feature_fraction is set=0.6000000000000001, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6000000000000001
[LightGBM] [Warning] min_data_in_leaf is set=800, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=800
[LightGBM] [Warning] min_gain_to_split is set=12.738978622410633, min_split_gain=0.0 will be ignored. Current value: min_gain_to_split=12.738978622410633
[LightGBM] [Warning] lambda_l1 is set=35, reg_alpha=0.0 will be ignored. Current value: lambda_l1=35
[LightGBM] [Warning] bagging_fraction is set=0.30000000000000004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.30000000000000004
[LightGBM] [Warning] lambda_l2 is set=10, reg_lambda=0.0 will be ignored. Current value: lambda_l2=10
[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
[1]	training's multi_logloss: 1.18567	validation's multi_logloss: 1.17286
Training until validation scores don't improve for 10 rounds
[2]	training's multi_logloss: 1.17082	validation's multi_logloss: 1.15828
[3]	training's multi_logloss: 1.15853	validation's multi_logloss: 1.14647
[4]	training's multi_logloss: 1.14727	validation's multi_logloss: 1.1355
[5]	training's multi_logloss: 1.13798	validation's multi_logloss: 1.12694
[6]	training's multi_logloss: 1.12869	validation's multi_logloss: 1.11805
[7]	training's multi_logloss: 1.11994	validation's multi_logloss: 1.10981
[8]	training's multi_logloss: 1.11198	validation's multi_logloss: 1.10185
[9]	training's multi_logloss: 1.10416	validation's multi_logloss: 1.0945
[10]	training's multi_logloss: 1.0977	validation's multi_logloss: 1.08815
[11]	training's multi_logloss: 1.09394	validation's multi_logloss: 1.08487
[12]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[13]	training's multi_logloss: 1.09129	validation's multi_logloss: 1.08239
[14]	training's multi_logloss: 1.08505	validation's multi_logloss: 1.07643
[15]	training's multi_logloss: 1.08253	validation's multi_logloss: 1.07419
[16]	training's multi_logloss: 1.07908	validation's multi_logloss: 1.0704
[17]	training's multi_logloss: 1.07695	validation's multi_logloss: 1.06823
[18]	training's multi_logloss: 1.07505	validation's multi_logloss: 1.06656
[19]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[20]	training's multi_logloss: 1.07342	validation's multi_logloss: 1.06513
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[22]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[23]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[24]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[25]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[26]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[27]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[28]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[29]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[30]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
[31]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
Early stopping, best iteration is:
[21]	training's multi_logloss: 1.06986	validation's multi_logloss: 1.06189
1.0372729261391127 0.44066
2376
INFO: end
