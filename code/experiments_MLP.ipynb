{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing, metrics, model_selection\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "torch.manual_seed(0)\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train      = 'F://TFG//datasets//data_train//'\n",
    "path_graphs     = 'F://TFG//graphs//plot_results//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(path_train+'training_features_DF.csv',sep=';',index_col='wyId')\n",
    "\n",
    "# X_train = pd.read_csv(path_train+'X_train.csv',sep=';',index_col='wyId')\n",
    "# y_train = pd.read_csv(path_train+'y_train.csv',sep=';',index_col='wyId')\n",
    "# X_test = pd.read_csv(path_train+'X_test.csv',sep=';',index_col='wyId')\n",
    "# y_test = pd.read_csv(path_train+'y_test.csv',sep=';',index_col='wyId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FootballMatchesDataset(Dataset):\n",
    "    def __init__(self,file):\n",
    "        df              = pd.read_csv(path_train+'X_'+file+'.csv',sep=';')\n",
    "        lab_df          = pd.read_csv(path_train+'y_'+file+'.csv',sep=';')\n",
    "        self.data       = torch.tensor(df.values[:,1:]).float() \n",
    "        self.labels     = F.one_hot(torch.tensor(lab_df.values[:,1]), num_classes=3).float()\n",
    "        self.matches    = torch.tensor(lab_df.values[:,0])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def shape(self):\n",
    "        return self.data.shape\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        sample  = self.data[idx]\n",
    "        label   = self.labels[idx]\n",
    "        match   = self.matches[idx]\n",
    "        return sample, label, match\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data  = FootballMatchesDataset(file = 'train')\n",
    "test_data   = FootballMatchesDataset(file = 'test')\n",
    "\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train_data, batch_size=4, shuffle=True, num_workers=0)\n",
    "train_feat, train_lab, _ = next(iter(dataloader))\n",
    "train_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler  = preprocessing.StandardScaler()\n",
    "train_data.data = scaler.fit_transform(train_data.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Implementation\n",
    "\n",
    "Define the class:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I) Artificial Neural Network Approach to Football Score Prediction\n",
    "\n",
    "Multilayer Perceptron with 1 hidden layer with BacpPropagation.\n",
    "6 units input -> 5 hidden units -> 2 output units w/ sigmoid\n",
    "\n",
    "Data Normalized [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data  = FootballMatchesDataset(file = 'train')\n",
    "test_data   = FootballMatchesDataset(file = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = preprocessing.Normalizer()\n",
    "train_data.data = normalizer.fit_transform(train_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_data.data.mean(), train_data.data.std())\n",
    "print(train_data.data.max(),  train_data.data.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train    = DataLoader(train_data, batch_size=20, shuffle=True)\n",
    "dataloader_test     = DataLoader(test_data,  batch_size=20, shuffle=True)\n",
    "\n",
    "train_feat, train_lab, _ = next(iter(dataloader_train))\n",
    "train_feat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_feature, ouput_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.h1 = nn.Linear(in_features=input_feature,out_features=5)\n",
    "        self.bn = nn.BatchNorm1d(5)\n",
    "        self.out = nn.Linear(5,ouput_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.h1(x))\n",
    "        x = self.bn(x)\n",
    "        return F.softmax(self.out(x),1)    \n",
    "\n",
    "    def reset_weights(self):\n",
    "        self.h1.reset_parameters()\n",
    "        self.bn.reset_parameters()\n",
    "        self.out.reset_parameters()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork(22,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the architecture and number of parameters.\n",
    "print(model)\n",
    "print(f\"The model has {sum([x.nelement() for x in model.parameters()]):,} parameters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss Function: Cross-entropy Loss\n",
    "\n",
    "we can provide `weights`, as prior probability of each class $C$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.labels   # in 1-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_class = np.mean(train_data.labels.numpy(),axis=0)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# optimizar con momentum (nesterov), weight decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(pred,y):\n",
    "    pred_class = torch.argmax(pred,dim=1).numpy()\n",
    "    y_class    = torch.argmax(y,dim=1).numpy()\n",
    "    # print(pred,pred_class)\n",
    "    # print(y,y_class)\n",
    "    # print()\n",
    "    return np.mean((pred_class == y_class))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, dataloader_train, dataloader_test, epochs):\n",
    "\n",
    "    accuracy_train  = []\n",
    "    error           = []\n",
    "    accuracy_test   = []\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        # Training.\n",
    "        model.train()\n",
    "        acc_batch   = []\n",
    "        \n",
    "        for it, batch in enumerate(dataloader_train):\n",
    "\n",
    "            # 5.1 Load a batch, break it down in images and targets.\n",
    "            x, y, _ = batch\n",
    "            # batch to device ????\n",
    "            \n",
    "            # 5.2 Run forward pass.\n",
    "            logits = model(x)\n",
    "            \n",
    "            # 5.3 Compute loss (using 'criterion').\n",
    "            loss = criterion(logits, y)\n",
    "            \n",
    "            # 5.4 Run backward pass.\n",
    "            loss.backward()\n",
    "            \n",
    "            # 5.5 Update the weights using optimizer.\n",
    "            optimizer.step()\n",
    "            \n",
    "            # 5.6 Zero-out the accumulated gradients.\n",
    "            optimizer.zero_grad()\n",
    "            # `model.zero_grad()` also works\n",
    "\n",
    "            acc_batch.append(get_accuracy(logits,y))\n",
    "\n",
    "        accuracy_train.append(np.mean(acc_batch)) \n",
    "        error.append(float(loss))\n",
    "\n",
    "        print('\\rEp {}/{}, it {}/{}: loss train: {:.2f}, accuracy train: {:.2f}'.\n",
    "                format(ep + 1, epochs, it + 1, len(dataloader_train), loss,\n",
    "                        np.mean(acc_batch)), end='')\n",
    "\n",
    "        # Validation.\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            acc_run = 0\n",
    "            for it, batch in enumerate(dataloader_test):\n",
    "                # Get batch of data.\n",
    "                x, y, _ = batch\n",
    "                curr_bs = x.shape[0]\n",
    "                acc_run += get_accuracy(model(x), y) * curr_bs\n",
    "            acc_test = acc_run / len(dataloader_test.dataset)\n",
    "            accuracy_test.append(acc_test)\n",
    "\n",
    "            print(', accuracy test: {:.2f}'.format(acc_test))\n",
    "\n",
    "    return error,accuracy_train,accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "epochs = 10\n",
    "learning_rate = 1e-1\n",
    "optimizer_lenet = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "error,accuracy_train,accuracy_test = train_model(model, criterion, optimizer, dataloader_train, dataloader_test, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "for p in [accuracy_train,accuracy_test,error]:\n",
    "    plt.plot(p)\n",
    "\n",
    "plt.title('Accuracy: MLP 5 hidden units, batch_size=20')\n",
    "plt.xticks(np.arange(epochs))\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "plt.savefig(path_graphs + 'acc_mlp5_bn20.jpg', format='jpg', dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 5\n",
    "kfold = model_selection.KFold(n_splits=folds,shuffle=True,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wCrossValidation(model,criterion,optimizer,train_data,batch_size,epochs=5):\n",
    "\n",
    "    error           = []\n",
    "    accuracy_train  = []\n",
    "    accuracy_test   = []\n",
    "\n",
    "    for fold,(train_idx,test_idx) in enumerate(kfold.split(train_data.data)):\n",
    "        train_subsampler    = SubsetRandomSampler(train_idx)\n",
    "        test_subsampler     = SubsetRandomSampler(test_idx)\n",
    "        \n",
    "        trainloader = DataLoader(\n",
    "                            train_data, \n",
    "                            batch_size=batch_size, sampler=train_subsampler)\n",
    "        testloader  = DataLoader(\n",
    "                            train_data,\n",
    "                            batch_size=batch_size, sampler=test_subsampler)\n",
    "        \n",
    "        model.reset_weights()\n",
    "\n",
    "        error_fold,acc_train_fold,acc_test_fold = train_model(\n",
    "                model, criterion, optimizer, trainloader, testloader, epochs\n",
    "            )\n",
    "\n",
    "        error.append(error_fold)\n",
    "        accuracy_train.append(acc_train_fold)\n",
    "        accuracy_test.append(acc_test_fold)\n",
    "        \n",
    "        print('\\rFold {}/{}: loss train: {:.2f}, accuracy train: {:.2f}, accuracy test: {:.2f}'.\n",
    "                format(fold + 1, folds, np.mean(error_fold),\n",
    "                        np.mean(acc_train_fold), np.mean(acc_test_fold)), end='')\n",
    "        print('\\n')\n",
    "    \n",
    "    return error, accuracy_train, accuracy_test\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error, accuracy_train, accuracy_test = train_wCrossValidation(model,criterion, optimizer, train_data, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "for p in error:\n",
    "    plt.plot(p)\n",
    "\n",
    "plt.title('Error Cross-Validation: MLP 5 hidden units, batch_size=20')\n",
    "plt.xticks(np.arange(folds))\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.ylim([0.5,1.5])\n",
    "\n",
    "plt.savefig(path_graphs + 'error_cv5_mlp5_bn20.jpg', format='jpg', dpi=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('tfg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "288ff6fe8157f43ba3e1fb4cfa0011490e9beb907b54ad0d71ae70a61946bdb3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
